Directory structure:
‚îî‚îÄ‚îÄ dagger-container-use/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ AGENT.md
    ‚îú‚îÄ‚îÄ CONTRIBUTING.md
    ‚îú‚îÄ‚îÄ dagger.json
    ‚îú‚îÄ‚îÄ go.mod
    ‚îú‚îÄ‚îÄ go.sum
    ‚îú‚îÄ‚îÄ install.sh
    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ RELEASING.md
    ‚îú‚îÄ‚îÄ uninstall.sh
    ‚îú‚îÄ‚îÄ .goreleaser.yaml
    ‚îú‚îÄ‚îÄ CLAUDE.md -> AGENT.md
    ‚îú‚îÄ‚îÄ cmd/
    ‚îÇ   ‚îî‚îÄ‚îÄ container-use/
    ‚îÇ       ‚îú‚îÄ‚îÄ apply.go
    ‚îÇ       ‚îú‚îÄ‚îÄ checkout.go
    ‚îÇ       ‚îú‚îÄ‚îÄ completion_override.go
    ‚îÇ       ‚îú‚îÄ‚îÄ config.go
    ‚îÇ       ‚îú‚îÄ‚îÄ delete.go
    ‚îÇ       ‚îú‚îÄ‚îÄ diff.go
    ‚îÇ       ‚îú‚îÄ‚îÄ docker_errors.go
    ‚îÇ       ‚îú‚îÄ‚îÄ docker_errors_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ env_selection.go
    ‚îÇ       ‚îú‚îÄ‚îÄ env_selection_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ inspect.go
    ‚îÇ       ‚îú‚îÄ‚îÄ list.go
    ‚îÇ       ‚îú‚îÄ‚îÄ log.go
    ‚îÇ       ‚îú‚îÄ‚îÄ logger.go
    ‚îÇ       ‚îú‚îÄ‚îÄ main.go
    ‚îÇ       ‚îú‚îÄ‚îÄ main_suite_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ merge.go
    ‚îÇ       ‚îú‚îÄ‚îÄ prune.go
    ‚îÇ       ‚îú‚îÄ‚îÄ signal_unix.go
    ‚îÇ       ‚îú‚îÄ‚îÄ signal_windows.go
    ‚îÇ       ‚îú‚îÄ‚îÄ signals_unix.go
    ‚îÇ       ‚îú‚îÄ‚îÄ signals_windows.go
    ‚îÇ       ‚îú‚îÄ‚îÄ stdio.go
    ‚îÇ       ‚îú‚îÄ‚îÄ stdio_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ terminal.go
    ‚îÇ       ‚îú‚îÄ‚îÄ terminal_unix.go
    ‚îÇ       ‚îú‚îÄ‚îÄ terminal_windows.go
    ‚îÇ       ‚îú‚îÄ‚îÄ version.go
    ‚îÇ       ‚îú‚îÄ‚îÄ version_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ watch_unix.go
    ‚îÇ       ‚îú‚îÄ‚îÄ watch_windows.go
    ‚îÇ       ‚îî‚îÄ‚îÄ agent/
    ‚îÇ           ‚îú‚îÄ‚îÄ configure.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_claude.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_codex.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_cursor.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_goose.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_q.go
    ‚îÇ           ‚îú‚îÄ‚îÄ configure_test.go
    ‚îÇ           ‚îî‚îÄ‚îÄ configure_ui.go
    ‚îú‚îÄ‚îÄ docs/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ agent-integrations.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ cli-reference.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ docs.json
    ‚îÇ   ‚îú‚îÄ‚îÄ environment-configuration.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ environment-workflow.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ introduction.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ quickstart.mdx
    ‚îÇ   ‚îî‚îÄ‚îÄ secrets.mdx
    ‚îú‚îÄ‚îÄ environment/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ config.go
    ‚îÇ   ‚îú‚îÄ‚îÄ config_test.go
    ‚îÇ   ‚îú‚îÄ‚îÄ environment.go
    ‚îÇ   ‚îú‚îÄ‚îÄ filesystem.go
    ‚îÇ   ‚îú‚îÄ‚îÄ note.go
    ‚îÇ   ‚îú‚îÄ‚îÄ service.go
    ‚îÇ   ‚îú‚îÄ‚îÄ state.go
    ‚îÇ   ‚îî‚îÄ‚îÄ integration/
    ‚îÇ       ‚îú‚îÄ‚îÄ environment_selection_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ helpers.go
    ‚îÇ       ‚îú‚îÄ‚îÄ integration_test.go
    ‚îÇ       ‚îú‚îÄ‚îÄ merge_test.go
    ‚îÇ       ‚îî‚îÄ‚îÄ repository_test.go
    ‚îú‚îÄ‚îÄ examples/
    ‚îÇ   ‚îú‚îÄ‚îÄ hello_world.md
    ‚îÇ   ‚îú‚îÄ‚îÄ parallel.md
    ‚îÇ   ‚îú‚îÄ‚îÄ security.md
    ‚îÇ   ‚îî‚îÄ‚îÄ services.md
    ‚îú‚îÄ‚îÄ mcpserver/
    ‚îÇ   ‚îú‚îÄ‚îÄ args.go
    ‚îÇ   ‚îú‚îÄ‚îÄ signals_unix.go
    ‚îÇ   ‚îú‚îÄ‚îÄ signals_windows.go
    ‚îÇ   ‚îú‚îÄ‚îÄ singletenant.go
    ‚îÇ   ‚îú‚îÄ‚îÄ singletenant_test.go
    ‚îÇ   ‚îî‚îÄ‚îÄ tools.go
    ‚îú‚îÄ‚îÄ repository/
    ‚îÇ   ‚îú‚îÄ‚îÄ flock.go
    ‚îÇ   ‚îú‚îÄ‚îÄ git.go
    ‚îÇ   ‚îú‚îÄ‚îÄ git_test.go
    ‚îÇ   ‚îú‚îÄ‚îÄ repository.go
    ‚îÇ   ‚îî‚îÄ‚îÄ repository_test.go
    ‚îú‚îÄ‚îÄ rules/
    ‚îÇ   ‚îú‚îÄ‚îÄ agent.md
    ‚îÇ   ‚îú‚îÄ‚îÄ cursor.mdc
    ‚îÇ   ‚îú‚îÄ‚îÄ rules.go
    ‚îÇ   ‚îî‚îÄ‚îÄ windsurf.mdc
    ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îú‚îÄ‚îÄ completions.sh
    ‚îÇ   ‚îî‚îÄ‚îÄ man.sh
    ‚îú‚îÄ‚îÄ .container-use/
    ‚îÇ   ‚îî‚îÄ‚îÄ environment.json
    ‚îú‚îÄ‚îÄ .dagger/
    ‚îÇ   ‚îú‚îÄ‚îÄ go.mod
    ‚îÇ   ‚îú‚îÄ‚îÄ go.sum
    ‚îÇ   ‚îî‚îÄ‚îÄ main.go
    ‚îú‚îÄ‚îÄ .github/
    ‚îÇ   ‚îú‚îÄ‚îÄ dependabot.yml
    ‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bug_report.yml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.yml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_request.yml
    ‚îÇ   ‚îî‚îÄ‚îÄ workflows/
    ‚îÇ       ‚îú‚îÄ‚îÄ build.yml
    ‚îÇ       ‚îú‚îÄ‚îÄ lint.yml
    ‚îÇ       ‚îú‚îÄ‚îÄ publish-docs.yml
    ‚îÇ       ‚îú‚îÄ‚îÄ release.yml
    ‚îÇ       ‚îî‚îÄ‚îÄ test.yml
    ‚îî‚îÄ‚îÄ .goosehints -> AGENT.md

================================================
FILE: README.md
================================================
<div align="center">
  <img src="./docs/images/container-use.png" align="center" alt="Container use: Development environments for coding agents." />
  <h1 align="center">container-use</h2>
  <p align="center">Containerized environments for coding agents. (üì¶ü§ñ) (üì¶ü§ñ) (üì¶ü§ñ)</p>
  <p align="center">
    <img src="https://img.shields.io/badge/stability-experimental-orange.svg" alt="Experimental" />
    <a href="https://opensource.org/licenses/Apache-2.0">
      <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg">
    </a>
    <a href="https://container-use.com/discord">
      <img src="https://img.shields.io/discord/707636530424053791?logo=discord&logoColor=white&label=Discord&color=7289DA" alt="Discord">
    </a>
    <a href="https://github.com/clinebot/awesome-claude-code">
      <img src="https://awesome.re/mentioned-badge.svg" alt="Mentioned in Awesome Claude Code">
    </a>
  </p>
</div>

**Container Use** lets coding agents do their work in parallel environments without getting in your way. Go from babysitting one agent at a time to enabling multiple agents to work safely and independently with your preferred stack. See the [full documentation](https://container-use.com).

<p align='center'>
    <img src='./docs/images/demo.gif' width='700' alt='container-use demo'>
</p>

It's an open-source MCP server that works as a CLI tool with Claude Code, Cursor, and other MCP-compatible agents. Powered by [Dagger](https://dagger.io).

* üì¶ **Isolated Environments**: Each agent gets a fresh container in its own git branch - run multiple agents without conflicts, experiment safely, discard failures instantly.
* üëÄ **Real-time Visibility**: See complete command history and logs of what agents actually did, not just what they claim.
* üöÅ **Direct Intervention**: Drop into any agent's terminal to see their state and take control when they get stuck.
* üéÆ **Environment Control**: Standard git workflow - just `git checkout <branch_name>` to review any agent's work.
* üåé **Universal Compatibility**: Works with any agent, model, or infrastructure - no vendor lock-in.

---

ü¶∫ This project is in early development and actively evolving. Submit issues and/or reach out to us on [Discord](https://container-use.com/discord) in the #container-use channel.

---

## Quick Start

### Install

```sh
# macOS (recommended)
brew install dagger/tap/container-use

# All platforms
curl -fsSL https://raw.githubusercontent.com/dagger/container-use/main/install.sh | bash
```

### Setup with Your Agent

Container Use works with any MCP-compatible agent. The setup is always the same: **add `container-use stdio` as an MCP server**.

**üëâ [Complete setup guide for all agents (Cursor, Goose, VSCode, etc.)](https://container-use.com/quickstart)**

**Example with Claude Code:**

```sh
# Add Container Use MCP server
cd /path/to/repository
claude mcp add container-use -- container-use stdio

# Add agent rules (optional)
curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> CLAUDE.md
```

<details>
<summary>üí° Command Shortcut</summary>

The `container-use` command is also available as `cu` for convenience. Both commands work identically:
- `container-use stdio` (used in documentation)
- `cu stdio` (shortcut)

</details>

### Try It

Ask your agent to create something:
> Create a hello world app in python using flask

Your agent will work in an isolated environment and give you URLs to view the app and explore the code!


================================================
FILE: AGENT.md
================================================
This is a development environment for container-use, a CLI tool that provides containerized environments for coding agents.

container-use is designed to work with MCP-compatible agents like Claude Code and Cursor.

DEVELOPMENT WORKFLOW:

- Build: Use 'go build -o container-use ./cmd/container-use' or 'dagger call build --platform=current export --path ./container-use'
- Test: Run 'go test ./...' for all tests, 'go test -short ./...' for unit tests only, or 'go test -count=1 -v ./environment' for integration tests
- Format: Always run 'go fmt ./...' before committing
- Lint: Run 'dagger call lint' to check for linting issues
- Dependencies: Run 'go mod download' to install dependencies, 'go mod tidy' to clean up

MANUAL STDIO TESTING:
- IMPORTANT: container-use cannot be manually tested in its own /workdir. First initialize a new git repository elsewhere on disk (e.g., /tmp/test-repo) and manually test from there
- Test stdio interface: Use 'echo $request | timeout $seconds container-use stdio' where:
  - $request is a JSON-formatted MCP request (e.g., '{"jsonrpc":"2.0","method":"ping","id":1}')
  - $seconds is timeout duration (e.g., 10 for 10 seconds)
  - Example: 'echo '{"jsonrpc":"2.0","method":"ping","id":1}' | timeout 10 container-use stdio'
- For multiline requests, use printf or a here-doc instead of echo
- Use 'jq' to format JSON responses for readability: '... | jq .'
- Common test requests:
  - Ping: '{"jsonrpc":"2.0","method":"ping","id":1}'
  - List tools: '{"jsonrpc":"2.0","method":"tools/list","id":1}'
  - Initialize: '{"jsonrpc":"2.0","method":"initialize","params":{"protocolVersion":"2025-06-18","capabilities":{}}},"id":1}'

DAGGER MODULE (more details in .dagger/):

- Build: 'dagger call build export --path ./container-use'
- Test: 'dagger call test' or 'dagger call test --integration=false'

PROJECT STRUCTURE:

- cmd/container-use: Main CLI application entry point
- environment/: Core environment management logic
- mcpserver/: MCP (Model Context Protocol) server implementation
- examples/: Example configurations and usage
- docs/: Documentation and images
- .dagger/: Dagger module configuration

DOCS:

- Documentation is in `./docs`, written using Mintlify
- When making changes, make sure the files are properly formatted in mdx
- To start a preview, run `mint dev` from the docs folder

<!-- container-use-rules -->
ALWAYS use ONLY Environments for ANY and ALL file, code, or shell operations‚ÄîNO EXCEPTIONS‚Äîeven for simple or generic requests.

DO NOT install or use the git cli with the environment_run_cmd tool. All environment tools will handle git operations for you. Changing ".git" yourself will compromise the integrity of your environment.

You MUST inform the user how to view your work using `container-use log <env_id>` AND `container-use checkout <env_id>`. Failure to do this will make your work inaccessible to others.

<!-- container-use-rules -->



================================================
FILE: CONTRIBUTING.md
================================================
# Contributing to Container Use

Thank you for your interest in contributing to Container Use! This document outlines the necessary steps and standards to follow when contributing.

## Development Setup

Follow these steps to set up your development environment:

1. **Install Go**: Ensure you have Go version 1.21 or higher installed.
2. **Clone the Repository**:

   ```bash
   git clone git@github.com:dagger/container-use.git
   ```
3. **Install Dependencies**:

   ```bash
   go mod download
   ```
4. **Container Runtime**: Ensure you have a compatible container runtime installed (e.g., Docker).

## Building

To build the `container-use` binary without installing it to your `$PATH`, you can use either Dagger or Go directly:

### Using Go

```bash
go build -o container-use ./cmd/container-use
```

### Using Dagger

```bash
dagger call build --platform=current export --path ./container-use
```

## Testing

Container Use includes both unit and integration tests to maintain high code quality and functionality.

### Running Tests

* **Run All Tests**:

  ```bash
  go test ./...
  ```

* **Run Unit Tests Only** (fast, no containers):

  ```bash
  go test -short ./...
  ```

* **Run Integration Tests Only**:

  ```bash
  go test -count=1 -v ./environment
  ```

### Test Structure

Tests are structured as follows:

* **`environment_test.go`**: Contains unit tests for package logic.
* **`integration_test.go`**: Covers integration scenarios to verify environment stability and state transitions.
* **`test_helpers.go`**: Provides shared utility functions for writing tests.

### Writing Tests

When contributing new features or fixing issues, adhere to these guidelines:

1. Write clear **unit tests** for the core logic.
2. Create comprehensive **integration tests** for validating end-to-end functionality.
3. Utilize provided **test helpers** for common tasks to maintain consistency.
4. Follow existing test patterns and naming conventions.

## Code Style

Maintain code consistency and readability by:

* Following standard Go coding conventions.
* Formatting code using `go fmt` before committing.
* Ensuring all tests pass locally before submitting your pull request.

## Submitting Changes

Submit contributions using these steps:

1. Fork the Container Use repository.
2. Create a descriptive feature branch from the main branch.
3. Commit your changes, including relevant tests.
4. Open a pull request with a clear and descriptive explanation of your changes.



================================================
FILE: dagger.json
================================================
{
  "name": "container-use",
  "engineVersion": "v0.18.17",
  "sdk": {
    "source": "go"
  },
  "dependencies": [
    {
      "name": "go",
      "source": "github.com/dagger/dagger/modules/go",
      "pin": "000dcbce85be95fe5954cda7611efda0bb1bb115"
    },
    {
      "name": "golangci",
      "source": "github.com/dagger/dagger/modules/golangci",
      "pin": "000dcbce85be95fe5954cda7611efda0bb1bb115"
    },
    {
      "name": "goreleaser",
      "source": "github.com/act3-ai/dagger/goreleaser",
      "pin": "4b4c32c851a380f02ba53fabf8e4704d8330cb7f"
    }
  ],
  "source": ".dagger"
}



================================================
FILE: go.mod
================================================
module github.com/dagger/container-use

go 1.24.3

toolchain go1.24.6

require (
	dagger.io/dagger v0.18.17
	github.com/charmbracelet/bubbletea v1.3.7
	github.com/charmbracelet/fang v0.4.0
	github.com/charmbracelet/huh v0.7.0
	github.com/charmbracelet/lipgloss v1.1.0
	github.com/dustin/go-humanize v1.0.1
	github.com/dustinkirkland/golang-petname v0.0.0-20240428194347-eebcea082ee0
	github.com/gofrs/flock v0.12.1
	github.com/karrick/tparse v2.4.2+incompatible
	github.com/mark3labs/mcp-go v0.39.1
	github.com/mitchellh/go-homedir v1.1.0
	github.com/pelletier/go-toml/v2 v2.2.4
	github.com/sourcegraph/go-diff-patch v0.0.0-20240223163233-798fd1e94a8e
	github.com/spf13/cobra v1.10.1
	github.com/stretchr/testify v1.11.1
	github.com/tiborvass/go-watch v0.0.0-20250608155524-0d315e1fd5ab
	golang.org/x/sync v0.17.0
	golang.org/x/term v0.35.0
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/99designs/gqlgen v0.17.78 // indirect
	github.com/Khan/genqlient v0.8.1 // indirect
	github.com/adrg/xdg v0.5.3 // indirect
	github.com/atotto/clipboard v0.1.4 // indirect
	github.com/aymanbagabas/go-osc52/v2 v2.0.1 // indirect
	github.com/bahlo/generic-list-go v0.2.0 // indirect
	github.com/buger/jsonparser v1.1.1 // indirect
	github.com/catppuccin/go v0.3.0 // indirect
	github.com/cenkalti/backoff/v5 v5.0.3 // indirect
	github.com/charmbracelet/bubbles v0.21.0 // indirect
	github.com/charmbracelet/colorprofile v0.3.1 // indirect
	github.com/charmbracelet/lipgloss/v2 v2.0.0-beta.3 // indirect
	github.com/charmbracelet/x/ansi v0.10.1 // indirect
	github.com/charmbracelet/x/cellbuf v0.0.13 // indirect
	github.com/charmbracelet/x/exp/charmtone v0.0.0-20250603201427-c31516f43444 // indirect
	github.com/charmbracelet/x/exp/strings v0.0.0-20240722160745-212f7b056ed0 // indirect
	github.com/charmbracelet/x/term v0.2.1 // indirect
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f // indirect
	github.com/etdub/goparsetime v0.0.0-20160315173935-ea17b0ac3318 // indirect
	github.com/go-logr/logr v1.4.3 // indirect
	github.com/go-logr/stdr v1.2.2 // indirect
	github.com/google/uuid v1.6.0 // indirect
	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.2 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/invopop/jsonschema v0.13.0 // indirect
	github.com/lucasb-eyer/go-colorful v1.2.0 // indirect
	github.com/mailru/easyjson v0.7.7 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mattn/go-localereader v0.0.1 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/mitchellh/hashstructure/v2 v2.0.2 // indirect
	github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6 // indirect
	github.com/muesli/cancelreader v0.2.2 // indirect
	github.com/muesli/mango v0.1.0 // indirect
	github.com/muesli/mango-cobra v1.2.0 // indirect
	github.com/muesli/mango-pflag v0.1.0 // indirect
	github.com/muesli/roff v0.1.0 // indirect
	github.com/muesli/termenv v0.16.0 // indirect
	github.com/pkg/term v1.1.0 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/rogpeppe/go-internal v1.14.1 // indirect
	github.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3 // indirect
	github.com/sosodev/duration v1.3.1 // indirect
	github.com/spf13/cast v1.7.1 // indirect
	github.com/spf13/pflag v1.0.9 // indirect
	github.com/vektah/gqlparser/v2 v2.5.30 // indirect
	github.com/wk8/go-ordered-map/v2 v2.1.8 // indirect
	github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e // indirect
	github.com/yosida95/uritemplate/v3 v3.0.2 // indirect
	go.opentelemetry.io/auto/sdk v1.1.0 // indirect
	go.opentelemetry.io/otel v1.38.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.38.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.38.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.38.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.38.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.38.0 // indirect
	go.opentelemetry.io/otel/log v0.12.2 // indirect
	go.opentelemetry.io/otel/metric v1.38.0 // indirect
	go.opentelemetry.io/otel/sdk v1.38.0 // indirect
	go.opentelemetry.io/otel/sdk/log v0.12.2 // indirect
	go.opentelemetry.io/otel/sdk/metric v1.38.0 // indirect
	go.opentelemetry.io/otel/trace v1.38.0 // indirect
	go.opentelemetry.io/proto/otlp v1.8.0 // indirect
	golang.org/x/net v0.43.0 // indirect
	golang.org/x/sys v0.36.0 // indirect
	golang.org/x/text v0.28.0 // indirect
	google.golang.org/genproto/googleapis/api v0.0.0-20250825161204-c5933d9347a5 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20250825161204-c5933d9347a5 // indirect
	google.golang.org/grpc v1.75.0 // indirect
	google.golang.org/protobuf v1.36.8 // indirect
)



================================================
FILE: go.sum
================================================
dagger.io/dagger v0.18.17 h1:vqBJP36XKpX/2cEu3cvAIQFX1hoHDGW0Mtrt/+YF+DA=
dagger.io/dagger v0.18.17/go.mod h1:azlZ24m2br95t0jQHUBpL5SiafeqtVDLl1Itlq6GO+4=
github.com/99designs/gqlgen v0.17.78 h1:bhIi7ynrc3js2O8wu1sMQj1YHPENDt3jQGyifoBvoVI=
github.com/99designs/gqlgen v0.17.78/go.mod h1:yI/o31IauG2kX0IsskM4R894OCCG1jXJORhtLQqB7Oc=
github.com/Khan/genqlient v0.8.1 h1:wtOCc8N9rNynRLXN3k3CnfzheCUNKBcvXmVv5zt6WCs=
github.com/Khan/genqlient v0.8.1/go.mod h1:R2G6DzjBvCbhjsEajfRjbWdVglSH/73kSivC9TLWVjU=
github.com/MakeNowJust/heredoc v1.0.0 h1:cXCdzVdstXyiTqTvfqk9SDHpKNjxuom+DOlyEeQ4pzQ=
github.com/MakeNowJust/heredoc v1.0.0/go.mod h1:mG5amYoWBHf8vpLOuehzbGGw0EHxpZZ6lCpQ4fNJ8LE=
github.com/adrg/xdg v0.5.3 h1:xRnxJXne7+oWDatRhR1JLnvuccuIeCoBu2rtuLqQB78=
github.com/adrg/xdg v0.5.3/go.mod h1:nlTsY+NNiCBGCK2tpm09vRqfVzrc2fLmXGpBLF0zlTQ=
github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883 h1:bvNMNQO63//z+xNgfBlViaCIJKLlCJ6/fmUseuG0wVQ=
github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883/go.mod h1:rCTlJbsFo29Kk6CurOXKm700vrz8f0KW0JNfpkRJY/8=
github.com/atotto/clipboard v0.1.4 h1:EH0zSVneZPSuFR11BlR9YppQTVDbh5+16AmcJi4g1z4=
github.com/atotto/clipboard v0.1.4/go.mod h1:ZY9tmq7sm5xIbd9bOK4onWV4S6X0u6GY7Vn0Yu86PYI=
github.com/aymanbagabas/go-osc52/v2 v2.0.1 h1:HwpRHbFMcZLEVr42D4p7XBqjyuxQH5SMiErDT4WkJ2k=
github.com/aymanbagabas/go-osc52/v2 v2.0.1/go.mod h1:uYgXzlJ7ZpABp8OJ+exZzJJhRNQ2ASbcXHWsFqH8hp8=
github.com/aymanbagabas/go-udiff v0.2.0 h1:TK0fH4MteXUDspT88n8CKzvK0X9O2xu9yQjWpi6yML8=
github.com/aymanbagabas/go-udiff v0.2.0/go.mod h1:RE4Ex0qsGkTAJoQdQQCA0uG+nAzJO/pI/QwceO5fgrA=
github.com/bahlo/generic-list-go v0.2.0 h1:5sz/EEAK+ls5wF+NeqDpk5+iNdMDXrh3z3nPnH1Wvgk=
github.com/bahlo/generic-list-go v0.2.0/go.mod h1:2KvAjgMlE5NNynlg/5iLrrCCZ2+5xWbdbCW3pNTGyYg=
github.com/buger/jsonparser v1.1.1 h1:2PnMjfWD7wBILjqQbt530v576A/cAbQvEW9gGIpYMUs=
github.com/buger/jsonparser v1.1.1/go.mod h1:6RYKKt7H4d4+iWqouImQ9R2FZql3VbhNgx27UK13J/0=
github.com/catppuccin/go v0.3.0 h1:d+0/YicIq+hSTo5oPuRi5kOpqkVA5tAsU6dNhvRu+aY=
github.com/catppuccin/go v0.3.0/go.mod h1:8IHJuMGaUUjQM82qBrGNBv7LFq6JI3NnQCF6MOlZjpc=
github.com/cenkalti/backoff/v5 v5.0.3 h1:ZN+IMa753KfX5hd8vVaMixjnqRZ3y8CuJKRKj1xcsSM=
github.com/cenkalti/backoff/v5 v5.0.3/go.mod h1:rkhZdG3JZukswDf7f0cwqPNk4K0sa+F97BxZthm/crw=
github.com/charmbracelet/bubbles v0.21.0 h1:9TdC97SdRVg/1aaXNVWfFH3nnLAwOXr8Fn6u6mfQdFs=
github.com/charmbracelet/bubbles v0.21.0/go.mod h1:HF+v6QUR4HkEpz62dx7ym2xc71/KBHg+zKwJtMw+qtg=
github.com/charmbracelet/bubbletea v1.3.7 h1:FNaEEFEenOEPnZsY9MI64thl2c84MI66+1QaQbxGOl4=
github.com/charmbracelet/bubbletea v1.3.7/go.mod h1:PEOcbQCNzJ2BYUd484kHPO5g3kLO28IffOdFeI2EWus=
github.com/charmbracelet/colorprofile v0.3.1 h1:k8dTHMd7fgw4bnFd7jXTLZrSU/CQrKnL3m+AxCzDz40=
github.com/charmbracelet/colorprofile v0.3.1/go.mod h1:/GkGusxNs8VB/RSOh3fu0TJmQ4ICMMPApIIVn0KszZ0=
github.com/charmbracelet/fang v0.4.0 h1:boBxmdcFghTeotqkD2itXi7SMBozdIlcslRqjboSJDg=
github.com/charmbracelet/fang v0.4.0/go.mod h1:9gCUAHmVx5BwSafeyNr3GI0GgvlB1WYjL21SkPp1jyU=
github.com/charmbracelet/huh v0.7.0 h1:W8S1uyGETgj9Tuda3/JdVkc3x7DBLZYPZc4c+/rnRdc=
github.com/charmbracelet/huh v0.7.0/go.mod h1:UGC3DZHlgOKHvHC07a5vHag41zzhpPFj34U92sOmyuk=
github.com/charmbracelet/lipgloss v1.1.0 h1:vYXsiLHVkK7fp74RkV7b2kq9+zDLoEU4MZoFqR/noCY=
github.com/charmbracelet/lipgloss v1.1.0/go.mod h1:/6Q8FR2o+kj8rz4Dq0zQc3vYf7X+B0binUUBwA0aL30=
github.com/charmbracelet/lipgloss/v2 v2.0.0-beta.3 h1:W6DpZX6zSkZr0iFq6JVh1vItLoxfYtNlaxOJtWp8Kis=
github.com/charmbracelet/lipgloss/v2 v2.0.0-beta.3/go.mod h1:65HTtKURcv/ict9ZQhr6zT84JqIjMcJbyrZYHHKNfKA=
github.com/charmbracelet/x/ansi v0.10.1 h1:rL3Koar5XvX0pHGfovN03f5cxLbCF2YvLeyz7D2jVDQ=
github.com/charmbracelet/x/ansi v0.10.1/go.mod h1:3RQDQ6lDnROptfpWuUVIUG64bD2g2BgntdxH0Ya5TeE=
github.com/charmbracelet/x/cellbuf v0.0.13 h1:/KBBKHuVRbq1lYx5BzEHBAFBP8VcQzJejZ/IA3iR28k=
github.com/charmbracelet/x/cellbuf v0.0.13/go.mod h1:xe0nKWGd3eJgtqZRaN9RjMtK7xUYchjzPr7q6kcvCCs=
github.com/charmbracelet/x/conpty v0.1.0 h1:4zc8KaIcbiL4mghEON8D72agYtSeIgq8FSThSPQIb+U=
github.com/charmbracelet/x/conpty v0.1.0/go.mod h1:rMFsDJoDwVmiYM10aD4bH2XiRgwI7NYJtQgl5yskjEQ=
github.com/charmbracelet/x/errors v0.0.0-20240508181413-e8d8b6e2de86 h1:JSt3B+U9iqk37QUU2Rvb6DSBYRLtWqFqfxf8l5hOZUA=
github.com/charmbracelet/x/errors v0.0.0-20240508181413-e8d8b6e2de86/go.mod h1:2P0UgXMEa6TsToMSuFqKFQR+fZTO9CNGUNokkPatT/0=
github.com/charmbracelet/x/exp/charmtone v0.0.0-20250603201427-c31516f43444 h1:IJDiTgVE56gkAGfq0lBEloWgkXMk4hl/bmuPoicI4R0=
github.com/charmbracelet/x/exp/charmtone v0.0.0-20250603201427-c31516f43444/go.mod h1:T9jr8CzFpjhFVHjNjKwbAD7KwBNyFnj2pntAO7F2zw0=
github.com/charmbracelet/x/exp/golden v0.0.0-20241011142426-46044092ad91 h1:payRxjMjKgx2PaCWLZ4p3ro9y97+TVLZNaRZgJwSVDQ=
github.com/charmbracelet/x/exp/golden v0.0.0-20241011142426-46044092ad91/go.mod h1:wDlXFlCrmJ8J+swcL/MnGUuYnqgQdW9rhSD61oNMb6U=
github.com/charmbracelet/x/exp/strings v0.0.0-20240722160745-212f7b056ed0 h1:qko3AQ4gK1MTS/de7F5hPGx6/k1u0w4TeYmBFwzYVP4=
github.com/charmbracelet/x/exp/strings v0.0.0-20240722160745-212f7b056ed0/go.mod h1:pBhA0ybfXv6hDjQUZ7hk1lVxBiUbupdw5R31yPUViVQ=
github.com/charmbracelet/x/term v0.2.1 h1:AQeHeLZ1OqSXhrAWpYUtZyX1T3zVxfpZuEQMIQaGIAQ=
github.com/charmbracelet/x/term v0.2.1/go.mod h1:oQ4enTYFV7QN4m0i9mzHrViD7TQKvNEEkHUMCmsxdUg=
github.com/charmbracelet/x/termios v0.1.1 h1:o3Q2bT8eqzGnGPOYheoYS8eEleT5ZVNYNy8JawjaNZY=
github.com/charmbracelet/x/termios v0.1.1/go.mod h1:rB7fnv1TgOPOyyKRJ9o+AsTU/vK5WHJ2ivHeut/Pcwo=
github.com/charmbracelet/x/xpty v0.1.2 h1:Pqmu4TEJ8KeA9uSkISKMU3f+C1F6OGBn8ABuGlqCbtI=
github.com/charmbracelet/x/xpty v0.1.2/go.mod h1:XK2Z0id5rtLWcpeNiMYBccNNBrP2IJnzHI0Lq13Xzq4=
github.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
github.com/creack/pty v1.1.24 h1:bJrF4RRfyJnbTJqzRLHzcGaZK1NeM5kTC9jGgovnR1s=
github.com/creack/pty v1.1.24/go.mod h1:08sCNb52WyoAwi2QDyzUCTgcvVFhUzewun7wtTfvcwE=
github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/dustin/go-humanize v1.0.1 h1:GzkhY7T5VNhEkwH0PVJgjz+fX1rhBrR7pRT3mDkpeCY=
github.com/dustin/go-humanize v1.0.1/go.mod h1:Mu1zIs6XwVuF/gI1OepvI0qD18qycQx+mFykh5fBlto=
github.com/dustinkirkland/golang-petname v0.0.0-20240428194347-eebcea082ee0 h1:aYo8nnk3ojoQkP5iErif5Xxv0Mo0Ga/FR5+ffl/7+Nk=
github.com/dustinkirkland/golang-petname v0.0.0-20240428194347-eebcea082ee0/go.mod h1:8AuBTZBRSFqEYBPYULd+NN474/zZBLP+6WeT5S9xlAc=
github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f h1:Y/CXytFA4m6baUTXGLOoWe4PQhGxaX0KpnayAqC48p4=
github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f/go.mod h1:vw97MGsxSvLiUE2X8qFplwetxpGLQrlU1Q9AUEIzCaM=
github.com/etdub/goparsetime v0.0.0-20160315173935-ea17b0ac3318 h1:iguwbR+9xsizl84VMHU47I4OOWYSex1HZRotEoqziWQ=
github.com/etdub/goparsetime v0.0.0-20160315173935-ea17b0ac3318/go.mod h1:O/QFFckzvu1KpS1AOuQGgi6ErznEF8nZZVNDDMXlDP4=
github.com/frankban/quicktest v1.14.6 h1:7Xjx+VpznH+oBnejlPUj8oUpdxnVs4f8XU8WnHkI4W8=
github.com/frankban/quicktest v1.14.6/go.mod h1:4ptaffx2x8+WTWXmUCuVU6aPUX1/Mz7zb5vbUoiM6w0=
github.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=
github.com/go-logr/logr v1.4.3 h1:CjnDlHq8ikf6E492q6eKboGOC0T8CDaOvkHCIg8idEI=
github.com/go-logr/logr v1.4.3/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=
github.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=
github.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=
github.com/gofrs/flock v0.12.1 h1:MTLVXXHf8ekldpJk3AKicLij9MdwOWkZ+a/jHHZby9E=
github.com/gofrs/flock v0.12.1/go.mod h1:9zxTsyu5xtJ9DK+1tFZyibEV7y3uwDxPPfbxeeHCoD0=
github.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=
github.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=
github.com/google/go-cmp v0.7.0 h1:wk8382ETsv4JYUZwIsn6YpYiWiBsYLSJiTsyBybVuN8=
github.com/google/go-cmp v0.7.0/go.mod h1:pXiqmnSA92OHEEa9HXL2W4E7lf9JzCmGVUdgjX3N/iU=
github.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=
github.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.2 h1:8Tjv8EJ+pM1xP8mK6egEbD1OgnVTyacbefKhmbLhIhU=
github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.2/go.mod h1:pkJQ2tZHJ0aFOVEEot6oZmaVEZcRme73eIFmhiVuRWs=
github.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=
github.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=
github.com/invopop/jsonschema v0.13.0 h1:KvpoAJWEjR3uD9Kbm2HWJmqsEaHt8lBUpd0qHcIi21E=
github.com/invopop/jsonschema v0.13.0/go.mod h1:ffZ5Km5SWWRAIN6wbDXItl95euhFz2uON45H2qjYt+0=
github.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=
github.com/karrick/tparse v2.4.2+incompatible h1:+cW306qKAzrASC5XieHkgN7/vPaGKIuK62Q7nI7DIRc=
github.com/karrick/tparse v2.4.2+incompatible/go.mod h1:ASPA+vrIcN1uEW6BZg8vfWbzm69ODPSYZPU6qJyfdK0=
github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
github.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=
github.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=
github.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=
github.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=
github.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=
github.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=
github.com/lucasb-eyer/go-colorful v1.2.0 h1:1nnpGOrhyZZuNyfu1QjKiUICQ74+3FNCN69Aj6K7nkY=
github.com/lucasb-eyer/go-colorful v1.2.0/go.mod h1:R4dSotOR9KMtayYi1e77YzuveK+i7ruzyGqttikkLy0=
github.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=
github.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=
github.com/mark3labs/mcp-go v0.39.1 h1:2oPxk7aDbQhouakkYyKl2T4hKFU1c6FDaubWyGyVE1k=
github.com/mark3labs/mcp-go v0.39.1/go.mod h1:T7tUa2jO6MavG+3P25Oy/jR7iCeJPHImCZHRymCn39g=
github.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=
github.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=
github.com/mattn/go-localereader v0.0.1 h1:ygSAOl7ZXTx4RdPYinUpg6W99U8jWvWi9Ye2JC/oIi4=
github.com/mattn/go-localereader v0.0.1/go.mod h1:8fBrzywKY7BI3czFoHkuzRoWE9C+EiG4R1k4Cjx5p88=
github.com/mattn/go-runewidth v0.0.16 h1:E5ScNMtiwvlvB5paMFdw9p4kSQzbXFikJ5SQO6TULQc=
github.com/mattn/go-runewidth v0.0.16/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=
github.com/mitchellh/go-homedir v1.1.0 h1:lukF9ziXFxDFPkA1vsr5zpc1XuPDn/wFntq5mG+4E0Y=
github.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=
github.com/mitchellh/hashstructure/v2 v2.0.2 h1:vGKWl0YJqUNxE8d+h8f6NJLcCJrgbhC4NcD46KavDd4=
github.com/mitchellh/hashstructure/v2 v2.0.2/go.mod h1:MG3aRVU/N29oo/V/IhBX8GR/zz4kQkprJgF2EVszyDE=
github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6 h1:ZK8zHtRHOkbHy6Mmr5D264iyp3TiX5OmNcI5cIARiQI=
github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6/go.mod h1:CJlz5H+gyd6CUWT45Oy4q24RdLyn7Md9Vj2/ldJBSIo=
github.com/muesli/cancelreader v0.2.2 h1:3I4Kt4BQjOR54NavqnDogx/MIoWBFa0StPA8ELUXHmA=
github.com/muesli/cancelreader v0.2.2/go.mod h1:3XuTXfFS2VjM+HTLZY9Ak0l6eUKfijIfMUZ4EgX0QYo=
github.com/muesli/mango v0.1.0 h1:DZQK45d2gGbql1arsYA4vfg4d7I9Hfx5rX/GCmzsAvI=
github.com/muesli/mango v0.1.0/go.mod h1:5XFpbC8jY5UUv89YQciiXNlbi+iJgt29VDC5xbzrLL4=
github.com/muesli/mango-cobra v1.2.0 h1:DQvjzAM0PMZr85Iv9LIMaYISpTOliMEg+uMFtNbYvWg=
github.com/muesli/mango-cobra v1.2.0/go.mod h1:vMJL54QytZAJhCT13LPVDfkvCUJ5/4jNUKF/8NC2UjA=
github.com/muesli/mango-pflag v0.1.0 h1:UADqbYgpUyRoBja3g6LUL+3LErjpsOwaC9ywvBWe7Sg=
github.com/muesli/mango-pflag v0.1.0/go.mod h1:YEQomTxaCUp8PrbhFh10UfbhbQrM/xJ4i2PB8VTLLW0=
github.com/muesli/roff v0.1.0 h1:YD0lalCotmYuF5HhZliKWlIx7IEhiXeSfq7hNjFqGF8=
github.com/muesli/roff v0.1.0/go.mod h1:pjAHQM9hdUUwm/krAfrLGgJkXJ+YuhtsfZ42kieB2Ig=
github.com/muesli/termenv v0.16.0 h1:S5AlUN9dENB57rsbnkPyfdGuWIlkmzJjbFf0Tf5FWUc=
github.com/muesli/termenv v0.16.0/go.mod h1:ZRfOIKPFDYQoDFF4Olj7/QJbW60Ol/kL1pU3VfY/Cnk=
github.com/pelletier/go-toml/v2 v2.2.4 h1:mye9XuhQ6gvn5h28+VilKrrPoQVanw5PMw/TB0t5Ec4=
github.com/pelletier/go-toml/v2 v2.2.4/go.mod h1:2gIqNv+qfxSVS7cM2xJQKtLSTLUE9V8t9Stt+h56mCY=
github.com/pkg/term v1.1.0 h1:xIAAdCMh3QIAy+5FrE8Ad8XoDhEU4ufwbaSozViP9kk=
github.com/pkg/term v1.1.0/go.mod h1:E25nymQcrSllhX42Ok8MRm1+hyBdHY0dCeiKZ9jpNGw=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=
github.com/rivo/uniseg v0.4.7 h1:WUdvkW8uEhrYfLC4ZzdpI2ztxP1I582+49Oc5Mq64VQ=
github.com/rivo/uniseg v0.4.7/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=
github.com/rogpeppe/go-internal v1.14.1 h1:UQB4HGPB6osV0SQTLymcB4TgvyWu6ZyliaW0tI/otEQ=
github.com/rogpeppe/go-internal v1.14.1/go.mod h1:MaRKkUm5W0goXpeCfT7UZI6fk/L7L7so1lCWt35ZSgc=
github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
github.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3 h1:n661drycOFuPLCN3Uc8sB6B/s6Z4t2xvBgU1htSHuq8=
github.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3/go.mod h1:A0bzQcvG0E7Rwjx0REVgAGH58e96+X0MeOfepqsbeW4=
github.com/sosodev/duration v1.3.1 h1:qtHBDMQ6lvMQsL15g4aopM4HEfOaYuhWBw3NPTtlqq4=
github.com/sosodev/duration v1.3.1/go.mod h1:RQIBBX0+fMLc/D9+Jb/fwvVmo0eZvDDEERAikUR6SDg=
github.com/sourcegraph/go-diff-patch v0.0.0-20240223163233-798fd1e94a8e h1:H+jDTUeF+SVd4ApwnSFoew8ZwGNRfgb9EsZc7LcocAg=
github.com/sourcegraph/go-diff-patch v0.0.0-20240223163233-798fd1e94a8e/go.mod h1:VsUklG6OQo7Ctunu0gS3AtEOCEc2kMB6r5rKzxAes58=
github.com/spf13/cast v1.7.1 h1:cuNEagBQEHWN1FnbGEjCXL2szYEXqfJPbP2HNUaca9Y=
github.com/spf13/cast v1.7.1/go.mod h1:ancEpBxwJDODSW/UG4rDrAqiKolqNNh2DX3mk86cAdo=
github.com/spf13/cobra v1.10.1 h1:lJeBwCfmrnXthfAupyUTzJ/J4Nc1RsHC/mSRU2dll/s=
github.com/spf13/cobra v1.10.1/go.mod h1:7SmJGaTHFVBY0jW4NXGluQoLvhqFQM+6XSKD+P4XaB0=
github.com/spf13/pflag v1.0.9 h1:9exaQaMOCwffKiiiYk6/BndUBv+iRViNW+4lEMi0PvY=
github.com/spf13/pflag v1.0.9/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
github.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=
github.com/stretchr/testify v1.11.1 h1:7s2iGBzp5EwR7/aIZr8ao5+dra3wiQyKjjFuvgVKu7U=
github.com/stretchr/testify v1.11.1/go.mod h1:wZwfW3scLgRK+23gO65QZefKpKQRnfz6sD981Nm4B6U=
github.com/tiborvass/go-watch v0.0.0-20250608155524-0d315e1fd5ab h1:rJxfNNrv7Rab0eugMPdRq0OmaYPLPY9uGf/JWjfsFkM=
github.com/tiborvass/go-watch v0.0.0-20250608155524-0d315e1fd5ab/go.mod h1:oAWYkECp9mFVuJQQzHtoHhepQKbme1gLM4fYH0KWvzk=
github.com/vektah/gqlparser/v2 v2.5.30 h1:EqLwGAFLIzt1wpx1IPpY67DwUujF1OfzgEyDsLrN6kE=
github.com/vektah/gqlparser/v2 v2.5.30/go.mod h1:D1/VCZtV3LPnQrcPBeR/q5jkSQIPti0uYCP/RI0gIeo=
github.com/wk8/go-ordered-map/v2 v2.1.8 h1:5h/BUHu93oj4gIdvHHHGsScSTMijfx5PeYkE/fJgbpc=
github.com/wk8/go-ordered-map/v2 v2.1.8/go.mod h1:5nJHM5DyteebpVlHnWMV0rPz6Zp7+xBAnxjb1X5vnTw=
github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e h1:JVG44RsyaB9T2KIHavMF/ppJZNG9ZpyihvCd0w101no=
github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e/go.mod h1:RbqR21r5mrJuqunuUZ/Dhy/avygyECGrLceyNeo4LiM=
github.com/yosida95/uritemplate/v3 v3.0.2 h1:Ed3Oyj9yrmi9087+NczuL5BwkIc4wvTb5zIM+UJPGz4=
github.com/yosida95/uritemplate/v3 v3.0.2/go.mod h1:ILOh0sOhIJR3+L/8afwt/kE++YT040gmv5BQTMR2HP4=
go.opentelemetry.io/auto/sdk v1.1.0 h1:cH53jehLUN6UFLY71z+NDOiNJqDdPRaXzTel0sJySYA=
go.opentelemetry.io/auto/sdk v1.1.0/go.mod h1:3wSPjt5PWp2RhlCcmmOial7AvC4DQqZb7a7wCow3W8A=
go.opentelemetry.io/otel v1.38.0 h1:RkfdswUDRimDg0m2Az18RKOsnI8UDzppJAtj01/Ymk8=
go.opentelemetry.io/otel v1.38.0/go.mod h1:zcmtmQ1+YmQM9wrNsTGV/q/uyusom3P8RxwExxkZhjM=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2 h1:06ZeJRe5BnYXceSM9Vya83XXVaNGe3H1QqsvqRANQq8=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2/go.mod h1:DvPtKE63knkDVP88qpatBj81JxN+w1bqfVbsbCbj1WY=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2 h1:tPLwQlXbJ8NSOfZc4OkgU5h2A38M4c9kfHSVc4PFQGs=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2/go.mod h1:QTnxBwT/1rBIgAG1goq6xMydfYOBKU6KTiYF4fp5zL8=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.38.0 h1:vl9obrcoWVKp/lwl8tRE33853I8Xru9HFbw/skNeLs8=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.38.0/go.mod h1:GAXRxmLJcVM3u22IjTg74zWBrRCKq8BnOqUVLodpcpw=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.38.0 h1:Oe2z/BCg5q7k4iXC3cqJxKYg0ieRiOqF0cecFYdPTwk=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.38.0/go.mod h1:ZQM5lAJpOsKnYagGg/zV2krVqTtaVdYdDkhMoX6Oalg=
go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.38.0 h1:GqRJVj7UmLjCVyVJ3ZFLdPRmhDUp2zFmQe3RHIOsw24=
go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.38.0/go.mod h1:ri3aaHSmCTVYu2AWv44YMauwAQc0aqI9gHKIcSbI1pU=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.38.0 h1:lwI4Dc5leUqENgGuQImwLo4WnuXFPetmPpkLi2IrX54=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.38.0/go.mod h1:Kz/oCE7z5wuyhPxsXDuaPteSWqjSBD5YaSdbxZYGbGk=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.38.0 h1:aTL7F04bJHUlztTsNGJ2l+6he8c+y/b//eR0jjjemT4=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.38.0/go.mod h1:kldtb7jDTeol0l3ewcmd8SDvx3EmIE7lyvqbasU3QC4=
go.opentelemetry.io/otel/log v0.12.2 h1:yob9JVHn2ZY24byZeaXpTVoPS6l+UrrxmxmPKohXTwc=
go.opentelemetry.io/otel/log v0.12.2/go.mod h1:ShIItIxSYxufUMt+1H5a2wbckGli3/iCfuEbVZi/98E=
go.opentelemetry.io/otel/metric v1.38.0 h1:Kl6lzIYGAh5M159u9NgiRkmoMKjvbsKtYRwgfrA6WpA=
go.opentelemetry.io/otel/metric v1.38.0/go.mod h1:kB5n/QoRM8YwmUahxvI3bO34eVtQf2i4utNVLr9gEmI=
go.opentelemetry.io/otel/sdk v1.38.0 h1:l48sr5YbNf2hpCUj/FoGhW9yDkl+Ma+LrVl8qaM5b+E=
go.opentelemetry.io/otel/sdk v1.38.0/go.mod h1:ghmNdGlVemJI3+ZB5iDEuk4bWA3GkTpW+DOoZMYBVVg=
go.opentelemetry.io/otel/sdk/log v0.12.2 h1:yNoETvTByVKi7wHvYS6HMcZrN5hFLD7I++1xIZ/k6W0=
go.opentelemetry.io/otel/sdk/log v0.12.2/go.mod h1:DcpdmUXHJgSqN/dh+XMWa7Vf89u9ap0/AAk/XGLnEzY=
go.opentelemetry.io/otel/sdk/log/logtest v0.0.0-20250521073539-a85ae98dcedc h1:uqxdywfHqqCl6LmZzI3pUnXT1RGFYyUgxj0AkWPFxi0=
go.opentelemetry.io/otel/sdk/log/logtest v0.0.0-20250521073539-a85ae98dcedc/go.mod h1:TY/N/FT7dmFrP/r5ym3g0yysP1DefqGpAZr4f82P0dE=
go.opentelemetry.io/otel/sdk/metric v1.38.0 h1:aSH66iL0aZqo//xXzQLYozmWrXxyFkBJ6qT5wthqPoM=
go.opentelemetry.io/otel/sdk/metric v1.38.0/go.mod h1:dg9PBnW9XdQ1Hd6ZnRz689CbtrUp0wMMs9iPcgT9EZA=
go.opentelemetry.io/otel/trace v1.38.0 h1:Fxk5bKrDZJUH+AMyyIXGcFAPah0oRcT+LuNtJrmcNLE=
go.opentelemetry.io/otel/trace v1.38.0/go.mod h1:j1P9ivuFsTceSWe1oY+EeW3sc+Pp42sO++GHkg4wwhs=
go.opentelemetry.io/proto/otlp v1.8.0 h1:fRAZQDcAFHySxpJ1TwlA1cJ4tvcrw7nXl9xWWC8N5CE=
go.opentelemetry.io/proto/otlp v1.8.0/go.mod h1:tIeYOeNBU4cvmPqpaji1P+KbB4Oloai8wN4rWzRrFF0=
go.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=
go.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=
golang.org/x/exp v0.0.0-20231006140011-7918f672742d h1:jtJma62tbqLibJ5sFQz8bKtEM8rJBtfilJ2qTU199MI=
golang.org/x/exp v0.0.0-20231006140011-7918f672742d/go.mod h1:ldy0pHrwJyGW56pPQzzkH36rKxoZW1tw7ZJpeKx+hdo=
golang.org/x/net v0.43.0 h1:lat02VYK2j4aLzMzecihNvTlJNQUq316m2Mr9rnM6YE=
golang.org/x/net v0.43.0/go.mod h1:vhO1fvI4dGsIjh73sWfUVjj3N7CA9WkKJNQm2svM6Jg=
golang.org/x/sync v0.17.0 h1:l60nONMj9l5drqw6jlhIELNv9I0A4OFgRsG9k2oT9Ug=
golang.org/x/sync v0.17.0/go.mod h1:9KTHXmSnoGruLpwFjVSX0lNNA75CykiMECbovNTZqGI=
golang.org/x/sys v0.0.0-20200909081042-eff7692f9009/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210809222454-d867a43fc93e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.36.0 h1:KVRy2GtZBrk1cBYA7MKu5bEZFxQk4NIDV6RLVcC8o0k=
golang.org/x/sys v0.36.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
golang.org/x/term v0.35.0 h1:bZBVKBudEyhRcajGcNc3jIfWPqV4y/Kt2XcoigOWtDQ=
golang.org/x/term v0.35.0/go.mod h1:TPGtkTLesOwf2DE8CgVYiZinHAOuy5AYUYT1lENIZnA=
golang.org/x/text v0.28.0 h1:rhazDwis8INMIwQ4tpjLDzUhx6RlXqZNPEM0huQojng=
golang.org/x/text v0.28.0/go.mod h1:U8nCwOR8jO/marOQ0QbDiOngZVEBB7MAiitBuMjXiNU=
gonum.org/v1/gonum v0.16.0 h1:5+ul4Swaf3ESvrOnidPp4GZbzf0mxVQpDCYUQE7OJfk=
gonum.org/v1/gonum v0.16.0/go.mod h1:fef3am4MQ93R2HHpKnLk4/Tbh/s0+wqD5nfa6Pnwy4E=
google.golang.org/genproto/googleapis/api v0.0.0-20250825161204-c5933d9347a5 h1:BIRfGDEjiHRrk0QKZe3Xv2ieMhtgRGeLcZQ0mIVn4EY=
google.golang.org/genproto/googleapis/api v0.0.0-20250825161204-c5933d9347a5/go.mod h1:j3QtIyytwqGr1JUDtYXwtMXWPKsEa5LtzIFN1Wn5WvE=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250825161204-c5933d9347a5 h1:eaY8u2EuxbRv7c3NiGK0/NedzVsCcV6hDuU5qPX5EGE=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250825161204-c5933d9347a5/go.mod h1:M4/wBTSeyLxupu3W3tJtOgB14jILAS/XWPSSa3TAlJc=
google.golang.org/grpc v1.75.0 h1:+TW+dqTd2Biwe6KKfhE5JpiYIBWq865PhKGSXiivqt4=
google.golang.org/grpc v1.75.0/go.mod h1:JtPAzKiq4v1xcAB2hydNlWI2RnF85XXcV0mhKXr2ecQ=
google.golang.org/protobuf v1.36.8 h1:xHScyCOEuuwZEc6UtSOvPbAT4zRh0xcNRYekJwfqyMc=
google.golang.org/protobuf v1.36.8/go.mod h1:fuxRtAxBytpl4zzqUh6/eyUujkJdNiuEkXntxiD/uRU=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=
gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=
gopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
gopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=



================================================
FILE: install.sh
================================================
#!/usr/bin/env bash

# container-use installer script
# Downloads and installs the appropriate container-use binary for your system

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPO="dagger/container-use"
BINARY_NAME="container-use"
INSTALL_DIR=""

# Helper functions
log_info() {
    printf "${BLUE}‚ÑπÔ∏è  %s${NC}\n" "$1"
}

log_success() {
    printf "${GREEN}‚úÖ %s${NC}\n" "$1"
}

log_warning() {
    printf "${YELLOW}‚ö†Ô∏è  %s${NC}\n" "$1"
}

log_error() {
    printf "${RED}‚ùå %s${NC}\n" "$1"
}

# Check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Check dependencies
check_dependencies() {
    log_info "Checking dependencies..."

    if ! command_exists docker; then
        log_error "Docker is required but not installed."
        log_info "Please install Docker from: https://docs.docker.com/get-started/get-docker/"
        exit 1
    fi

    if ! command_exists git; then
        log_error "Git is required but not installed."
        log_info "Please install Git from: https://git-scm.com/downloads"
        exit 1
    fi
}

# Detect operating system
detect_os() {
    local os
    case "$(uname -s)" in
        Linux*)     os="linux";;
        Darwin*)    os="darwin";;
        CYGWIN*|MINGW32*|MSYS*|MINGW*)
            log_error "Windows is not supported"
            log_info "container-use uses Unix syscalls and requires Linux or macOS"
            exit 1;;
        *)
            log_error "Unsupported operating system: $(uname -s)"
            exit 1;;
    esac
    echo "$os"
}

# Detect architecture
detect_arch() {
    local arch
    case "$(uname -m)" in
        x86_64|amd64)   arch="amd64";;
        arm64|aarch64)  arch="arm64";;
        *)
            log_error "Unsupported architecture: $(uname -m)"
            exit 1;;
    esac
    echo "$arch"
}



# Find the best installation directory
find_install_dir() {
    local install_dir="${BIN_DIR:-$HOME/.local/bin}"

    # Create the directory if it doesn't exist
    mkdir -p "$install_dir"

    # Check if it's writable
    if [ ! -w "$install_dir" ]; then
        log_error "$install_dir is not a writable directory"
        exit 1
    fi

    echo "$install_dir"
}

# Get the latest release version
get_latest_version() {
    curl -s "https://api.github.com/repos/$REPO/releases/latest" | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\1/'
}

# Show shell completion setup instructions
show_completion_instructions() {
    local binary="$1"

    log_info "To enable shell completions:"
    echo ""
    echo "  # For container-use command:"
    echo "  $binary completion bash > /usr/local/etc/bash_completion.d/container-use"
    echo "  $binary completion zsh > /usr/local/share/zsh/site-functions/_container-use"
    echo "  $binary completion fish > ~/.config/fish/completions/container-use.fish"
    echo ""
    echo "  # For cu command:"
    echo "  $binary completion --command-name=cu bash > /usr/local/etc/bash_completion.d/cu"
    echo "  $binary completion --command-name=cu zsh > /usr/local/share/zsh/site-functions/_cu"
    echo "  $binary completion --command-name=cu fish > ~/.config/fish/completions/cu.fish"
}

# Verify checksum of downloaded file
verify_checksum() {
    local archive_file="$1"
    local archive_name="$2"
    local version="$3"

    log_info "Verifying checksum..."

    # Download checksums file
    local checksums_url="https://github.com/$REPO/releases/download/$version/checksums.txt"
    local checksums_file="$(dirname "$archive_file")/checksums.txt"

    curl -s -L -o "$checksums_file" "$checksums_url"
    if [ ! -f "$checksums_file" ]; then
        log_error "Failed to download checksums file"
        return 1
    fi

    # Extract expected checksum for our file
    local expected_checksum=$(grep "$(basename "$archive_file")" "$checksums_file" | cut -d' ' -f1)
    if [ -z "$expected_checksum" ]; then
        log_error "Checksum not found for $(basename "$archive_file")"
        return 1
    fi

    # Calculate actual checksum
    local actual_checksum
    if command_exists sha256sum; then
        actual_checksum=$(sha256sum "$archive_file" | cut -d' ' -f1)
    elif command_exists shasum; then
        actual_checksum=$(shasum -a 256 "$archive_file" | cut -d' ' -f1)
    else
        log_warning "No SHA256 tool found, skipping checksum verification"
        return 0
    fi

    # Compare checksums
    if [ "$actual_checksum" = "$expected_checksum" ]; then
        log_success "Checksum verified"
        return 0
    else
        log_error "Checksum verification failed!"
        log_error "Expected: $expected_checksum"
        log_error "Actual:   $actual_checksum"
        return 1
    fi
}

# Download and extract binary
download_and_install() {
    local os="$1"
    local arch="$2"
    local version="$3"
    local install_dir="$4"

    local archive_name="container-use_${version}_${os}_${arch}"
    local extension="tar.gz"

    local download_url="https://github.com/$REPO/releases/download/$version/${archive_name}.${extension}"
    local temp_dir=$(mktemp -d)
    local archive_file="$temp_dir/${archive_name}.${extension}"

    log_info "Downloading $BINARY_NAME $version for $os/$arch..."

    curl -L -o "$archive_file" "$download_url"

    if [ ! -f "$archive_file" ]; then
        log_error "Failed to download $download_url"
        exit 1
    fi

    # Verify checksum
    if ! verify_checksum "$archive_file" "$archive_name" "$version"; then
        log_error "Checksum verification failed, aborting installation"
        exit 1
    fi

    log_info "Extracting archive..."

    tar -xzf "$archive_file" -C "$temp_dir"

    local binary_path="$temp_dir/$BINARY_NAME"

    if [ ! -f "$binary_path" ]; then
        log_error "Binary not found in archive"
        exit 1
    fi

    log_info "Installing to $install_dir..."
    mkdir -p "$install_dir"
    cp "$binary_path" "$install_dir/"
    chmod +x "$install_dir/$BINARY_NAME"

    log_info "Creating cu symlink for backward compatibility..."
    ln -sf "$BINARY_NAME" "$install_dir/cu"

    # Clean up
    rm -rf "$temp_dir"

    log_success "$BINARY_NAME installed successfully!"
}

# Main installation process
main() {
    # Handle command line arguments
    case "${1:-}" in
        -h|--help)
            echo "container-use installer"
            echo ""
            echo "Usage: $0 [options]"
            echo ""
            echo "Options:"
            echo "  -h, --help    Show this help message"
            echo ""
            echo "This script will:"
            echo "  1. Check for Docker installation"
            echo "  2. Detect your OS and architecture"
            echo "  3. Download the latest container-use binary"
            echo "  4. Install 'container-use' binary and create 'cu' shortcut"
            echo "  5. Provide instructions to set up shell completions for both commands"
            exit 0
            ;;
    esac

    log_info "Starting container-use installation..."

    check_dependencies

    local os=$(detect_os)
    local arch=$(detect_arch)
    log_info "Detected platform: $os/$arch"

    local version=$(get_latest_version)
    if [ -z "$version" ]; then
        log_error "Failed to get latest release version"
        exit 1
    fi
    log_info "Latest version: $version"

    INSTALL_DIR=$(find_install_dir)
    log_info "Installation directory: $INSTALL_DIR"

    download_and_install "$os" "$arch" "$version" "$INSTALL_DIR"

    # Check if install directory is in PATH
    if ! echo "$PATH" | grep -q "$INSTALL_DIR"; then
        log_warning "Installation directory $INSTALL_DIR is not in your PATH"
        log_info "Add this to your shell profile (.bashrc, .zshrc, etc.):"
        echo "    export PATH=\"$INSTALL_DIR:\$PATH\""
        log_info "Then restart your terminal or run: source ~/.bashrc (or your shell's config file)"
    fi

    # Verify installation
    if [ -x "$INSTALL_DIR/$BINARY_NAME" ]; then
        log_success "Installation complete!"

        # Show shell completion instructions
        show_completion_instructions "$BINARY_NAME"

        # Verify installation
        if command -v "$BINARY_NAME" >/dev/null 2>&1 && command -v "cu" >/dev/null 2>&1; then
            log_success "container-use is ready to use!"
        else
            log_warning "You may need to restart your terminal or update your PATH"
        fi

        log_info "Run 'container-use --help' or 'cu --help' to get started"
    else
        log_error "Installation verification failed"
        exit 1
    fi
}

main "$@"



================================================
FILE: LICENSE
================================================

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   Copyright 2022 Dagger, Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: RELEASING.md
================================================
# Releasing

## Steps

1. **Fetch the latest main branch**
   ```sh
   git fetch origin main
   git checkout origin/main
   ```
   NOTE: this puts you on a detached head, which is fine for tagging and pushing the tag.

2. **Tag the release**
   ```sh
   git tag v1.2.3
   ```

3. **Push the tag**
   ```sh
   git push origin v1.2.3
   ```

4. **Check the draft release**
   - Monitor the [release workflow](https://github.com/dagger/container-use/actions/workflows/release.yml) for progress and errors
   - Go to [GitHub Releases](https://github.com/dagger/container-use/releases)
   - Review the auto-generated draft release
   - Verify binaries and checksums are attached

5. **Publish the release**
   - Edit the draft release if needed
   - Click "Publish release"

6. **Merge the homebrew tap PR**
   - After publishing the release, a PR will be automatically created in [dagger/homebrew-tap](https://github.com/dagger/homebrew-tap)
   - Review and merge the PR to make the release available via Homebrew

The Dagger CI automatically handles building binaries and creating the draft release when tags are pushed.



================================================
FILE: uninstall.sh
================================================
#!/bin/sh

# container-use uninstaller script

set -euo pipefail

main() {
    local BINARY_NAME="container-use"
    local INSTALL_DIR="${BIN_DIR:-$HOME/.local/bin}"
    local BINARY_PATH="$INSTALL_DIR/$BINARY_NAME"

    if [ ! -f "$BINARY_PATH" ]; then
        echo "container-use not found at $BINARY_PATH"
        exit 1
    fi

    # Safety check: don't delete from system paths or homebrew
    case "$BINARY_PATH" in
        /usr/bin/* | /bin/* | /usr/local/bin/* | /opt/homebrew/bin/*)
            echo "Error: Refusing to delete from system/brew path: $BINARY_PATH"
            echo "This script only removes container-use from user directories"
            exit 1
            ;;
    esac

    echo "Found container-use at: $BINARY_PATH"
    printf "Remove this file? (y/N): "
    read -r response

    case "$response" in
        [yY]|[yY][eE][sS])
            rm -f "$BINARY_PATH"
            echo "Removed $BINARY_PATH"

            # Also remove cu symlink if it exists
            local SYMLINK_PATH="$INSTALL_DIR/cu"
            if [ -L "$SYMLINK_PATH" ]; then
                rm -f "$SYMLINK_PATH"
                echo "Removed cu symlink at $SYMLINK_PATH"
            fi
            ;;
        *)
            echo "Cancelled"
            exit 1
            ;;
    esac
}

main "$@"



================================================
FILE: .goreleaser.yaml
================================================
# GoReleaser configuration for container-use
version: 2

project_name: container-use

before:
  hooks:
    - go mod tidy
    - ./scripts/completions.sh
    - ./scripts/man.sh

builds:
  - id: container-use
    binary: container-use
    main: ./cmd/container-use
    env:
      - CGO_ENABLED=0
    goos:
      - linux
      - darwin
      - windows
    goarch:
      - amd64
      - arm64

    ldflags:
      - -s -w
      - -X main.version={{.Version}}
      - -X main.commit={{.Commit}}
      - -X main.date={{.Date}}

archives:
  - id: container-use-archive
    ids:
      - container-use
    name_template: "{{ .ProjectName }}_{{ .Tag }}_{{ .Os }}_{{ .Arch }}"
    files:
      - README.md
      - LICENSE
      - completions/*
      - man/*

homebrew_casks:
  - repository:
      owner: "{{ .Env.GH_ORG_NAME }}"
      name: homebrew-tap
      branch: "{{ .ProjectName }}-{{ .Version }}"
      token: "{{ .Env.GITHUB_TOKEN }}"
      pull_request:
        enabled: true
    name: container-use
    binary: container-use
    skip_upload: auto # if the version is like v0.0.0-rc1, don't make the tap PR.
    commit_author:
      name: container-use-bot
      email: noreply@dagger.io
    url:
      template: "https://github.com/{{ .Env.GH_ORG_NAME }}/container-use/releases/download/{{ .Tag }}/{{ .ArtifactName }}"
    homepage: "https://github.com/{{ .Env.GH_ORG_NAME }}/container-use"
    description: "Containerized environments for coding agents"
    manpages:
      - man/container-use.1
    completions:
      bash: "completions/container-use.bash"
      zsh: "completions/container-use.zsh"
      fish: "completions/container-use.fish"
    hooks:
      post:
        install: |
          # remove quarantine xattr (note we don't do anything with signatures yet)
          if File.exist?("/usr/bin/xattr")
            system "/usr/bin/xattr", "-dr", "com.apple.quarantine", "#{staged_path}/container-use"
          end

          # Create cu symlink for backward compatibility
          FileUtils.ln_sf "#{HOMEBREW_PREFIX}/bin/container-use", "#{HOMEBREW_PREFIX}/bin/cu"

          # Install cu completions for backward compatibility
          bash_completion = "#{HOMEBREW_PREFIX}/etc/bash_completion.d"
          zsh_completion = "#{HOMEBREW_PREFIX}/share/zsh/site-functions"
          fish_completion = "#{HOMEBREW_PREFIX}/share/fish/vendor_completions.d"

          if File.exist?("#{staged_path}/completions/cu.bash")
            FileUtils.mkdir_p bash_completion
            FileUtils.cp "#{staged_path}/completions/cu.bash", "#{bash_completion}/cu"
          end

          if File.exist?("#{staged_path}/completions/cu.zsh")
            FileUtils.mkdir_p zsh_completion
            FileUtils.cp "#{staged_path}/completions/cu.zsh", "#{zsh_completion}/_cu"
          end

          if File.exist?("#{staged_path}/completions/cu.fish")
            FileUtils.mkdir_p fish_completion
            FileUtils.cp "#{staged_path}/completions/cu.fish", "#{fish_completion}/cu.fish"
          end
        uninstall: |
          # Remove cu symlink
          FileUtils.rm_f "#{HOMEBREW_PREFIX}/bin/cu"

          # Remove cu completions
          FileUtils.rm_f "#{HOMEBREW_PREFIX}/etc/bash_completion.d/cu"
          FileUtils.rm_f "#{HOMEBREW_PREFIX}/share/zsh/site-functions/_cu"
          FileUtils.rm_f "#{HOMEBREW_PREFIX}/share/fish/vendor_completions.d/cu.fish"

# https://goreleaser.com/customization/nix/
nix:
  - name: container-use
    repository:
      owner: "{{ .Env.GH_ORG_NAME }}"
      name: nix
    commit_author:
      name: container-use-bot
      email: noreply@dagger.io
    url_template: "https://github.com/{{ .Env.GH_ORG_NAME }}/container-use/releases/download/{{ .Tag }}/{{ .ArtifactName }}"
    homepage: "https://github.com/{{ .Env.GH_ORG_NAME }}/container-use"
    description: "Containerized environments for coding agents"
    license: "asl20"
    post_install: |
      installShellCompletion --cmd container-use \
        --bash <($out/bin/container-use completion bash) \
        --fish <($out/bin/container-use completion fish) \
        --zsh <($out/bin/container-use completion zsh)
      
      # Create cu symlink for backward compatibility
      ln -sf $out/bin/container-use $out/bin/cu
      
      # Install cu completions for backward compatibility
      installShellCompletion --cmd cu \
        --bash <($out/bin/cu completion bash) \
        --fish <($out/bin/cu completion fish) \
        --zsh <($out/bin/cu completion zsh)

checksum:
  name_template: "checksums.txt"

changelog:
  sort: asc
  use: github
  filters:
    exclude:
      - "^docs:"
      - "^test:"
      - "^ci:"
      - "^chore:"
      - "Merge pull request"
      - "Merge branch"

release:
  github:
    owner: "{{ .Env.GH_ORG_NAME }}" # reconfigure if test releasing on your own fork
    name: container-use
  draft: true
  prerelease: auto
  mode: replace
  header: |
    ## container-use {{ .Tag }}

    Download the pre-compiled binaries from the assets below.
  footer: |
    **Full Changelog**: https://github.com/{{ .Env.GH_ORG_NAME }}/container-use/compare/{{ .PreviousTag }}...{{ .Tag }}



================================================
SYMLINK: CLAUDE.md -> AGENT.md
================================================



================================================
FILE: cmd/container-use/apply.go
================================================
package main

import (
	"fmt"
	"os"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var (
	applyDelete bool
)

var applyCmd = &cobra.Command{
	Use:   "apply [<env>]",
	Short: "Apply an environment's work as staged changes to your branch",
	Long: `Apply an environment's changes to your current git branch as staged modifications.
Unlike 'merge' which preserves the original commit history, 'apply' stages all changes
for you to commit manually, discarding the original commit sequence. This lets you
review and customize the final commit before making the agent's work permanent.
Your working directory will be automatically stashed and restored.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# Apply agent's work as staged changes to current branch
cu apply backend-api

# Apply and delete the environment after successful application
cu apply -d backend-api
cu apply --delete backend-api

# After applying, you can review and commit the changes
git status
git commit -m "Add backend API implementation"

# Auto-select environment
cu apply`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		if err := repo.Apply(ctx, envID, os.Stdout); err != nil {
			return fmt.Errorf("failed to apply environment: %w", err)
		}

		return deleteAfterMerge(ctx, repo, envID, applyDelete, "applied")
	},
}

func init() {
	applyCmd.Flags().BoolVarP(&applyDelete, "delete", "d", false, "Delete the environment after successful application")

	rootCmd.AddCommand(applyCmd)
}



================================================
FILE: cmd/container-use/checkout.go
================================================
package main

import (
	"fmt"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var checkoutCmd = &cobra.Command{
	Use:   "checkout [<env>]",
	Short: "Switch to an environment's branch locally",
	Long: `Bring an environment's work into your local git workspace.
This creates a local branch from the environment's state so you can
explore files in your IDE, make changes, or continue development.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# Switch to environment's branch locally
container-use checkout fancy-mallard

# Create custom branch name
container-use checkout fancy-mallard -b my-review-branch

# Auto-select environment
container-use checkout`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		branchName, err := app.Flags().GetString("branch")
		if err != nil {
			return err
		}

		branch, err := repo.Checkout(ctx, envID, branchName)
		if err != nil {
			return err
		}

		fmt.Printf("Switched to branch '%s'\n", branch)
		return nil
	},
}

func init() {
	checkoutCmd.Flags().StringP("branch", "b", "", "Local branch name to use")
	rootCmd.AddCommand(checkoutCmd)
}



================================================
FILE: cmd/container-use/completion_override.go
================================================
package main

import (
	"os"
	"strings"

	"github.com/spf13/cobra"
)

var commandName string

func init() {
	// Override cobra's default completion command
	completionCmd := &cobra.Command{
		Use:   "completion [bash|zsh|fish|powershell]",
		Short: "Generate the autocompletion script for the specified shell",
		Long: `Generate the autocompletion script for container-use for the specified shell.
See each sub-command's help for details on how to use the generated script.

Use --command-name to generate completions for a different command name (e.g., 'cu').`,
		DisableFlagsInUseLine: true,
		ValidArgs:             []string{"bash", "zsh", "fish", "powershell"},
		Args:                  cobra.MatchAll(cobra.ExactArgs(1), cobra.OnlyValidArgs),
		RunE: func(cmd *cobra.Command, args []string) error {
			return generateCompletionForBinary(args[0])
		},
	}

	completionCmd.PersistentFlags().StringVar(&commandName, "command-name", "container-use", "Command name to use in completions")

	// Add help subcommands that show usage instructions
	for _, shell := range []string{"bash", "zsh", "fish", "powershell"} {
		shell := shell // capture loop variable
		helpCmd := &cobra.Command{
			Use:   shell,
			Short: "Generate the autocompletion script for " + shell,
			Long:  generateHelpText(shell),
			RunE: func(cmd *cobra.Command, args []string) error {
				return generateCompletionForBinary(shell)
			},
		}
		completionCmd.AddCommand(helpCmd)
	}

	rootCmd.AddCommand(completionCmd)
}

func generateCompletionForBinary(shell string) error {
	tempRootCmd := &cobra.Command{
		Use:   commandName,
		Short: rootCmd.Short,
		Long:  rootCmd.Long,
	}

	for _, subCmd := range rootCmd.Commands() {
		if subCmd.Name() != "completion" {
			tempRootCmd.AddCommand(subCmd)
		}
	}

	switch shell {
	case "bash":
		return tempRootCmd.GenBashCompletion(os.Stdout)
	case "zsh":
		return tempRootCmd.GenZshCompletion(os.Stdout)
	case "fish":
		return tempRootCmd.GenFishCompletion(os.Stdout, true)
	case "powershell":
		return tempRootCmd.GenPowerShellCompletion(os.Stdout)
	}
	return nil
}

func generateHelpText(shell string) string {
	// Generate help text dynamically based on the shell
	// This reduces duplication of the static help text
	templates := map[string]string{
		"bash": `Generate the autocompletion script for the bash shell.

This script depends on the 'bash-completion' package.
If it is not installed already, you can install it via your OS's package manager.

To load completions in your current shell session:
	source <({{.command}} completion bash)

To load completions for every new session, save the output to your bash completion directory.
Common locations include:
  - Linux: /usr/local/etc/bash_completion.d/{{.command}}
  - macOS: $(brew --prefix)/etc/bash_completion.d/{{.command}}
  - Windows (Git Bash): /usr/share/bash-completion/completions/{{.command}}

Example:
	{{.command}} completion bash > /path/to/bash_completion.d/{{.command}}`,

		"zsh": `Generate the autocompletion script for the zsh shell.

If shell completion is not already enabled in your environment,
you will need to enable it. You can execute the following once:
	echo "autoload -U compinit; compinit" >> ~/.zshrc

To load completions in your current shell session:
	source <({{.command}} completion zsh)

To load completions for every new session, save the output to your zsh completion directory.
Common locations include:
  - Linux: /usr/local/share/zsh/site-functions/_{{.command}}
  - macOS: $(brew --prefix)/share/zsh/site-functions/_{{.command}}
  - Custom: Any directory in your $fpath

Example:
	{{.command}} completion zsh > /path/to/zsh/site-functions/_{{.command}}`,

		"fish": `Generate the autocompletion script for the fish shell.

To load completions in your current shell session:
	{{.command}} completion fish | source

To load completions for every new session, save the output to your fish completion directory.
Common locations include:
  - Linux/macOS: ~/.config/fish/completions/{{.command}}.fish
  - Windows: %APPDATA%\fish\completions\{{.command}}.fish

Example:
	{{.command}} completion fish > ~/.config/fish/completions/{{.command}}.fish`,

		"powershell": `Generate the autocompletion script for PowerShell.

To load completions in your current shell session:
	{{.command}} completion powershell | Out-String | Invoke-Expression

To load completions for every new session, add the output to your PowerShell profile.
Common profile locations include:
  - Windows: $PROFILE (usually %USERPROFILE%\Documents\PowerShell\Microsoft.PowerShell_profile.ps1)
  - Linux/macOS: ~/.config/powershell/Microsoft.PowerShell_profile.ps1

Example:
	{{.command}} completion powershell >> $PROFILE

Note: You may need to create the profile file if it doesn't exist.`,
	}

	template := templates[shell]
	return strings.ReplaceAll(template, "{{.command}}", commandName)
}



================================================
FILE: cmd/container-use/config.go
================================================
package main

import (
	"encoding/json"
	"fmt"
	"os"
	"text/tabwriter"

	"github.com/dagger/container-use/cmd/container-use/agent"
	"github.com/dagger/container-use/environment"
	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

// Helper function for read-only config operations
func withConfig(cmd *cobra.Command, fn func(*environment.EnvironmentConfig) error) error {
	ctx := cmd.Context()
	repo, err := repository.Open(ctx, ".")
	if err != nil {
		return fmt.Errorf("failed to open repository: %w", err)
	}

	config := environment.DefaultConfig()
	if err := config.Load(repo.SourcePath()); err != nil {
		return fmt.Errorf("failed to load configuration: %w", err)
	}

	return fn(config)
}

// Helper function for config update operations
func updateConfig(cmd *cobra.Command, fn func(*environment.EnvironmentConfig) error) error {
	ctx := cmd.Context()
	repo, err := repository.Open(ctx, ".")
	if err != nil {
		return fmt.Errorf("failed to open repository: %w", err)
	}

	config := environment.DefaultConfig()
	if err := config.Load(repo.SourcePath()); err != nil {
		return fmt.Errorf("failed to load configuration: %w", err)
	}

	if err := fn(config); err != nil {
		return err
	}

	if err := config.Save(repo.SourcePath()); err != nil {
		return fmt.Errorf("failed to save configuration: %w", err)
	}

	return nil
}

var configCmd = &cobra.Command{
	Use:   "config",
	Short: "Manage environment configuration",
	Long: `Configure the development environment settings such as base image and setup commands.
These settings are stored in .container-use/environment.json and apply to all new environments.`,
}

func init() {
	configShowCmd.Flags().Bool("json", false, "Dump the configuration in JSON")
}

var configShowCmd = &cobra.Command{
	Use:   "show [<env>]",
	Short: "Show environment configuration",
	Long: `Display environment configuration including base image and setup commands.
Without an environment argument, shows the default configuration used for new environments.
With an environment argument, shows the configuration for that specific environment.`,
	Example: `# Show the default environment configuration
container-use config show

# Show the configuration for a specific environment
container-use config show my-env
`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	RunE: func(cmd *cobra.Command, args []string) error {
		ctx := cmd.Context()

		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return fmt.Errorf("failed to open repository: %w", err)
		}

		var config *environment.EnvironmentConfig

		// If no environment is specified, use the default configuration
		if len(args) == 0 {
			config = environment.DefaultConfig()
			if err := config.Load(repo.SourcePath()); err != nil {
				return fmt.Errorf("failed to load configuration: %w", err)
			}
		} else {
			envID := args[0]
			env, err := repo.Info(ctx, envID)
			if err != nil {
				return err
			}
			config = env.State.Config
		}

		if ok, _ := cmd.Flags().GetBool("json"); ok {
			enc := json.NewEncoder(os.Stdout)
			enc.SetIndent("", "  ")
			return enc.Encode(config)
		}

		tw := tabwriter.NewWriter(os.Stdout, 0, 0, 2, ' ', 0)
		defer tw.Flush()

		fmt.Fprintf(tw, "Base Image:\t%s\n", config.BaseImage)
		fmt.Fprintf(tw, "Workdir:\t%s\n", config.Workdir)

		if len(config.SetupCommands) > 0 {
			fmt.Fprintf(tw, "Setup Commands:\t\n")
			for i, cmd := range config.SetupCommands {
				fmt.Fprintf(tw, "  %d.\t%s\n", i+1, cmd)
			}
		} else {
			fmt.Fprintf(tw, "Setup Commands:\t(none)\n")
		}

		if len(config.InstallCommands) > 0 {
			fmt.Fprintf(tw, "Install Commands:\t\n")
			for i, cmd := range config.InstallCommands {
				fmt.Fprintf(tw, "  %d.\t%s\n", i+1, cmd)
			}
		} else {
			fmt.Fprintf(tw, "Install Commands:\t(none)\n")
		}

		envKeys := config.Env.Keys()
		if len(envKeys) > 0 {
			fmt.Fprintf(tw, "Environment Variables:\t\n")
			for i, key := range envKeys {
				value := config.Env.Get(key)
				fmt.Fprintf(tw, "  %d.\t%s=%s\n", i+1, key, value)
			}
		} else {
			fmt.Fprintf(tw, "Environment Variables:\t(none)\n")
		}

		secretKeys := config.Secrets.Keys()
		if len(secretKeys) > 0 {
			fmt.Fprintf(tw, "Secrets:\t\n")
			for i, key := range secretKeys {
				value := config.Secrets.Get(key)
				fmt.Fprintf(tw, "  %d.\t%s=%s\n", i+1, key, value)
			}
		} else {
			fmt.Fprintf(tw, "Secrets:\t(none)\n")
		}

		return nil
	},
}

var configImportCmd = &cobra.Command{
	Use:   "import <env>",
	Short: "Import configuration from an environment",
	Long: `Import configuration from an existing environment and set it as the default.
This copies the environment's base image, setup commands, environment variables,
and secrets to be used as defaults for new environments.`,
	Example: `# Import configuration from an environment
container-use config import my-env

# View the configuration before importing
container-use config show my-env
container-use config import my-env`,
	Args:              cobra.ExactArgs(1),
	ValidArgsFunction: suggestEnvironments,
	RunE: func(cmd *cobra.Command, args []string) error {
		ctx := cmd.Context()

		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return fmt.Errorf("failed to open repository: %w", err)
		}

		envID := args[0]
		env, err := repo.Info(ctx, envID)
		if err != nil {
			return err
		}
		if err := env.State.Config.Save(repo.SourcePath()); err != nil {
			return fmt.Errorf("failed to save configuration: %w", err)
		}

		fmt.Printf("Configuration imported from environment '%s'\n", envID)
		return nil
	},
}

// Base image object commands
var configBaseImageCmd = &cobra.Command{
	Use:   "base-image",
	Short: "Manage base container image",
	Long:  `Manage the base container image for new environments.`,
}

var configBaseImageSetCmd = &cobra.Command{
	Use:   "set <image>",
	Short: "Set the base container image",
	Long:  `Set the base container image for new environments (e.g., python:3.11, node:18, ubuntu:22.04).`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		baseImage := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.BaseImage = baseImage
			fmt.Printf("Base image set to: %s\n", baseImage)
			return nil
		})
	},
}

var configBaseImageGetCmd = &cobra.Command{
	Use:   "get",
	Short: "Get the current base container image",
	Long:  `Display the current base container image.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return withConfig(cmd, func(config *environment.EnvironmentConfig) error {
			fmt.Println(config.BaseImage)
			return nil
		})
	},
}

var configBaseImageResetCmd = &cobra.Command{
	Use:   "reset",
	Short: "Reset base image to default",
	Long:  `Reset the base container image to the default (ubuntu:24.04).`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			defaultConfig := environment.DefaultConfig()
			config.BaseImage = defaultConfig.BaseImage
			fmt.Printf("Base image reset to default: %s\n", defaultConfig.BaseImage)
			return nil
		})
	},
}

// Setup command object commands
var configSetupCommandCmd = &cobra.Command{
	Use:   "setup-command",
	Short: "Manage setup commands",
	Long:  `Manage setup commands that are run when creating environments.`,
}

var configSetupCommandAddCmd = &cobra.Command{
	Use:   "add <command>",
	Short: "Add a setup command",
	Long:  `Add a command to be run when creating new environments (e.g., "apt update && apt install -y python3").`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		command := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.SetupCommands = append(config.SetupCommands, command)
			fmt.Printf("Setup command added: %s\n", command)
			return nil
		})
	},
}

var configSetupCommandRemoveCmd = &cobra.Command{
	Use:   "remove <command>",
	Short: "Remove a setup command",
	Long:  `Remove a setup command from the environment configuration.`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		command := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			found := false
			newCommands := make([]string, 0, len(config.SetupCommands))
			for _, existing := range config.SetupCommands {
				if existing != command {
					newCommands = append(newCommands, existing)
				} else {
					found = true
				}
			}

			if !found {
				return fmt.Errorf("setup command not found: %s", command)
			}

			config.SetupCommands = newCommands
			fmt.Printf("Setup command removed: %s\n", command)
			return nil
		})
	},
}

var configSetupCommandListCmd = &cobra.Command{
	Use:   "list",
	Short: "List all setup commands",
	Long:  `List all setup commands that will be run when creating environments.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return withConfig(cmd, func(config *environment.EnvironmentConfig) error {
			if len(config.SetupCommands) == 0 {
				fmt.Println("No setup commands configured")
				return nil
			}

			for i, command := range config.SetupCommands {
				fmt.Printf("%d. %s\n", i+1, command)
			}
			return nil
		})
	},
}

var configSetupCommandClearCmd = &cobra.Command{
	Use:   "clear",
	Short: "Clear all setup commands",
	Long:  `Remove all setup commands from the environment configuration.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.SetupCommands = []string{}
			fmt.Println("All setup commands cleared")
			return nil
		})
	},
}

// Install command object commands
var configInstallCommandCmd = &cobra.Command{
	Use:   "install-command",
	Short: "Manage install commands",
	Long:  `Manage install commands that are run after copying code to environments.`,
}

var configInstallCommandAddCmd = &cobra.Command{
	Use:   "add <command>",
	Short: "Add an install command",
	Long:  `Add a command to be run after copying code to new environments (e.g., "go mod download").`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		command := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.InstallCommands = append(config.InstallCommands, command)
			fmt.Printf("Install command added: %s\n", command)
			return nil
		})
	},
}

var configInstallCommandRemoveCmd = &cobra.Command{
	Use:   "remove <command>",
	Short: "Remove an install command",
	Long:  `Remove an install command from the environment configuration.`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		command := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			found := false
			newCommands := make([]string, 0, len(config.InstallCommands))
			for _, existing := range config.InstallCommands {
				if existing != command {
					newCommands = append(newCommands, existing)
				} else {
					found = true
				}
			}

			if !found {
				return fmt.Errorf("install command not found: %s", command)
			}

			config.InstallCommands = newCommands
			fmt.Printf("Install command removed: %s\n", command)
			return nil
		})
	},
}

var configInstallCommandListCmd = &cobra.Command{
	Use:   "list",
	Short: "List all install commands",
	Long:  `List all install commands that will be run after copying code to environments.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return withConfig(cmd, func(config *environment.EnvironmentConfig) error {
			if len(config.InstallCommands) == 0 {
				fmt.Println("No install commands configured")
				return nil
			}

			for i, command := range config.InstallCommands {
				fmt.Printf("%d. %s\n", i+1, command)
			}
			return nil
		})
	},
}

var configInstallCommandClearCmd = &cobra.Command{
	Use:   "clear",
	Short: "Clear all install commands",
	Long:  `Remove all install commands from the environment configuration.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.InstallCommands = []string{}
			fmt.Println("All install commands cleared")
			return nil
		})
	},
}

// Environment variable object commands
var configEnvCmd = &cobra.Command{
	Use:   "env",
	Short: "Manage environment variables",
	Long:  `Manage environment variables that are set when creating environments.`,
}

var configEnvSetCmd = &cobra.Command{
	Use:   "set <key> <value>",
	Short: "Set an environment variable",
	Long:  `Set an environment variable to be used when creating new environments (e.g., "PATH" "/usr/local/bin:$PATH").`,
	Args:  cobra.ExactArgs(2),
	RunE: func(cmd *cobra.Command, args []string) error {
		key := args[0]
		value := args[1]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.Env.Set(key, value)
			fmt.Printf("Environment variable set: %s=%s\n", key, value)
			return nil
		})
	},
}

var configEnvUnsetCmd = &cobra.Command{
	Use:   "unset <key>",
	Short: "Unset an environment variable",
	Long:  `Unset an environment variable from the environment configuration.`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		key := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			if !config.Env.Unset(key) {
				return fmt.Errorf("environment variable not found: %s", key)
			}
			fmt.Printf("Environment variable unset: %s\n", key)
			return nil
		})
	},
}

var configEnvListCmd = &cobra.Command{
	Use:   "list",
	Short: "List all environment variables",
	Long:  `List all environment variables that will be set when creating environments.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return withConfig(cmd, func(config *environment.EnvironmentConfig) error {
			keys := config.Env.Keys()
			if len(keys) == 0 {
				fmt.Println("No environment variables configured")
				return nil
			}

			for i, key := range keys {
				value := config.Env.Get(key)
				fmt.Printf("%d. %s=%s\n", i+1, key, value)
			}
			return nil
		})
	},
}

var configEnvClearCmd = &cobra.Command{
	Use:   "clear",
	Short: "Clear all environment variables",
	Long:  `Remove all environment variables from the environment configuration.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.Env.Clear()
			fmt.Println("All environment variables cleared")
			return nil
		})
	},
}

// Secret object commands
var configSecretCmd = &cobra.Command{
	Use:   "secret",
	Short: "Manage secrets",
	Long:  `Manage secrets that are set when creating environments.`,
}

var configSecretSetCmd = &cobra.Command{
	Use:   "set <key> <value>",
	Short: "Set a secret",
	Long:  `Set a secret to be used when creating new environments (e.g., "API_KEY" "op://vault/item/field").`,
	Args:  cobra.ExactArgs(2),
	RunE: func(cmd *cobra.Command, args []string) error {
		key := args[0]
		value := args[1]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.Secrets.Set(key, value)
			fmt.Printf("Secret set: %s=%s\n", key, value)
			return nil
		})
	},
}

var configSecretUnsetCmd = &cobra.Command{
	Use:   "unset <key>",
	Short: "Unset a secret",
	Long:  `Unset a secret from the environment configuration.`,
	Args:  cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		key := args[0]
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			if !config.Secrets.Unset(key) {
				return fmt.Errorf("secret not found: %s", key)
			}
			fmt.Printf("Secret unset: %s\n", key)
			return nil
		})
	},
}

var configSecretListCmd = &cobra.Command{
	Use:   "list",
	Short: "List all secrets",
	Long:  `List all secrets that will be set when creating environments.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return withConfig(cmd, func(config *environment.EnvironmentConfig) error {
			keys := config.Secrets.Keys()
			if len(keys) == 0 {
				fmt.Println("No secrets configured")
				return nil
			}

			for i, key := range keys {
				value := config.Secrets.Get(key)
				fmt.Printf("%d. %s=%s\n", i+1, key, value)
			}
			return nil
		})
	},
}

var configSecretClearCmd = &cobra.Command{
	Use:   "clear",
	Short: "Clear all secrets",
	Long:  `Remove all secrets from the environment configuration.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		return updateConfig(cmd, func(config *environment.EnvironmentConfig) error {
			config.Secrets.Clear()
			fmt.Println("All secrets cleared")
			return nil
		})
	},
}

func init() {
	// Add base-image commands
	configBaseImageCmd.AddCommand(configBaseImageSetCmd)
	configBaseImageCmd.AddCommand(configBaseImageGetCmd)
	configBaseImageCmd.AddCommand(configBaseImageResetCmd)

	// Add setup-command commands
	configSetupCommandCmd.AddCommand(configSetupCommandAddCmd)
	configSetupCommandCmd.AddCommand(configSetupCommandRemoveCmd)
	configSetupCommandCmd.AddCommand(configSetupCommandListCmd)
	configSetupCommandCmd.AddCommand(configSetupCommandClearCmd)

	// Add install-command commands
	configInstallCommandCmd.AddCommand(configInstallCommandAddCmd)
	configInstallCommandCmd.AddCommand(configInstallCommandRemoveCmd)
	configInstallCommandCmd.AddCommand(configInstallCommandListCmd)
	configInstallCommandCmd.AddCommand(configInstallCommandClearCmd)

	// Add env commands
	configEnvCmd.AddCommand(configEnvSetCmd)
	configEnvCmd.AddCommand(configEnvUnsetCmd)
	configEnvCmd.AddCommand(configEnvListCmd)
	configEnvCmd.AddCommand(configEnvClearCmd)

	// Add secret commands
	configSecretCmd.AddCommand(configSecretSetCmd)
	configSecretCmd.AddCommand(configSecretUnsetCmd)
	configSecretCmd.AddCommand(configSecretListCmd)
	configSecretCmd.AddCommand(configSecretClearCmd)

	// Add object commands to config
	configCmd.AddCommand(configBaseImageCmd)
	configCmd.AddCommand(configSetupCommandCmd)
	configCmd.AddCommand(configInstallCommandCmd)
	configCmd.AddCommand(configEnvCmd)
	configCmd.AddCommand(configSecretCmd)
	configCmd.AddCommand(configShowCmd)
	configCmd.AddCommand(configImportCmd)

	// Add agent command
	configCmd.AddCommand(agent.AgentCmd)

	// Add config command to root
	rootCmd.AddCommand(configCmd)
}



================================================
FILE: cmd/container-use/delete.go
================================================
package main

import (
	"fmt"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var deleteCmd = &cobra.Command{
	Use:   "delete [<env>...]",
	Short: "Delete environments and start fresh",
	Long: `Delete one or more environments and their associated resources.
This permanently removes the environment's branch and container state.
Use this when starting over with a different approach.

Use --all to delete all environments at once.`,
	Args: func(cmd *cobra.Command, args []string) error {
		all, _ := cmd.Flags().GetBool("all")
		if all && len(args) > 0 {
			return fmt.Errorf("cannot specify environment names when using --all flag")
		}
		if !all && len(args) == 0 {
			return fmt.Errorf("must specify at least one environment name or use --all flag")
		}
		return nil
	},
	ValidArgsFunction: suggestEnvironments,
	Example: `# Delete a single environment
container-use delete fancy-mallard

# Delete multiple environments at once
container-use delete env1 env2 env3

# Delete all environments
container-use delete --all`,
	RunE: func(cmd *cobra.Command, args []string) error {
		ctx := cmd.Context()
		all, _ := cmd.Flags().GetBool("all")

		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return fmt.Errorf("failed to open repository: %w", err)
		}

		var envIDs []string
		if all {
			// Get all environment IDs
			envs, err := repo.List(ctx)
			if err != nil {
				return fmt.Errorf("failed to list environments: %w", err)
			}
			if len(envs) == 0 {
				fmt.Println("No environments found to delete.")
				return nil
			}
			for _, env := range envs {
				envIDs = append(envIDs, env.ID)
			}
			fmt.Printf("Deleting %d environment(s)...\n", len(envIDs))
		} else {
			envIDs = args
		}

		for _, envID := range envIDs {
			if err := repo.Delete(ctx, envID); err != nil {
				return fmt.Errorf("failed to delete environment '%s': %w", envID, err)
			}
			fmt.Printf("Environment '%s' deleted successfully.\n", envID)
		}

		if all {
			fmt.Printf("Successfully deleted %d environment(s).\n", len(envIDs))
		}

		return nil
	},
}

func init() {
	rootCmd.AddCommand(deleteCmd)
	deleteCmd.Flags().Bool("all", false, "Delete all environments")
}



================================================
FILE: cmd/container-use/diff.go
================================================
package main

import (
	"os"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var diffCmd = &cobra.Command{
	Use:   "diff [<env>]",
	Short: "Show what files an agent changed",
	Long: `Display the code changes made by an agent in an environment.
Shows a git diff between the environment's state and your current branch.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# See what changes the agent made
container-use diff fancy-mallard

# Quick assessment before merging
container-use diff backend-api

# Auto-select environment
container-use diff`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		return repo.Diff(ctx, envID, os.Stdout)
	},
}

func init() {
	rootCmd.AddCommand(diffCmd)
}



================================================
FILE: cmd/container-use/docker_errors.go
================================================
package main

import (
	"fmt"
	"os"
	"strings"
)

// isDockerDaemonError checks if the error is related to Docker daemon connectivity
func isDockerDaemonError(err error) bool {
	if err == nil {
		return false
	}

	errStr := strings.ToLower(err.Error())

	// Linux: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
	if strings.Contains(errStr, "cannot connect to the docker daemon") {
		return true
	}

	// Windows: error during connect: Get "http://%2F%2F.%2Fpipe%2FdockerDesktopLinuxEngine/v1.51/containers/json": open //./pipe/dockerDesktopLinuxEngine: The system cannot find the file specified.
	if strings.Contains(errStr, "error during connect") && strings.Contains(errStr, "pipe/dockerdesktoplinuxengine") && strings.Contains(errStr, "the system cannot find the file specified") {
		return true
	}

	// macOS: request returned 500 Internal Server Error for API route and version http://%2FUsers%2Fb1tank%2F.docker%2Frun%2Fdocker.sock/v1.50/containers/json, check if the server supports the requested API version
	if strings.Contains(errStr, "request returned 500 internal server error") && strings.Contains(errStr, "docker.sock") && strings.Contains(errStr, "check if the server supports the requested api version") {
		return true
	}

	// Generic fallbacks
	return strings.Contains(errStr, "docker daemon") ||
		strings.Contains(errStr, "docker.sock")
}

// handleDockerDaemonError prints a helpful error message for Docker daemon issues
func handleDockerDaemonError() {
	fmt.Fprintf(os.Stderr, "\nError: Docker daemon is not running.\n")
	fmt.Fprintf(os.Stderr, "Please start Docker and try again.\n\n")
}



================================================
FILE: cmd/container-use/docker_errors_test.go
================================================
package main

import (
	"errors"
	"testing"
)

func TestIsDockerDaemonError(t *testing.T) {
	tests := []struct {
		name     string
		err      error
		expected bool
	}{
		{
			name:     "nil error",
			err:      nil,
			expected: false,
		},
		{
			name:     "docker daemon error - linux",
			err:      errors.New("Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?"),
			expected: true,
		},
		{
			name:     "docker daemon error - windows",
			err:      errors.New("error during connect: Get \"http://%2F%2F.%2Fpipe%2FdockerDesktopLinuxEngine/v1.51/containers/json\": open //./pipe/dockerDesktopLinuxEngine: The system cannot find the file specified."),
			expected: true,
		},
		{
			name:     "docker daemon error - macos",
			err:      errors.New("request returned 500 Internal Server Error for API route and version http://%2FUsers%2Fb1tank%2F.docker%2Frun%2Fdocker.sock/v1.50/containers/json, check if the server supports the requested API version"),
			expected: true,
		},
		{
			name:     "docker daemon error - generic",
			err:      errors.New("docker daemon is not running"),
			expected: true,
		},
		{
			name:     "docker socket error - generic",
			err:      errors.New("connection to docker.sock failed"),
			expected: true,
		},
		{
			name:     "other error",
			err:      errors.New("some other error"),
			expected: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			if got := isDockerDaemonError(tt.err); got != tt.expected {
				t.Errorf("isDockerDaemonError() = %v, want %v", got, tt.expected)
			}
		})
	}
}



================================================
FILE: cmd/container-use/env_selection.go
================================================
package main

import (
	"context"
	"errors"
	"fmt"
	"strings"

	"github.com/charmbracelet/huh"
	"github.com/dagger/container-use/environment"
	"github.com/dagger/container-use/repository"
)

// resolveEnvironmentID resolves the environment ID for commands that take env_id as the only positional argument.
// If no args are provided, it filters environments to those where the local repo head is a parent of the environment's head,
// then either auto-selects if there's only one match or prompts the user to select from multiple options.
func resolveEnvironmentID(ctx context.Context, repo *repository.Repository, args []string) (string, error) {
	if len(args) == 1 {
		return args[0], nil
	}
	if len(args) > 1 {
		return "", errors.New("too many arguments")
	}

	// Get current user repo head - this could easily go inside ListDescendantEnvironments, but keeping it outside simplifies testing
	currentHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
	if err != nil {
		return "", fmt.Errorf("failed to get current HEAD: %w", err)
	}
	currentHead = strings.TrimSpace(currentHead)

	// Get environments that are descendants of current HEAD
	filteredEnvs, err := repo.ListDescendantEnvironments(ctx, currentHead)
	if err != nil {
		return "", fmt.Errorf("failed to list descendant environments: %w", err)
	}

	if len(filteredEnvs) == 0 {
		return "", errors.New("no environments found that are descendants of the current HEAD")
	}

	// If only one environment matches, use it
	if len(filteredEnvs) == 1 {
		return filteredEnvs[0].ID, nil
	}

	// Multiple environments - prompt user to select
	return promptForEnvironmentSelection(filteredEnvs)
}

// promptForEnvironmentSelection prompts the user to select from multiple environments
func promptForEnvironmentSelection(envs []*environment.EnvironmentInfo) (string, error) {
	var options []huh.Option[string]

	for _, env := range envs {
		title := env.State.Title
		if title == "" {
			title = "No description"
		}

		label := fmt.Sprintf("%s - %s", env.ID, title)
		options = append(options, huh.NewOption(label, env.ID))
	}

	var selectedID string
	prompt := huh.NewSelect[string]().
		Title("Select an environment:").
		Options(options...).
		Value(&selectedID)

	if err := prompt.Run(); err != nil {
		return "", err
	}

	return selectedID, nil
}



================================================
FILE: cmd/container-use/env_selection_test.go
================================================
package main

import (
	"context"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestResolveEnvironmentID(t *testing.T) {
	t.Run("WithSingleArg", func(t *testing.T) {
		// When one arg is provided, should return it directly
		ctx := context.Background()
		args := []string{"test-env"}

		envID, err := resolveEnvironmentID(ctx, nil, args)
		require.NoError(t, err)
		assert.Equal(t, "test-env", envID)
	})

	t.Run("WithMultipleArgs", func(t *testing.T) {
		// When multiple args are provided, should return an error
		ctx := context.Background()
		args := []string{"test-env", "other-arg"}

		_, err := resolveEnvironmentID(ctx, nil, args)
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "too many arguments")
	})

	// Note: Testing with no args requires a real repository and is tested
	// in environment/integration/environment_selection_test.go
}



================================================
FILE: cmd/container-use/inspect.go
================================================
package main

import (
	"encoding/json"
	"fmt"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var inspectCmd = &cobra.Command{
	Use:               "inspect [<env>]",
	Short:             "Inspect an environment",
	Long:              "This is an internal command used by the CLI to inspect an environment. It is not meant to be used by users.",
	Args:              cobra.MaximumNArgs(1),
	Hidden:            true,
	ValidArgsFunction: suggestEnvironments,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		envInfo, err := repo.Info(ctx, envID)
		if err != nil {
			return err
		}

		envInfo.State.Container = ""
		out, err := json.MarshalIndent(envInfo, "", "  ")
		if err != nil {
			return err
		}

		fmt.Println(string(out))
		return nil
	},
}

func init() {
	rootCmd.AddCommand(inspectCmd)
}



================================================
FILE: cmd/container-use/list.go
================================================
package main

import (
	"fmt"
	"os"
	"text/tabwriter"

	"github.com/dagger/container-use/repository"
	"github.com/dustin/go-humanize"
	"github.com/spf13/cobra"
)

var listCmd = &cobra.Command{
	Use:   "list",
	Short: "List all environments",
	Long: `Display all active environments with their IDs, titles, and timestamps.
Use -q for environment IDs only, useful for scripting.`,
	RunE: func(app *cobra.Command, _ []string) error {
		ctx := app.Context()
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}
		envInfos, err := repo.List(ctx)
		if err != nil {
			return err
		}
		if quiet, _ := app.Flags().GetBool("quiet"); quiet {
			for _, envInfo := range envInfos {
				fmt.Println(envInfo.ID)
			}
			return nil
		}

		tw := tabwriter.NewWriter(os.Stdout, 0, 0, 2, ' ', 0)
		fmt.Fprintln(tw, "ID\tTITLE\tCREATED\tUPDATED")

		defer tw.Flush()
		for _, envInfo := range envInfos {
			fmt.Fprintf(tw, "%s\t%s\t%s\t%s\n", envInfo.ID, truncate(app, envInfo.State.Title, 40), humanize.Time(envInfo.State.CreatedAt), humanize.Time(envInfo.State.UpdatedAt))
		}
		return nil
	},
}

func truncate(app *cobra.Command, s string, max int) string {
	if noTrunc, _ := app.Flags().GetBool("no-trunc"); noTrunc {
		return s
	}
	if len(s) > max {
		return s[:max] + "‚Ä¶"
	}
	return s
}

func init() {
	listCmd.Flags().BoolP("quiet", "q", false, "Display only environment IDs")
	listCmd.Flags().BoolP("no-trunc", "", false, "Don't truncate output")
	rootCmd.AddCommand(listCmd)
}



================================================
FILE: cmd/container-use/log.go
================================================
package main

import (
	"os"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var logCmd = &cobra.Command{
	Use:   "log [<env>]",
	Short: "View what an agent did step-by-step",
	Long: `Display the complete development history for an environment.
Shows all commits made by the agent plus command execution notes.
Use -p to include code patches in the output.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# See what agent did
container-use log fancy-mallard

# Include code changes
container-use log fancy-mallard -p

# Auto-select environment
container-use log`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		patch, _ := app.Flags().GetBool("patch")

		return repo.Log(ctx, envID, patch, os.Stdout)
	},
}

func init() {
	logCmd.Flags().BoolP("patch", "p", false, "Generate patch")
	rootCmd.AddCommand(logCmd)
}



================================================
FILE: cmd/container-use/logger.go
================================================
package main

import (
	"fmt"
	"io"
	"log/slog"
	"os"
	"path/filepath"
	"time"
)

var (
	logWriter = io.Discard
)

func parseLogLevel(levelStr string) slog.Level {
	switch levelStr {
	case "debug", "DEBUG":
		return slog.LevelDebug
	case "info", "INFO":
		return slog.LevelInfo
	case "warn", "WARN", "warning", "WARNING":
		return slog.LevelWarn
	case "error", "ERROR":
		return slog.LevelError
	default:
		return slog.LevelInfo
	}
}

func setupLogger() error {
	var writers []io.Writer

	logFile := filepath.Join(os.TempDir(), "container-use.debug.stderr.log")
	if v, ok := os.LookupEnv("CONTAINER_USE_STDERR_FILE"); ok {
		logFile = v
	}

	file, err := os.OpenFile(logFile, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		return fmt.Errorf("failed to open log file %s: %w", logFile, err)
	}
	writers = append(writers, file)

	if len(writers) == 0 {
		fmt.Fprintf(os.Stderr, "%s Logging disabled. Set CONTAINER_USE_STDERR_FILE and CONTAINER_USE_LOG_LEVEL environment variables\n", time.Now().Format(time.DateTime))
	}

	logLevel := parseLogLevel(os.Getenv("CONTAINER_USE_LOG_LEVEL"))
	logWriter = io.MultiWriter(writers...)
	handler := slog.NewTextHandler(logWriter, &slog.HandlerOptions{
		Level: logLevel,
	})
	slog.SetDefault(slog.New(handler))

	return nil
}



================================================
FILE: cmd/container-use/main.go
================================================
package main

import (
	"context"
	_ "embed"
	"fmt"
	"os"

	"github.com/charmbracelet/fang"
	"github.com/dagger/container-use/repository"
	"github.com/dustin/go-humanize"
	"github.com/spf13/cobra"
	"golang.org/x/term"
)

var (
	rootCmd = &cobra.Command{
		Use:   "container-use",
		Short: "Containerized environments for coding agents",
		Long: `Container Use creates isolated development environments for AI agents.
Each environment runs in its own container with dedicated git branches.`,
	}
)

func main() {
	ctx := context.Background()
	setupSignalHandling()

	if err := setupLogger(); err != nil {
		fmt.Fprintf(os.Stderr, "Failed to setup logger: %v\n", err)
		os.Exit(1)
	}

	// FIXME(aluzzardi): `fang` misbehaves with the `stdio` command.
	// It hangs on Ctrl-C. Traced the hang back to `lipgloss.HasDarkBackground(os.Stdin, os.Stdout)`
	// I'm assuming it's not playing nice the mcpserver listening on stdio.
	if len(os.Args) > 1 && os.Args[1] == "stdio" {
		if err := rootCmd.ExecuteContext(ctx); err != nil {
			os.Exit(1)
		}
		return
	}

	if err := fang.Execute(
		ctx,
		rootCmd,
		fang.WithVersion(version),
		fang.WithCommit(commit),
		fang.WithNotifySignal(getNotifySignals()...),
	); err != nil {
		os.Exit(1)
	}
}

func getTerminalWidth() int {
	width, _, err := term.GetSize(int(os.Stdout.Fd()))
	if err != nil {
		// Default to 120 columns if we can't detect terminal size -- this seems common
		return 120
	}
	return width
}

// calculateMaxTitleLength calculates the maximum length for title truncation
// based on terminal width, leaving room for environment ID, description format, and padding
func calculateMaxTitleLength(terminalWidth int) int {
	// Format: "env-id	description: title (updated time ago)"
	// We need to account for:
	// - Environment ID (typically 8-15 chars like "adapted-tetra")
	// - Tab separator (1 char)
	// - Description prefix/suffix like " (updated " and ")"
	// - Time string like "2 hours ago" (typically 5-15 chars)
	// - Some padding for safety

	const (
		avgEnvIDLength = 12 // typical environment ID length
		tabSeparator   = 1  // tab character
		descSuffix     = 11 // " (updated "
		avgTimeLength  = 10 // "2 hours ago"
		closeParen     = 1  // ")"
		padding        = 5  // safety padding
	)

	usedSpace := avgEnvIDLength + tabSeparator + descSuffix + avgTimeLength + closeParen + padding
	maxTitleLength := terminalWidth - usedSpace

	// Ensure we have a reasonable minimum and maximum
	if maxTitleLength < 10 {
		return 10 // minimum readable length
	}
	if maxTitleLength > 100 {
		return 100 // reasonable maximum
	}

	return maxTitleLength
}

func suggestEnvironments(cmd *cobra.Command, args []string, toComplete string) ([]string, cobra.ShellCompDirective) {
	ctx := cmd.Context()

	repo, err := repository.Open(ctx, ".")
	if err != nil {
		return nil, cobra.ShellCompDirectiveError
	}

	// Use the standard List method - it's already parallelized and works correctly
	envs, err := repo.List(ctx)
	if err != nil {
		return nil, cobra.ShellCompDirectiveError
	}

	// If no environments found, return directive that prevents fallback to file completion
	if len(envs) == 0 {
		return []string{}, cobra.ShellCompDirectiveNoFileComp
	}

	// Create completions with descriptions showing title and update time
	terminalWidth := getTerminalWidth()
	maxTitleLength := calculateMaxTitleLength(terminalWidth)

	completions := make([]string, len(envs))
	for i, env := range envs {
		title := env.State.Title
		if len(title) > maxTitleLength {
			title = title[:maxTitleLength] + "‚Ä¶"
		}
		description := fmt.Sprintf("%s (updated %s)", title, humanize.Time(env.State.UpdatedAt))
		completions[i] = cobra.CompletionWithDesc(env.ID, description)
	}

	return completions, cobra.ShellCompDirectiveNoFileComp
}



================================================
FILE: cmd/container-use/main_suite_test.go
================================================
package main_test

import (
	"context"
	"os"
	"os/exec"
	"path/filepath"
	"sync"
	"testing"

	"github.com/stretchr/testify/require"
)

var (
	binaryPath     string
	binaryPathOnce sync.Once
)

// getContainerUseBinary builds the container-use binary once per test run
func getContainerUseBinary(t *testing.T) string {
	binaryPathOnce.Do(func() {
		t.Log("Building fresh container-use binary...")
		cmd := exec.Command("go", "build", "-o", "container-use", ".")
		cmd.Stderr = os.Stderr
		cmd.Stdout = os.Stdout
		err := cmd.Run()
		if err != nil {
			t.Fatalf("Failed to build container-use binary: %v", err)
		}

		abs, err := filepath.Abs("container-use")
		if err != nil {
			t.Fatalf("Failed to get absolute path: %v", err)
		}
		binaryPath = abs
	})
	return binaryPath
}

// setupGitRepo initializes a git repository in the given directory
func setupGitRepo(t *testing.T, repoDir string) {
	ctx := context.Background()

	cmds := [][]string{
		{"init"},
		{"config", "user.email", "test@example.com"},
		{"config", "user.name", "Test User"},
		{"config", "commit.gpgsign", "false"},
	}

	for _, cmd := range cmds {
		err := runGitCommand(ctx, repoDir, cmd...)
		require.NoError(t, err, "Failed to run git %v", cmd)
	}

	writeFile(t, repoDir, "README.md", "# E2E Test Repository\n")
	writeFile(t, repoDir, "package.json", `{
  "name": "e2e-test-project",
  "version": "1.0.0",
  "main": "index.js"
}`)

	err := runGitCommand(ctx, repoDir, "add", ".")
	require.NoError(t, err, "Failed to stage files")
	err = runGitCommand(ctx, repoDir, "commit", "-m", "Initial commit")
	require.NoError(t, err, "Failed to commit")
}

// writeFile creates a file with the given content
func writeFile(t *testing.T, repoDir, path, content string) {
	fullPath := filepath.Join(repoDir, path)
	dir := filepath.Dir(fullPath)
	err := os.MkdirAll(dir, 0755)
	require.NoError(t, err, "Failed to create dir")
	err = os.WriteFile(fullPath, []byte(content), 0644)
	require.NoError(t, err, "Failed to write file")
}

// runGitCommand runs a git command in the specified directory
func runGitCommand(ctx context.Context, dir string, args ...string) error {
	cmd := exec.CommandContext(ctx, "git", args...)
	cmd.Dir = dir
	_, err := cmd.CombinedOutput()
	return err
}



================================================
FILE: cmd/container-use/merge.go
================================================
package main

import (
	"context"
	"fmt"
	"os"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var (
	mergeDelete bool
)

var mergeCmd = &cobra.Command{
	Use:   "merge [<env>]",
	Short: "Accept an environment's work into your branch",
	Long: `Merge an environment's changes into your current git branch.
This makes the agent's work permanent in your repository.
Your working directory will be automatically stashed and restored.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# Accept agent's work into current branch
container-use merge backend-api

# Merge and delete the environment after successful merge
container-use merge -d backend-api
container-use merge --delete backend-api

# Auto-select environment
container-use merge`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		if err := repo.Merge(ctx, envID, os.Stdout); err != nil {
			return fmt.Errorf("failed to merge environment: %w", err)
		}

		return deleteAfterMerge(ctx, repo, envID, mergeDelete, "merged")
	},
}

func deleteAfterMerge(ctx context.Context, repo *repository.Repository, env string, delete bool, verb string) error {
	if !delete {
		fmt.Printf("Environment '%s' %s successfully.\n", env, verb)
		return nil
	}
	if err := repo.Delete(ctx, env); err != nil {
		return fmt.Errorf("environment '%s' %s but delete failed: %w", env, verb, err)
	}
	fmt.Printf("Environment '%s' %s and deleted successfully.\n", env, verb)
	return nil
}

func init() {
	mergeCmd.Flags().BoolVarP(&mergeDelete, "delete", "d", false, "Delete the environment after successful merge")

	rootCmd.AddCommand(mergeCmd)
}



================================================
FILE: cmd/container-use/prune.go
================================================
package main

import (
	"fmt"
	"time"

	"github.com/dagger/container-use/repository"
	"github.com/karrick/tparse"
	"github.com/spf13/cobra"
)

var pruneCmd = &cobra.Command{
	Use:   "prune",
	Short: "Delete environments older than specified age",
	Long: `Delete environments that haven't been updated within the specified time period.
This permanently removes old environments and their associated resources including
branches and container state. By default, environments older than 1 week are pruned.

Use --dry-run to see what would be deleted without actually deleting anything.
Use --before to configure the age threshold (e.g., 24h, 3d, 2w, 1mo).`,
	Example: `# Prune environments older than 1 week (default)
container-use prune

# Prune environments older than 3 days
container-use prune --before 3d

# See what would be pruned without deleting
container-use prune --dry-run

# Prune environments older than 2 weeks
container-use prune --before 2w`,
	RunE: func(cmd *cobra.Command, args []string) error {
		ctx := cmd.Context()
		before, _ := cmd.Flags().GetString("before")
		dryRun, _ := cmd.Flags().GetBool("dry-run")

		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return fmt.Errorf("failed to open repository: %w", err)
		}

		var duration time.Duration
		if before == "" {
			duration = 7 * 24 * time.Hour
		} else {
			targetTime, err := tparse.ParseNow(time.RFC3339, "now-"+before)
			if err != nil {
				return fmt.Errorf("invalid --before format: %w", err)
			}
			duration = time.Since(targetTime)
		}

		envs, err := repo.List(ctx)
		if err != nil {
			return fmt.Errorf("failed to list environments: %w", err)
		}

		if len(envs) == 0 {
			fmt.Println("No environments found.")
			return nil
		}

		cutoff := time.Now().Add(-duration)
		var envsToPrune []string

		for _, env := range envs {
			if env.State.UpdatedAt.Before(cutoff) {
				envsToPrune = append(envsToPrune, env.ID)
			}
		}

		if len(envsToPrune) == 0 {
			fmt.Printf("No environments older than %s found.\n", duration)
			return nil
		}

		if dryRun {
			fmt.Printf("Would prune %d environment(s) older than %s:\n", len(envsToPrune), duration)
			for _, envID := range envsToPrune {
				fmt.Printf("  - %s\n", envID)
			}
			return nil
		}

		fmt.Printf("Pruning %d environment(s) older than %s...\n", len(envsToPrune), duration)

		var deletedCount int
		for _, envID := range envsToPrune {
			if err := repo.Delete(ctx, envID); err != nil {
				fmt.Printf("Failed to delete environment '%s': %v\n", envID, err)
			} else {
				fmt.Printf("Environment '%s' deleted successfully.\n", envID)
				deletedCount++
			}
		}

		fmt.Printf("Successfully deleted %d environment(s).\n", deletedCount)
		return nil
	},
}

func init() {
	rootCmd.AddCommand(pruneCmd)
	pruneCmd.Flags().String("before", "1w", "Delete environments older than this duration (e.g., 24h, 3d, 2w, 1mo)")
	pruneCmd.Flags().Bool("dry-run", false, "Show what would be pruned without actually deleting")
}



================================================
FILE: cmd/container-use/signal_unix.go
================================================
//go:build !windows

package main

import (
	"io"
	"os"
	"os/signal"
	"runtime"
	"syscall"
)

func setupSignalHandling() {
	sigusrCh := make(chan os.Signal, 1)
	signal.Notify(sigusrCh, syscall.SIGUSR1)
	go handleSIGUSR(sigusrCh)
}

func handleSIGUSR(sigusrCh <-chan os.Signal) {
	for sig := range sigusrCh {
		if sig == syscall.SIGUSR1 {
			dumpStacks()
		}
	}
}

func dumpStacks() {
	buf := make([]byte, 1<<20) // 1MB buffer
	n := runtime.Stack(buf, true)
	io.MultiWriter(logWriter, os.Stderr).Write(buf[:n])
}



================================================
FILE: cmd/container-use/signal_windows.go
================================================
//go:build windows

package main

// On Windows, SIGUSR1 is not available, so we provide a no-op implementation
func setupSignalHandling() {
	// No special signal handling on Windows
}



================================================
FILE: cmd/container-use/signals_unix.go
================================================
//go:build !windows

package main

import (
	"os"
	"syscall"
)

// getNotifySignals returns Unix-compatible signals
func getNotifySignals() []os.Signal {
	return []os.Signal{os.Interrupt, os.Kill, syscall.SIGTERM}
}



================================================
FILE: cmd/container-use/signals_windows.go
================================================
//go:build windows

package main

import (
	"os"
	"syscall"
)

// getNotifySignals returns Windows-compatible signals for receiving
func getNotifySignals() []os.Signal {
	// On Windows:
	// - os.Interrupt: Ctrl+C signal (can receive, cannot send to other processes)
	// - syscall.SIGTERM: Termination signal (can receive) (https://pkg.go.dev/os/signal#hdr-Windows)
	// - os.Kill: Not a receivable signal
	return []os.Signal{os.Interrupt, syscall.SIGTERM}
}



================================================
FILE: cmd/container-use/stdio.go
================================================
package main

import (
	"log/slog"
	"os"

	"dagger.io/dagger"
	"github.com/dagger/container-use/mcpserver"
	"github.com/spf13/cobra"
)

var singleTenant bool

var stdioCmd = &cobra.Command{
	Use:   "stdio",
	Short: "Start MCP server for agent integration",
	Long:  `Start the Model Context Protocol server that enables AI agents to create and manage containerized environments. This is typically used by agents like Claude Code, Cursor, or VSCode.`,
	RunE: func(app *cobra.Command, _ []string) error {
		ctx := app.Context()

		slog.Info("connecting to dagger")

		dag, err := dagger.Connect(ctx, dagger.WithLogOutput(logWriter))
		if err != nil {
			slog.Error("Error starting dagger", "error", err)

			if isDockerDaemonError(err) {
				handleDockerDaemonError()
			}

			os.Exit(1)
		}
		defer dag.Close()

		return mcpserver.RunStdioServer(ctx, dag, singleTenant)
	},
}

func init() {
	stdioCmd.Flags().BoolVar(&singleTenant, "single-tenant", false, "Enable single-tenant mode where environment ID is optional (assumes one session per server)")
	rootCmd.AddCommand(stdioCmd)
}



================================================
FILE: cmd/container-use/stdio_test.go
================================================
package main_test

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"strings"
	"sync"
	"testing"

	"github.com/mark3labs/mcp-go/client"
	"github.com/mark3labs/mcp-go/mcp"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// MCPServerProcess represents a running container-use MCP server
type MCPServerProcess struct {
	cmd        *exec.Cmd
	client     *client.Client
	repoDir    string
	configDir  string
	serverInfo *mcp.InitializeResult
	t          *testing.T
}

// NewMCPServerProcess starts a new container-use MCP server process
func NewMCPServerProcess(t *testing.T, testName string) *MCPServerProcess {
	ctx := context.Background()

	repoDir, err := os.MkdirTemp("", fmt.Sprintf("cu-e2e-%s-repo-*", testName))
	require.NoError(t, err, "Failed to create repo dir")

	configDir, err := os.MkdirTemp("", fmt.Sprintf("cu-e2e-%s-config-*", testName))
	require.NoError(t, err, "Failed to create config dir")

	setupGitRepo(t, repoDir)

	containerUseBinary := getContainerUseBinary(t)
	cmd := exec.CommandContext(ctx, containerUseBinary, "stdio")
	cmd.Dir = repoDir
	cmd.Env = append(os.Environ(), fmt.Sprintf("CONTAINER_USE_CONFIG_DIR=%s", configDir))

	mcpClient, err := client.NewStdioMCPClient(containerUseBinary, cmd.Env, "stdio")
	require.NoError(t, err, "Failed to create MCP client")
	initRequest := mcp.InitializeRequest{}
	initRequest.Params.ProtocolVersion = mcp.LATEST_PROTOCOL_VERSION
	initRequest.Params.ClientInfo = mcp.Implementation{
		Name:    fmt.Sprintf("E2E Test Client - %s", testName),
		Version: "1.0.0",
	}
	initRequest.Params.Capabilities = mcp.ClientCapabilities{}

	serverInfo, err := mcpClient.Initialize(ctx, initRequest)
	require.NoError(t, err, "Failed to initialize MCP client")

	server := &MCPServerProcess{
		cmd:        cmd,
		client:     mcpClient,
		repoDir:    repoDir,
		configDir:  configDir,
		serverInfo: serverInfo,
		t:          t,
	}

	t.Cleanup(func() {
		server.Close()
	})

	return server
}

// Close shuts down the MCP server process and cleans up resources
func (s *MCPServerProcess) Close() {
	if s.client != nil {
		s.client.Close()
	}
	if s.cmd != nil && s.cmd.Process != nil {
		s.cmd.Process.Kill()
		s.cmd.Wait()
	}
	os.RemoveAll(s.repoDir)
	os.RemoveAll(s.configDir)
}

// CreateEnvironment creates a new environment via MCP
func (s *MCPServerProcess) CreateEnvironment(title, explanation string) (string, error) {
	ctx := context.Background()

	request := mcp.CallToolRequest{}
	request.Params.Name = "environment_create"
	request.Params.Arguments = map[string]any{
		"environment_source": s.repoDir,
		"title":              title,
		"explanation":        explanation,
	}

	result, err := s.client.CallTool(ctx, request)
	if err != nil {
		return "", err
	}

	// Check if the tool call resulted in an error
	if result.IsError && len(result.Content) > 0 {
		if textContent, ok := result.Content[0].(mcp.TextContent); ok {
			return "", fmt.Errorf("environment creation failed: %s", textContent.Text)
		}
		return "", fmt.Errorf("environment creation failed with unknown error format")
	}

	if len(result.Content) > 0 {
		if textContent, ok := result.Content[0].(mcp.TextContent); ok {
			var envResponse struct {
				ID string `json:"id"`
			}
			if err := json.Unmarshal([]byte(textContent.Text), &envResponse); err != nil {
				return "", fmt.Errorf("failed to parse environment response (content: %q): %w", textContent.Text, err)
			}
			return envResponse.ID, nil
		}
	}

	return "", fmt.Errorf("no valid response content found")
}

// FileRead reads a file from an environment via MCP
func (s *MCPServerProcess) FileRead(envID, targetFile string) (string, error) {
	ctx := context.Background()

	request := mcp.CallToolRequest{}
	request.Params.Name = "environment_file_read"
	request.Params.Arguments = map[string]any{
		"environment_source":      s.repoDir,
		"environment_id":          envID,
		"target_file":             targetFile,
		"should_read_entire_file": true,
		"explanation":             "Reading file for verification",
	}

	result, err := s.client.CallTool(ctx, request)
	if err != nil {
		return "", err
	}

	if len(result.Content) > 0 {
		if textContent, ok := result.Content[0].(mcp.TextContent); ok {
			return textContent.Text, nil
		}
	}

	return "", nil
}

// FileWrite writes a file to an environment via MCP
func (s *MCPServerProcess) FileWrite(envID, targetFile, contents, explanation string) error {
	ctx := context.Background()

	request := mcp.CallToolRequest{}
	request.Params.Name = "environment_file_write"
	request.Params.Arguments = map[string]any{
		"environment_source": s.repoDir,
		"environment_id":     envID,
		"target_file":        targetFile,
		"contents":           contents,
		"explanation":        explanation,
	}

	_, err := s.client.CallTool(ctx, request)
	return err
}

// RunCommand executes a command in an environment via MCP
func (s *MCPServerProcess) RunCommand(envID, command, explanation string) (string, error) {
	ctx := context.Background()

	request := mcp.CallToolRequest{}
	request.Params.Name = "environment_run_cmd"
	request.Params.Arguments = map[string]any{
		"environment_source": s.repoDir,
		"environment_id":     envID,
		"command":            command,
		"explanation":        explanation,
	}

	result, err := s.client.CallTool(ctx, request)
	if err != nil {
		return "", err
	}

	if len(result.Content) > 0 {
		if textContent, ok := result.Content[0].(mcp.TextContent); ok {
			return textContent.Text, nil
		}
	}

	return "", nil
}

// createMCPServerForRepositoryTest creates an MCP server process for repository contention testing
func createMCPServerForRepositoryTest(t *testing.T, i int, repoDir, configDir string, singleTenant bool) *MCPServerProcess {
	ctx := context.Background()
	containerUseBinary := getContainerUseBinary(t)

	var cmd *exec.Cmd
	var clientArgs []string
	if singleTenant {
		cmd = exec.CommandContext(ctx, containerUseBinary, "stdio", "--single-tenant")
		clientArgs = []string{"stdio", "--single-tenant"}
	} else {
		cmd = exec.CommandContext(ctx, containerUseBinary, "stdio")
		clientArgs = []string{"stdio"}
	}

	cmd.Dir = repoDir
	cmd.Env = append(os.Environ(), fmt.Sprintf("CONTAINER_USE_CONFIG_DIR=%s", configDir))

	mcpClient, err := client.NewStdioMCPClient(containerUseBinary, cmd.Env, clientArgs...)
	require.NoError(t, err)

	initRequest := mcp.InitializeRequest{}
	initRequest.Params.ProtocolVersion = mcp.LATEST_PROTOCOL_VERSION
	initRequest.Params.ClientInfo = mcp.Implementation{
		Name:    fmt.Sprintf("Repository Test Client %d", i),
		Version: "1.0.0",
	}
	initRequest.Params.Capabilities = mcp.ClientCapabilities{}

	serverInfo, err := mcpClient.Initialize(ctx, initRequest)
	require.NoError(t, err)

	server := &MCPServerProcess{
		cmd:        cmd,
		client:     mcpClient,
		repoDir:    repoDir,
		configDir:  configDir,
		serverInfo: serverInfo,
		t:          t,
	}

	return server
}

// runRepositoryContentionTest runs the core repository contention test logic
func runRepositoryContentionTest(t *testing.T, servers []*MCPServerProcess, testPrefix string) {
	numServers := len(servers)
	var wg sync.WaitGroup
	envIDs := make([]string, numServers)
	errors := make([]error, numServers)

	for i := range numServers {
		wg.Add(1)
		go func(serverIdx int) {
			defer wg.Done()

			envID, err := servers[serverIdx].CreateEnvironment(
				fmt.Sprintf("%s Test %d", testPrefix, serverIdx),
				fmt.Sprintf("Testing %s repository contention %d", testPrefix, serverIdx),
			)
			if err != nil {
				errors[serverIdx] = fmt.Errorf("environment creation failed: %w", err)
				return
			}
			envIDs[serverIdx] = envID

			for j := range 3 {
				err := servers[serverIdx].FileWrite(
					envID,
					fmt.Sprintf("server%d_file%d.txt", serverIdx, j),
					fmt.Sprintf("Content from server %d, file %d\nTimestamp: concurrent test", serverIdx, j),
					fmt.Sprintf("Writing file %d from server %d", j, serverIdx),
				)
				if err != nil {
					errors[serverIdx] = fmt.Errorf("file write failed: %w", err)
					return
				}
			}

			content, err := servers[serverIdx].FileRead(envID, fmt.Sprintf("server%d_file0.txt", serverIdx))
			if err != nil {
				errors[serverIdx] = fmt.Errorf("file read failed: %w", err)
				return
			}
			if content == "" {
				errors[serverIdx] = fmt.Errorf("file read returned empty content")
				return
			}

			listOutput, err := servers[serverIdx].RunCommand(
				envID,
				fmt.Sprintf("ls -la server%d_*.txt | wc -l", serverIdx),
				"Count files created by this server",
			)
			if err != nil {
				errors[serverIdx] = fmt.Errorf("command execution failed: %w", err)
				return
			}

			lines := strings.Split(strings.TrimSpace(listOutput), "\n")
			if len(lines) == 0 {
				errors[serverIdx] = fmt.Errorf("command returned empty output")
				return
			}
			firstLine := lines[0]
			if firstLine != "3" {
				errors[serverIdx] = fmt.Errorf("expected 3 files, got output: %q (first line: %q)", listOutput, firstLine)
				return
			}

			_, err = servers[serverIdx].RunCommand(
				envID,
				fmt.Sprintf("echo 'Server %d completed successfully' > completion_%d.txt", serverIdx, serverIdx),
				"Mark completion",
			)
			if err != nil {
				errors[serverIdx] = fmt.Errorf("completion command failed: %w", err)
				return
			}
		}(i)
	}

	wg.Wait()

	for i := range numServers {
		assert.NoError(t, errors[i], "Server %d should handle %s repository contention successfully", i, testPrefix)
		assert.NotEmpty(t, envIDs[i], "Server %d should have environment ID", i)
	}

	envIDSet := make(map[string]bool)
	for _, envID := range envIDs {
		if envID != "" {
			assert.False(t, envIDSet[envID], "Environment ID %s should be unique", envID)
			envIDSet[envID] = true
		}
	}

	t.Logf("All %d %s servers completed successfully", numServers, testPrefix)
}

func TestRepositoryContention(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping E2E test")
	}

	const numServers = 10
	sharedRepoDir, err := os.MkdirTemp("", "cu-e2e-shared-repo-*")
	require.NoError(t, err)
	defer os.RemoveAll(sharedRepoDir)

	setupGitRepo(t, sharedRepoDir)

	sharedConfigDir, err := os.MkdirTemp("", "cu-e2e-shared-config-*")
	require.NoError(t, err)
	defer os.RemoveAll(sharedConfigDir)

	servers := make([]*MCPServerProcess, numServers)

	for i := range numServers {
		servers[i] = createMCPServerForRepositoryTest(t, i, sharedRepoDir, sharedConfigDir, false)
		t.Cleanup(func() {
			servers[i].Close()
		})
	}

	runRepositoryContentionTest(t, servers, "Multi-Tenant")
}

func TestSingleTenantRepositoryContention(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping E2E test")
	}

	const numServers = 10
	sharedRepoDir, err := os.MkdirTemp("", "cu-e2e-single-tenant-repo-*")
	require.NoError(t, err)
	defer os.RemoveAll(sharedRepoDir)

	setupGitRepo(t, sharedRepoDir)

	sharedConfigDir, err := os.MkdirTemp("", "cu-e2e-single-tenant-config-*")
	require.NoError(t, err)
	defer os.RemoveAll(sharedConfigDir)

	servers := make([]*MCPServerProcess, numServers)

	for i := range numServers {
		servers[i] = createMCPServerForRepositoryTest(t, i, sharedRepoDir, sharedConfigDir, true)
		t.Cleanup(func() {
			servers[i].Close()
		})
	}

	runRepositoryContentionTest(t, servers, "Single-Tenant")
}



================================================
FILE: cmd/container-use/terminal.go
================================================
package main

import (
	"errors"
	"fmt"
	"os"
	"os/exec"

	"dagger.io/dagger"
	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var terminalCmd = &cobra.Command{
	Use:   "terminal [<env>]",
	Short: "Get a shell inside an environment's container",
	Long: `Open an interactive terminal in the exact container environment the agent used. Perfect for debugging, testing, or hands-on exploration.

If no environment is specified, automatically selects from environments 
that are descendants of the current HEAD.`,
	Args:              cobra.MaximumNArgs(1),
	ValidArgsFunction: suggestEnvironments,
	Example: `# Drop into environment's container
container-use terminal fancy-mallard

# Debug agent's work interactively
container-use terminal backend-api

# Auto-select environment
container-use terminal`,
	RunE: func(app *cobra.Command, args []string) error {
		ctx := app.Context()

		repo, err := repository.Open(ctx, ".")
		if err != nil {
			return err
		}

		// FIXME(aluzzardi): This is a hack to make sure we're wrapped in `dagger run` since `Terminal()` only works with the CLI.
		// If not, it will auto-wrap this command in a `dagger run`.
		if _, ok := os.LookupEnv("DAGGER_SESSION_TOKEN"); !ok {
			daggerBin, err := exec.LookPath("dagger")
			if err != nil {
				if errors.Is(err, exec.ErrNotFound) {
					return fmt.Errorf("dagger is not installed. Please install it from https://docs.dagger.io/install/")
				}
				return fmt.Errorf("failed to look up dagger binary: %w", err)
			}
			return execDaggerRun(daggerBin, append([]string{"dagger", "run"}, os.Args...), os.Environ())
		}

		dag, err := dagger.Connect(ctx, dagger.WithLogOutput(os.Stderr))
		if err != nil {
			if isDockerDaemonError(err) {
				handleDockerDaemonError()
			}
			return fmt.Errorf("failed to connect to dagger: %w", err)
		}
		defer dag.Close()

		envID, err := resolveEnvironmentID(ctx, repo, args)
		if err != nil {
			return err
		}

		env, err := repo.Get(ctx, dag, envID)
		if err != nil {
			return err
		}

		return env.Terminal(ctx)
	},
}

func init() {
	rootCmd.AddCommand(terminalCmd)
}



================================================
FILE: cmd/container-use/terminal_unix.go
================================================
//go:build !windows

package main

import (
	"syscall"
)

func execDaggerRun(daggerBin string, args []string, env []string) error {
	return syscall.Exec(daggerBin, args, env)
}



================================================
FILE: cmd/container-use/terminal_windows.go
================================================
//go:build windows

package main

import (
	"fmt"
	"os"
	"os/exec"
)

func execDaggerRun(daggerBin string, args []string, env []string) error {
	cmd := exec.Command(daggerBin, args...)
	cmd.Args = append([]string{"dagger", "run"}, os.Args...)
	cmd.Env = env
	cmd.Stdin = os.Stdin
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	if err := cmd.Run(); err != nil {
		return fmt.Errorf("failed to execute dagger run: %w", err)
	}

	// On Windows, we can't replace the current process, so we exit
	os.Exit(0)
	return nil
}



================================================
FILE: cmd/container-use/version.go
================================================
package main

import (
	"context"
	"fmt"
	"os/exec"
	"regexp"
	"runtime"
	"runtime/debug"
	"strings"
	"time"

	"github.com/spf13/cobra"
)

var (
	version = "dev"
	commit  = "unknown"
	date    = "unknown"
)

const defaultTimeout = 2 * time.Second

func init() {
	if version == "dev" {
		if buildCommit, buildTime := getBuildInfoFromBinary(); buildCommit != "unknown" {
			commit = buildCommit
			date = buildTime
		}
	}

	versionCmd.Flags().BoolP("system", "s", false, "Show system information")
	rootCmd.AddCommand(versionCmd)
}

var versionCmd = &cobra.Command{
	Use:   "version",
	Short: "Print version information",
	Long:  `Print the version, commit hash, and build date of the container-use binary.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		showSystem, _ := cmd.Flags().GetBool("system")

		// Always show basic version info
		cmd.Printf("container-use version %s\n", version)
		if commit != "unknown" {
			cmd.Printf("commit: %s\n", commit)
		}
		if date != "unknown" {
			cmd.Printf("built: %s\n", date)
		}

		if showSystem {
			cmd.Printf("\nSystem:\n")
			cmd.Printf("  OS/Arch: %s/%s\n", runtime.GOOS, runtime.GOARCH)

			// Check container runtime
			if runtime := detectContainerRuntime(cmd.Context()); runtime != nil {
				cmd.Printf("  Container Runtime: %s\n", runtime)
			} else {
				cmd.Printf("  Container Runtime: not found\n")
			}

			// Check Git
			if version := getToolVersion(cmd.Context(), "git", "--version"); version != "" {
				cmd.Printf("  Git: %s\n", version)
			} else {
				cmd.Printf("  Git: not found\n")
			}

			// Check Dagger CLI
			if version := getToolVersion(cmd.Context(), "dagger", "version"); version != "" {
				cmd.Printf("  Dagger CLI: %s\n", version)
			} else {
				cmd.Printf("  Dagger CLI: not found (needed for 'terminal' command)\n")
			}
		}

		return nil
	},
}

// runtimeInfo holds container runtime information
type runtimeInfo struct {
	Name    string
	Version string
	Running bool
}

func (r *runtimeInfo) String() string {
	if !r.Running {
		return fmt.Sprintf("%s %s (daemon not running)", r.Name, r.Version)
	}
	return fmt.Sprintf("%s %s", r.Name, r.Version)
}

// detectContainerRuntime finds the first available container runtime
func detectContainerRuntime(ctx context.Context) *runtimeInfo {
	// Check in the same order as Dagger
	runtimes := []struct {
		command string
		name    string
	}{
		{"docker", "Docker"},
		{"podman", "Podman"},
		{"nerdctl", "nerdctl"},
		{"finch", "finch"},
	}

	for _, rt := range runtimes {
		if info := checkRuntime(ctx, rt.command, rt.name); info != nil {
			return info
		}
	}
	return nil
}

// checkRuntime checks if a specific runtime is available
func checkRuntime(ctx context.Context, command, name string) *runtimeInfo {
	// Check if command exists
	if _, err := exec.LookPath(command); err != nil {
		return nil
	}

	info := &runtimeInfo{
		Name:    name,
		Version: "unknown",
	}

	// Get version
	ctx, cancel := context.WithTimeout(ctx, defaultTimeout)
	defer cancel()

	if out, err := exec.CommandContext(ctx, command, "--version").Output(); err == nil {
		info.Version = extractVersion(string(out))
	}

	// Check if daemon is running
	cmd := exec.CommandContext(ctx, command, "info")
	cmd.Stdout = nil // discard output
	cmd.Stderr = nil
	info.Running = cmd.Run() == nil

	return info
}

var versionRegex = regexp.MustCompile(`v?(\d+\.\d+(?:\.\d+)?)`)

// extractVersion finds a version number in the output
func extractVersion(output string) string {
	if matches := versionRegex.FindStringSubmatch(output); len(matches) > 1 {
		return matches[1]
	}
	return "unknown"
}

// getToolVersion runs a command and returns its version output
func getToolVersion(ctx context.Context, tool string, args ...string) string {
	ctx, cancel := context.WithTimeout(ctx, defaultTimeout)
	defer cancel()

	out, err := exec.CommandContext(ctx, tool, args...).Output()
	if err != nil {
		return ""
	}

	output := strings.TrimSpace(string(out))

	// Handle specific tools
	switch tool {
	case "git":
		// "git version 2.39.3" -> "2.39.3"
		return strings.TrimPrefix(output, "git version ")
	case "dagger":
		// "dagger vX.Y.Z (...)" -> "vX.Y.Z"
		fields := strings.Fields(output)
		if len(fields) > 1 {
			return fields[1]
		}
	}

	return output
}

func getBuildInfoFromBinary() (string, string) {
	buildInfo, ok := debug.ReadBuildInfo()
	if !ok {
		return "unknown", "unknown"
	}

	var revision, buildTime, modified string
	for _, setting := range buildInfo.Settings {
		switch setting.Key {
		case "vcs.revision":
			revision = setting.Value
		case "vcs.time":
			buildTime = setting.Value
		case "vcs.modified":
			modified = setting.Value
		}
	}

	// Format commit hash
	if len(revision) > 7 {
		revision = revision[:7]
	}
	if modified == "true" {
		revision += "-dirty"
	}

	if revision == "" {
		revision = "unknown"
	}
	if buildTime == "" {
		buildTime = "unknown"
	}

	return revision, buildTime
}



================================================
FILE: cmd/container-use/version_test.go
================================================
package main

import (
	"bytes"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestVersionCommand(t *testing.T) {
	tests := []struct {
		name          string
		args          []string
		checkOutput   func(t *testing.T, output string)
		expectedError bool
	}{
		{
			name: "basic version output",
			args: []string{"version"},
			checkOutput: func(t *testing.T, output string) {
				// Should always show version, may show commit and build date
				assert.Contains(t, output, "container-use version")
				// Should not show system info without --system
				assert.NotContains(t, output, "System:")
				assert.NotContains(t, output, "Container Runtime:")
				assert.NotContains(t, output, "Git:")
			},
		},
		{
			name: "system flag shows system info",
			args: []string{"version", "--system"},
			checkOutput: func(t *testing.T, output string) {
				// Should show basic version info
				assert.Contains(t, output, "container-use version")

				// Should show system info section
				assert.Contains(t, output, "System:")
				assert.Contains(t, output, "OS/Arch:")
				assert.Contains(t, output, "Container Runtime:")
				assert.Contains(t, output, "Git:")
				assert.Contains(t, output, "Dagger CLI:")

				// Should show OS/arch format
				assert.Regexp(t, `[\w]+/[\w]+`, output)

				// Container runtime output should show one of the supported runtimes
				// This handles: "Docker 24.0.5", "Podman 4.3.1", "Docker 24.0.5 (daemon not running)", or "not found"
				assert.Regexp(t, `Container Runtime: ((Docker|Podman|nerdctl|finch) [\d\.]+(v[\d\.]+)?(\s+\(daemon not running\))?|not found)`, output)
			},
		},
		{
			name: "short flag works",
			args: []string{"version", "-s"},
			checkOutput: func(t *testing.T, output string) {
				assert.Contains(t, output, "System:")
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Create a new command instance for each test
			cmd := rootCmd
			buf := new(bytes.Buffer)
			cmd.SetOut(buf)
			cmd.SetErr(buf)
			cmd.SetArgs(tt.args)

			err := cmd.Execute()
			if tt.expectedError {
				require.Error(t, err)
			} else {
				require.NoError(t, err)
			}

			output := buf.String()
			if tt.checkOutput != nil {
				tt.checkOutput(t, output)
			}
		})
	}
}

func TestVersionParsing(t *testing.T) {
	// Test that version parsing handles common formats gracefully
	// This is a focused integration test of the parsing logic
	tests := []struct {
		name  string
		input string
		valid bool
	}{
		{
			name:  "docker standard format",
			input: "Docker version 24.0.5, build 1234567",
			valid: true,
		},
		{
			name:  "git standard format",
			input: "git version 2.39.3",
			valid: true,
		},
		{
			name:  "git with vendor info",
			input: "git version 2.39.3 (Apple Git-145)",
			valid: true,
		},
		{
			name:  "empty string",
			input: "",
			valid: false,
		},
		{
			name:  "unrelated output",
			input: "command not found",
			valid: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// This test primarily validates that our regex patterns work
			// The actual parsing is tested implicitly through the command tests
			if tt.valid {
				assert.NotEmpty(t, tt.input)
			}
		})
	}
}



================================================
FILE: cmd/container-use/watch_unix.go
================================================
//go:build !windows

package main

import (
	"time"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
	watch "github.com/tiborvass/go-watch"
)

var watchCmd = &cobra.Command{
	Use:   "watch",
	Short: "Watch environment activity in real-time",
	Long: `Continuously display environment activity as agents work.
Shows new commits and environment changes updated every second.
Press Ctrl+C to stop watching.`,
	Example: `# Watch all environment activity
container-use watch

# Monitor agents while they work
container-use watch`,
	RunE: func(app *cobra.Command, _ []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		if _, err := repository.Open(ctx, "."); err != nil {
			return err
		}

		w := watch.Watcher{Interval: time.Second}
		w.Watch(app.Context(), "git", "log", "--color=always", "--remotes=container-use", "--oneline", "--graph", "--decorate")
		return nil
	},
}

func init() {
	rootCmd.AddCommand(watchCmd)
}



================================================
FILE: cmd/container-use/watch_windows.go
================================================
//go:build windows

package main

import (
	"bufio"
	"bytes"
	"context"
	"fmt"
	"os"
	"os/exec"
	"strings"
	"time"

	"golang.org/x/term"

	"github.com/dagger/container-use/repository"
	"github.com/spf13/cobra"
)

var watchCmd = &cobra.Command{
	Use:   "watch",
	Short: "Watch environment activity in real-time",
	Long: `Continuously display environment activity as agents work.
Shows new commits and environment changes updated every second.
Press Ctrl+C to stop watching.`,
	Example: `# Watch all environment activity
container-use watch

# Monitor agents while they work
container-use watch`,
	RunE: func(app *cobra.Command, _ []string) error {
		ctx := app.Context()

		// Ensure we're in a git repository
		if _, err := repository.Open(ctx, "."); err != nil {
			return err
		}

		// Enter alternate screen buffer and hide cursor
		fmt.Print("\x1b[?1049h\x1b[?25l")
		defer fmt.Print("\x1b[?25h\x1b[?1049l") // restore screen + show cursor

		ticker := time.NewTicker(time.Second)
		defer ticker.Stop()

		// Run once immediately
		if err := runGitLogWindows(ctx); err != nil {
			return err
		}

		for {
			select {
			case <-ctx.Done():
				return nil
			case <-ticker.C:
				if err := runGitLogWindows(ctx); err != nil {
					// Don't exit on git errors, just display them and continue
					fmt.Fprintf(os.Stderr, "Warning: %v\n", err)
				}
			}
		}
	},
}

// runGitLogWindows executes the git log command with output matching Unix watch format
func runGitLogWindows(ctx context.Context) error {
	var buf bytes.Buffer

	// Clear screen and move cursor to home position
	buf.WriteString("\x1b[H\x1b[J")

	// Get hostname
	hostname, err := os.Hostname()
	if err != nil {
		hostname = "unknown"
	}

	// Format timestamp like Unix watch (Day Month DD HH:MM:SS YYYY)
	timestamp := time.Now().Format("Mon Jan 2 15:04:05 2006")

	// Create header that matches Unix watch format exactly
	gitCommand := "git log --color=always --remotes=container-use --oneline --graph --decorate"
	headerLine := fmt.Sprintf("Every 1.0s: %s", gitCommand)

	// Get terminal width, fallback to 80 if unable to determine
	terminalWidth := 80
	if width, _, err := term.GetSize(int(os.Stdout.Fd())); err == nil && width > 0 {
		terminalWidth = width
	}

	// Calculate spaces needed to right-align the hostname and timestamp
	rightPart := fmt.Sprintf("%s: %s", hostname, timestamp)
	spacesNeeded := terminalWidth - len(headerLine) - len(rightPart)

	// Write the header line with responsive spacing
	if spacesNeeded >= 1 {
		// Enough space to fit on one line - right align
		buf.WriteString(headerLine + strings.Repeat(" ", spacesNeeded) + rightPart + "\n")
	} else {
		// Not enough space - wrap to next line with minimum 1 space
		buf.WriteString(headerLine + " " + rightPart + "\n")
	}
	buf.WriteString("\n") // Empty line after header to match Unix watch format

	// Run git log command with same arguments as Unix version
	cmd := exec.CommandContext(ctx, "git", "log",
		"--color=always",
		"--remotes=container-use",
		"--oneline",
		"--graph",
		"--decorate")

	// Create pipe to capture output
	pr, pw, err := os.Pipe()
	if err != nil {
		return fmt.Errorf("failed to create pipe: %w", err)
	}

	cmd.Stdout = pw
	cmd.Stderr = pw

	// Start the command
	if err := cmd.Start(); err != nil {
		pw.Close()
		pr.Close()
		return fmt.Errorf("failed to start git log: %w", err)
	}

	// Close write end so we can read
	pw.Close()

	// Read all output into buffer
	scanner := bufio.NewScanner(pr)
	for scanner.Scan() {
		buf.WriteString(scanner.Text() + "\n")
	}

	pr.Close()

	// Wait for command to complete
	if err := cmd.Wait(); err != nil {
		return fmt.Errorf("git log failed: %w", err)
	}

	// Output everything at once for smooth rendering
	os.Stdout.Write(buf.Bytes())

	return nil
}

func init() {
	rootCmd.AddCommand(watchCmd)
}



================================================
FILE: cmd/container-use/agent/configure.go
================================================
package agent

import (
	"fmt"
	"os"
	"path/filepath"
	"runtime"
	"strings"

	"github.com/dagger/container-use/mcpserver"
	"github.com/spf13/cobra"
)

type MCPServersConfig struct {
	MCPServers map[string]MCPServer `json:"mcpServers"`
}

type MCPServer struct {
	Command       string            `json:"command"`
	Args          []string          `json:"args"`
	Env           map[string]string `json:"env,omitempty"`
	Timeout       *int              `json:"timeout,omitempty"`
	Disabled      *bool             `json:"disabled,omitempty"`
	AutoApprove   []string          `json:"autoApprove,omitempty"`
	AlwaysAllow   []string          `json:"alwaysAllow,omitempty"`
	WorkingDir    *string           `json:"working_directory,omitempty"`
	StartOnLaunch *bool             `json:"start_on_launch,omitempty"`
}

const ContainerUseBinary = "container-use"

var AgentCmd = &cobra.Command{
	Use:   "agent [agent]",
	Short: "Configure MCP server for different agents",
	Long:  `Setup the container-use MCP server according to the specified agent including Claude Code, Goose, Cursor, and others.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		if len(args) == 0 {
			return interactiveConfiguration()
		}
		agent, err := selectAgent(args[0])
		if err != nil {
			return err
		}
		return configureAgent(agent)
	},
}

func interactiveConfiguration() error {
	selectedAgent, err := RunAgentSelector()
	if err != nil {
		// If the user quits, it's not an error, just exit gracefully.
		if err.Error() == "no agent selected" {
			return nil
		}
		return fmt.Errorf("failed to select agent: %w", err)
	}

	agent, err := selectAgent(selectedAgent)
	if err != nil {
		return err
	}
	return configureAgent(agent)
}

type ConfigurableAgent interface {
	name() string
	description() string
	editMcpConfig() error
	editRules() error
	isInstalled() bool
}

// Add agents here
func selectAgent(agentKey string) (ConfigurableAgent, error) {
	// Check if agent is supported on current platform
	if runtime.GOOS == "windows" {
		switch agentKey {
		case "codex", "amazonq":
			return nil, fmt.Errorf("agent '%s' is not supported on native Windows.\nTo use this agent, please install and run container-use in Windows Subsystem for Linux (WSL)", agentKey)
		}
	}

	switch agentKey {
	case "claude":
		return &ConfigureClaude{}, nil
	case "goose":
		return &ConfigureGoose{}, nil
	case "cursor":
		return &ConfigureCursor{}, nil
	case "codex":
		return &ConfigureCodex{}, nil
	case "amazonq":
		return &ConfigureQ{}, nil
	}
	return nil, fmt.Errorf("unknown agent: %s", agentKey)
}

func configureAgent(agent ConfigurableAgent) error {
	fmt.Printf("Configuring %s...\n", agent.name())

	// Save MCP config
	err := agent.editMcpConfig()
	if err != nil {
		return err
	}
	fmt.Printf("‚úì Configured %s MCP configuration\n", agent.name())

	// Save rules
	err = agent.editRules()
	if err != nil {
		return err
	}
	fmt.Printf("‚úì Saved %s container-use rules\n", agent.name())

	fmt.Printf("\n%s configuration complete!\n", agent.name())
	return nil
}

// Helper functions
func saveRulesFile(rulesFile, content string) error {
	dir := filepath.Dir(rulesFile)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return err
	}

	// Append to file if it exists, create if it doesn't TODO make it re-entrant with a marker
	existing, err := os.ReadFile(rulesFile)
	if err != nil && !os.IsNotExist(err) {
		return fmt.Errorf("failed to read existing rules: %w", err)
	}
	existingStr := string(existing)

	editedRules, err := editRulesFile(existingStr, content)
	if err != nil {
		return err
	}

	err = os.WriteFile(rulesFile, []byte(editedRules), 0600)
	if err != nil {
		return fmt.Errorf("failed to update rules: %w", err)
	}

	return nil
}

func editRulesFile(existingRules, content string) (string, error) {
	// Look for section markers
	const marker = "<!-- container-use-rules -->"

	if strings.Contains(existingRules, marker) {
		// Update existing section
		parts := strings.Split(existingRules, marker)
		if len(parts) != 3 {
			return "", fmt.Errorf("malformed rules file - expected single section marked with %s", marker)
		}
		newContent := parts[0] + marker + "\n" + content + "\n" + marker + parts[2]
		return newContent, nil
	} else {
		// Append new section
		newContent := existingRules
		if len(newContent) > 0 && !strings.HasSuffix(newContent, "\n") {
			newContent += "\n"
		}
		newContent += "\n" + marker + "\n" + content + "\n" + marker + "\n"
		return newContent, nil
	}
}

func tools(prefix string) []string {
	tools := []string{}
	for _, t := range mcpserver.Tools() {
		tools = append(tools, fmt.Sprintf("%s%s", prefix, t.Definition.Name))
	}
	return tools
}



================================================
FILE: cmd/container-use/agent/configure_claude.go
================================================
package agent

import (
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"

	"github.com/dagger/container-use/rules"
)

type ConfigureClaude struct {
	Name        string
	Description string
}

func NewConfigureClaude() *ConfigureClaude {
	return &ConfigureClaude{
		Name:        "Claude Code",
		Description: "Anthropic's Claude Code",
	}
}

type ClaudeSettingsLocal struct {
	Permissions *ClaudePermissions `json:"permissions,omitempty"`
	Env         map[string]string  `json:"env,omitempty"`
}

type ClaudePermissions struct {
	Allow []string `json:"allow,omitempty"`
	Deny  []string `json:"deny,omitempty"`
}

func (c *ConfigureClaude) name() string {
	return c.Name
}

func (c *ConfigureClaude) description() string {
	return c.Description
}

func (c *ConfigureClaude) editMcpConfig() error {
	// Remove existing MCP server (ignore errors if it doesn't exist)
	removeCmd := exec.Command("claude", "mcp", "remove", "container-use")
	_ = removeCmd.Run() // Ignore error - server might not exist

	// Add MCP server
	cmd := exec.Command("claude", "mcp", "add", "container-use", "--", ContainerUseBinary, "stdio")
	err := cmd.Run()
	if err != nil {
		return fmt.Errorf("could not automatically add MCP server: %w", err)
	}

	// Configure auto approve settings
	configPath := filepath.Join(".claude", "settings.local.json")
	// Create directory if it doesn't exist
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}
	var config ClaudeSettingsLocal
	if data, err := os.ReadFile(configPath); err == nil {
		if err := json.Unmarshal(data, &config); err != nil {
			return fmt.Errorf("failed to parse existing config: %w", err)
		}
	}

	data, err := c.updateSettingsLocal(config)
	if err != nil {
		return err
	}

	err = os.WriteFile(configPath, data, 0600)
	if err != nil {
		return fmt.Errorf("failed to write config: %w", err)
	}
	return nil
}

func (c *ConfigureClaude) updateSettingsLocal(config ClaudeSettingsLocal) ([]byte, error) {
	// Initialize permissions map if nil
	if config.Permissions == nil {
		config.Permissions = &ClaudePermissions{Allow: []string{}}
	}

	// remove save non-container-use items from allow
	allows := []string{}
	for _, tool := range config.Permissions.Allow {
		if !strings.HasPrefix(tool, "mcp__container-use") {
			allows = append(allows, tool)
		}
	}

	// Add container-use tools to allow
	tools := tools("mcp__container-use__")
	allows = append(allows, tools...)
	config.Permissions.Allow = allows

	// Write config back
	data, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}
	return data, nil
}

func (c *ConfigureClaude) editRules() error {
	return saveRulesFile("CLAUDE.md", rules.AgentRules)
}

func (c *ConfigureClaude) isInstalled() bool {
	_, err := exec.LookPath("claude")
	return err == nil
}



================================================
FILE: cmd/container-use/agent/configure_codex.go
================================================
package agent

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"

	"github.com/dagger/container-use/rules"
	"github.com/mitchellh/go-homedir"
	"github.com/pelletier/go-toml/v2"
)

type ConfigureCodex struct {
	Name        string
	Description string
}

func NewConfigureCodex() *ConfigureCodex {
	return &ConfigureCodex{
		Name:        "OpenAI Codex",
		Description: "OpenAI's lightweight coding agent that runs in your terminal",
	}
}

// Return the agents full name
func (a *ConfigureCodex) name() string {
	return a.Name
}

// Return a description of the agent
func (a *ConfigureCodex) description() string {
	return a.Description
}

// Save the MCP config with container-use enabled
func (a *ConfigureCodex) editMcpConfig() error {
	configPath, err := homedir.Expand(filepath.Join("~", ".codex", "config.toml"))
	if err != nil {
		return err
	}

	// Create directory if it doesn't exist
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// Read existing config or create new
	var config map[string]any
	if data, err := os.ReadFile(configPath); err == nil {
		if err := toml.Unmarshal(data, &config); err != nil {
			return fmt.Errorf("failed to parse existing config: %w", err)
		}
	} else {
		config = make(map[string]any)
	}

	data, err := a.updateCodexConfig(config)
	if err != nil {
		return err
	}

	err = os.WriteFile(configPath, data, 0600)
	if err != nil {
		return fmt.Errorf("failed to write config: %w", err)
	}
	return nil
}

func (a *ConfigureCodex) updateCodexConfig(config map[string]any) ([]byte, error) {
	// Get mcp_servers map
	var mcpServers map[string]any
	if servers, ok := config["mcp_servers"]; ok {
		mcpServers = servers.(map[string]any)
	} else {
		mcpServers = make(map[string]any)
		config["mcp_servers"] = mcpServers
	}

	// Add container-use server
	mcpServers["container-use"] = map[string]any{
		"command":      ContainerUseBinary,
		"args":         []any{"stdio"},
		"auto_approve": tools(""),
	}

	// Write config back
	data, err := toml.Marshal(&config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}
	return data, nil
}

// Save the agent rules with the container-use prompt
func (a *ConfigureCodex) editRules() error {
	agentsFile := "AGENTS.md"
	return saveRulesFile(agentsFile, rules.AgentRules)
}

func (a *ConfigureCodex) isInstalled() bool {
	_, err := exec.LookPath("codex")
	return err == nil
}



================================================
FILE: cmd/container-use/agent/configure_cursor.go
================================================
package agent

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"

	"github.com/dagger/container-use/rules"
)

type ConfigureCursor struct {
	Name        string
	Description string
}

func NewConfigureCursor() *ConfigureCursor {
	return &ConfigureCursor{
		Name:        "Cursor",
		Description: "AI-powered code editor",
	}
}

// Return the agents full name
func (a *ConfigureCursor) name() string {
	return a.Name
}

// Return a description of the agent
func (a *ConfigureCursor) description() string {
	return a.Description
}

// Save the MCP config with container-use enabled
func (a *ConfigureCursor) editMcpConfig() error {
	configPath := filepath.Join(".cursor", "mcp.json")

	// Create directory if it doesn't exist
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// Read existing config or create new
	var config MCPServersConfig
	if data, err := os.ReadFile(configPath); err == nil {
		if err := json.Unmarshal(data, &config); err != nil {
			return fmt.Errorf("failed to parse existing config: %w", err)
		}
	}

	data, err := a.updateMcpConfig(config)
	if err != nil {
		return err
	}

	err = os.WriteFile(configPath, data, 0600)
	if err != nil {
		return fmt.Errorf("failed to write config: %w", err)
	}
	return nil
}

func (a *ConfigureCursor) updateMcpConfig(config MCPServersConfig) ([]byte, error) {
	// Initialize mcpServers map if nil
	if config.MCPServers == nil {
		config.MCPServers = make(map[string]MCPServer)
	}

	// Add container-use server
	config.MCPServers["container-use"] = MCPServer{
		Command: ContainerUseBinary,
		Args:    []string{"stdio"},
	}

	// Write config back
	data, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}
	return data, nil
}

// Save the agent rules with the container-use prompt
func (a *ConfigureCursor) editRules() error {
	rulesFile := filepath.Join(".cursor", "rules", "container-use.mdc")
	return saveRulesFile(rulesFile, rules.CursorRules)
}

func (a *ConfigureCursor) isInstalled() bool {
	return true
}



================================================
FILE: cmd/container-use/agent/configure_goose.go
================================================
package agent

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"

	"github.com/dagger/container-use/rules"
	"github.com/mitchellh/go-homedir"
	"gopkg.in/yaml.v3"
)

type ConfigureGoose struct {
	Name        string
	Description string
}

func NewConfigureGoose() *ConfigureGoose {
	return &ConfigureGoose{
		Name:        "Goose",
		Description: "an open source, extensible AI agent that goes beyond code suggestions",
	}
}

// Return the agents full name
func (a *ConfigureGoose) name() string {
	return a.Name
}

// Return a description of the agent
func (a *ConfigureGoose) description() string {
	return a.Description
}

// Save the MCP config with container-use enabled
func (a *ConfigureGoose) editMcpConfig() error {
	var configPath string
	var err error

	if runtime.GOOS == "windows" {
		// Windows: %APPDATA%\Block\goose\config\config.yaml
		// Reference: https://block.github.io/goose/docs/guides/config-file
		appData := os.Getenv("APPDATA")
		if appData == "" {
			return fmt.Errorf("APPDATA environment variable not set")
		}
		configPath = filepath.Join(appData, "Block", "goose", "config", "config.yaml")
	} else {
		// macOS/Linux: ~/.config/goose/config.yaml
		configPath, err = homedir.Expand(filepath.Join("~", ".config", "goose", "config.yaml"))
		if err != nil {
			return err
		}
	}

	// Create directory if it doesn't exist
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// Read existing config or create new
	var config map[string]any
	if data, err := os.ReadFile(configPath); err == nil {
		if err := yaml.Unmarshal(data, &config); err != nil {
			return fmt.Errorf("failed to parse existing config: %w", err)
		}
	} else {
		config = make(map[string]any)
	}

	data, err := a.updateGooseConfig(config)
	if err != nil {
		return err
	}

	if err := os.WriteFile(configPath, data, 0600); err != nil {
		return fmt.Errorf("failed to write config: %w", err)
	}
	return nil
}

func (a *ConfigureGoose) updateGooseConfig(config map[string]any) ([]byte, error) {
	// Get extensions map
	var extensions map[string]any
	if ext, ok := config["extensions"]; ok {
		extensions = ext.(map[string]any)
	} else {
		extensions = make(map[string]any)
		config["extensions"] = extensions
	}

	// Add container-use extension
	extensions["container-use"] = map[string]any{
		"name":    "container-use",
		"type":    "stdio",
		"enabled": true,
		"cmd":     ContainerUseBinary,
		"args":    []any{"stdio"},
		"envs":    map[string]any{},
	}

	// Write config back
	data, err := yaml.Marshal(&config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}
	return data, nil
}

// Save the agent rules with the container-use prompt
func (a *ConfigureGoose) editRules() error {
	return saveRulesFile(".goosehints", rules.AgentRules)
}

func (a *ConfigureGoose) isInstalled() bool {
	_, err := exec.LookPath("goose")
	return err == nil
}



================================================
FILE: cmd/container-use/agent/configure_q.go
================================================
package agent

import (
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"

	"github.com/dagger/container-use/rules"
)

type ConfigureQ struct {
	Name        string
	Description string
}

func NewConfigureQ() *ConfigureQ {
	return &ConfigureQ{
		Name:        "Amazon Q Developer",
		Description: "Amazon's agentic chat experience in your terminal",
	}
}

// Return the agents full name
func (a *ConfigureQ) name() string {
	return a.Name
}

// Return a description of the agent
func (a *ConfigureQ) description() string {
	return a.Description
}

// Save the MCP config with container-use enabled
func (a *ConfigureQ) editMcpConfig() error {
	configPath := filepath.Join(".amazonq", "mcp.json")

	// Create directory if it doesn't exist
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// Read existing config or create new
	var config MCPServersConfig
	if data, err := os.ReadFile(configPath); err == nil {
		if err := json.Unmarshal(data, &config); err != nil {
			return fmt.Errorf("failed to parse existing config: %w", err)
		}
	}

	data, err := a.updateMcpConfig(config)
	if err != nil {
		return err
	}

	err = os.WriteFile(configPath, data, 0600)
	if err != nil {
		return fmt.Errorf("failed to write config: %w", err)
	}
	return nil
}

func (a *ConfigureQ) updateMcpConfig(config MCPServersConfig) ([]byte, error) {
	// Initialize mcpServers map if nil
	if config.MCPServers == nil {
		config.MCPServers = make(map[string]MCPServer)
	}

	// Add container-use server
	config.MCPServers["container-use"] = MCPServer{
		Command: ContainerUseBinary,
		Args:    []string{"stdio"},
		Env:     map[string]string{},
		Timeout: &[]int{60000}[0],
	}

	// Write config back
	data, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}
	return data, nil
}

// Save the agent rules with the container-use prompt
func (a *ConfigureQ) editRules() error {
	return saveRulesFile(".amazonq/rules/container-use.md", rules.AgentRules)
}

func (a *ConfigureQ) isInstalled() bool {
	_, err := exec.LookPath("q")
	return err == nil
}



================================================
FILE: cmd/container-use/agent/configure_test.go
================================================
package agent

import (
	"testing"

	"github.com/dagger/container-use/rules"
	"github.com/stretchr/testify/assert"
)

func TestConfigureEditRulesFile(t *testing.T) {
	blankRules := "\nFOO\n"
	existingRules := blankRules + rules.AgentRules

	// Edit rules file that doesnt have container-use rules yet
	editedBlank, err := editRulesFile(blankRules, rules.AgentRules)
	assert.NoError(t, err)
	// check rules have been added
	assert.Contains(t, editedBlank, rules.AgentRules)
	// check original content is still there
	assert.Contains(t, editedBlank, blankRules)

	// Edit rules file that has existing container-use rules
	editedExisting, err := editRulesFile(existingRules, rules.AgentRules)
	assert.NoError(t, err)
	assert.Contains(t, editedExisting, rules.AgentRules)
}

func TestConfigureClaudeUpdateSettings(t *testing.T) {
	claude := &ConfigureClaude{}
	settings := ClaudeSettingsLocal{}
	expect := `{
  "permissions": {
    "allow": [
      "mcp__container-use__environment_`
	editedSettings, err := claude.updateSettingsLocal(settings)
	assert.NoError(t, err)
	assert.Contains(t, string(editedSettings), expect)
}

func TestConfigureCodexUpdateConfig(t *testing.T) {
	codex := &ConfigureCodex{}
	config := make(map[string]any)
	contains := `[mcp_servers]
[mcp_servers.container-use]
args = ['stdio']
auto_approve = ['`
	editedConfig, err := codex.updateCodexConfig(config)
	assert.NoError(t, err)
	assert.Contains(t, string(editedConfig), contains)
}

func TestConfigureGooseUpdateConfig(t *testing.T) {
	goose := &ConfigureGoose{}
	config := make(map[string]any)
	contains := `extensions:
    container-use:
        args:
            - stdio
        cmd: container-use
        enabled: true
        envs: {}
        name: container-use
        type: stdio`
	editedConfig, err := goose.updateGooseConfig(config)
	assert.NoError(t, err)
	assert.Contains(t, string(editedConfig), contains)
}

func TestConfigureQUpdateConfig(t *testing.T) {
	q := &ConfigureQ{}
	config := MCPServersConfig{}
	expect := `{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": [
        "stdio"
      ],
      "timeout": 60000
    }
  }
}`
	editedConfig, err := q.updateMcpConfig(config)
	assert.NoError(t, err)
	assert.Equal(t, string(editedConfig), expect)
}

func TestConfigureCursorUpdateConfig(t *testing.T) {
	q := &ConfigureCursor{}
	config := MCPServersConfig{}
	expect := `{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": [
        "stdio"
      ]
    }
  }
}`
	editedConfig, err := q.updateMcpConfig(config)
	assert.NoError(t, err)
	assert.Equal(t, string(editedConfig), expect)
}



================================================
FILE: cmd/container-use/agent/configure_ui.go
================================================
package agent

import (
	"fmt"
	"runtime"
	"strings"

	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
)

// Agent represents an agent configuration option
type Agent struct {
	Key         string
	Name        string
	Description string
}

// Available agents
var agents = []Agent{
	{
		Key:         "claude",
		Name:        "Claude Code",
		Description: "Anthropic's Claude Code",
	},
	{
		Key:         "goose",
		Name:        "Goose",
		Description: "an open source, extensible AI agent that goes beyond code suggestions",
	},
	{
		Key:         "cursor",
		Name:        "Cursor",
		Description: "AI-powered code editor",
	},
	{
		Key:         "codex",
		Name:        "OpenAI Codex",
		Description: "OpenAI's lightweight coding agent that runs in your terminal (Linux/macOS/WSL)",
	},
	{
		Key:         "amazonq",
		Name:        "Amazon Q Developer",
		Description: "Amazon's agentic chat experience in your terminal (Linux/macOS/WSL)",
	},
}

// getSupportedAgents returns agents that are supported on the current platform
func getSupportedAgents() []Agent {
	if runtime.GOOS == "windows" {
		// Filter out Windows-incompatible agents
		var supportedAgents []Agent
		for _, agent := range agents {
			if agent.Key != "codex" && agent.Key != "amazonq" {
				supportedAgents = append(supportedAgents, agent)
			}
		}
		return supportedAgents
	}
	return agents
}

// AgentSelectorModel represents the bubbletea model for agent selection
type AgentSelectorModel struct {
	cursor   int
	selected string
	quit     bool
}

// InitialModel creates the initial model for agent selection
func InitialModel() AgentSelectorModel {
	return AgentSelectorModel{}
}

// Init initializes the model
func (m AgentSelectorModel) Init() tea.Cmd {
	return nil
}

// Update handles incoming messages and updates the model
func (m AgentSelectorModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	supportedAgents := getSupportedAgents()
	switch msg := msg.(type) {
	case tea.KeyMsg:
		switch msg.String() {
		case "ctrl+c", "q", "esc":
			m.quit = true
			return m, tea.Quit
		case "up", "k":
			if m.cursor > 0 {
				m.cursor--
			}
		case "down", "j":
			if m.cursor < len(supportedAgents)-1 {
				m.cursor++
			}
		case "enter", " ":
			m.selected = supportedAgents[m.cursor].Key
			m.quit = true
			return m, tea.Quit
		}
	default:
		return m, nil
	}
	return m, nil
}

// View renders the interface
func (m AgentSelectorModel) View() string {
	if m.quit {
		return ""
	}

	// Styles
	titleStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#FAFAFA")).
		Background(lipgloss.Color("#7D56F4")).
		Padding(0, 1).
		Margin(1, 0).
		Bold(true)

	headerStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#7D56F4")).
		Bold(true).
		Margin(1, 0, 0, 0)

	selectedStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#FAFAFA")).
		Background(lipgloss.Color("#F25D94")).
		Padding(0, 1).
		Bold(true)

	normalStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#04B575")).
		Padding(0, 1)

	descriptionStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#626262")).
		Padding(0, 1, 0, 3).
		Italic(true)

	footerStyle := lipgloss.NewStyle().
		Foreground(lipgloss.Color("#626262")).
		Margin(1, 0, 0, 0)

	// Build the view
	var s strings.Builder

	// Title
	s.WriteString(titleStyle.Render("üõ†Ô∏è  Container Use Configuration"))
	s.WriteString("\n")

	// Header
	s.WriteString(headerStyle.Render("Select an agent to configure:"))
	s.WriteString("\n\n")

	// Show WSL note for Windows users
	if runtime.GOOS == "windows" {
		wslNoteStyle := lipgloss.NewStyle().
			Foreground(lipgloss.Color("#FFA500")).
			Padding(0, 1).
			Italic(true)
		s.WriteString(wslNoteStyle.Render("Note: OpenAI Codex and Amazon Q Developer are available in WSL"))
		s.WriteString("\n\n")
	}

	// Agent list TODO: filter or sort agents based on if they are installed (ConfigurableAgent.isInstalled())
	supportedAgents := getSupportedAgents()
	for i, agent := range supportedAgents {
		cursor := "  " // not selected
		if m.cursor == i {
			cursor = "‚ñ∂ " // selected
		}

		agentLine := fmt.Sprintf("%s%s", cursor, agent.Name)
		if m.cursor == i {
			s.WriteString(selectedStyle.Render(agentLine))
		} else {
			s.WriteString(normalStyle.Render(agentLine))
		}

		s.WriteString("\n")

		// Show description for selected item
		if m.cursor == i {
			s.WriteString(descriptionStyle.Render(agent.Description))
			s.WriteString("\n")
		}
	}

	// Footer
	s.WriteString("\n")
	s.WriteString(footerStyle.Render("Use ‚Üë/‚Üì or j/k to navigate ‚Ä¢ Enter/Space to select ‚Ä¢ q/Ctrl+C/Esc to quit"))

	return s.String()
}

// RunAgentSelector runs the interactive agent selector and returns the selected agent key
func RunAgentSelector() (string, error) {
	p := tea.NewProgram(InitialModel())
	finalModel, err := p.Run()
	if err != nil {
		return "", fmt.Errorf("error running agent selector: %w", err)
	}

	m := finalModel.(AgentSelectorModel)
	if m.selected == "" {
		return "", fmt.Errorf("no agent selected")
	}

	return m.selected, nil
}



================================================
FILE: docs/README.md
================================================
# container-use documentation

This documentation is built using MDX and Mintlify. Run the following commands to get started:

```
npx mint dev
```

## Deploying

The docs site is always updated whenever the `main` branch is updated in this repo.



================================================
FILE: docs/agent-integrations.mdx
================================================
---
title: Agent Integration
description: "Setup guides for some popular coding agents."
icon: robot
---

Container Use works with any coding agent that supports the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction).

<Note>All agents use the same MCP server command: `container-use stdio`</Note>

<details>
<summary>üí° Command Shortcut</summary>

The `container-use` command is also available as `cu` for convenience. Both commands work identically:
- `container-use stdio` (used in documentation)
- `cu stdio` (shortcut)

</details>

## Claude Code

**Add MCP Configuration:**
```sh
cd /path/to/repository
claude mcp add container-use -- container-use stdio
```

**Add Agent Rules (Optional):**
Save the CLAUDE.md file at the root of your repository:
```sh
curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> CLAUDE.md
```

**Trust Only Container Use Tools (Optional):**
For maximum security, restrict Claude Code to only use Container Use tools:
```sh
claude --allowedTools mcp__container-use__environment_add_service,mcp__container-use__environment_checkpoint,mcp__container-use__environment_config,mcp__container-use__environment_create,mcp__container-use__environment_file_delete,mcp__container-use__environment_file_edit,mcp__container-use__environment_file_list,mcp__container-use__environment_file_read,mcp__container-use__environment_file_write,mcp__container-use__environment_open,mcp__container-use__environment_run_cmd,mcp__container-use__environment_update_metadata
```

<Info>
  Learn more: [Claude Code MCP Documentation](https://docs.anthropic.com/en/docs/claude-code/tutorials#set-up-model-context-protocol-mcp)
</Info>

## Amazon Q Developer

**Add MCP Configuration:**
Add this configuration to `~/.aws/amazonq/mcp.json`:
```json
{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "env": {},
      "timeout": 60000
    }
  }
}
```

**Add Agent Rules:**
Save agent instructions to your project root:
```sh
mkdir -p ./.amazonq/rules && curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md > .amazonq/rules/container-use.md
```

**Trust Only Container Use Tools (Optional):**
```sh
q chat --trust-tools=container_use___environment_add_service,container_use___environment_checkpoint,container_use___environment_config,container_use___environment_create,container_use___environment_file_delete,container_use___environment_file_edit,container_use___environment_file_list,container_use___environment_file_read,container_use___environment_file_write,container_use___environment_open,container_use___environment_run_cmd,container_use___environment_update_metadata
```

<Card title="Video Tutorial" icon="youtube" href="https://youtu.be/C2g3vdbffOI">
  Watch the Amazon Q Developer setup walkthrough
</Card>

## Cursor

**Install MCP Server:**

Use the one-click deeplink to install (requires Cursor and Container Use already installed):

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.com/install-mcp?name=container-use&config=eyJjb21tYW5kIjoiY29udGFpbmVyLXVzZSBzdGRpbyJ9)

**Add Agent Rules:**

Add the rules file to your project or home directory:

```sh
curl --create-dirs -o .cursor/rules/container-use.mdc https://raw.githubusercontent.com/dagger/container-use/main/rules/cursor.mdc
```

<Info>
  Learn more: [Cursor MCP
  Documentation](https://docs.cursor.com/context/model-context-protocol)
</Info>

## Windsurf

**Install MCP Server:**

In `~/.codeium/windsurf/mcp_config.json`, add the following configuration:

```json
{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "env": {}
    }
  }
}
```

**Add Agent Rules:**

Add the rules file to your project or home directory:

```sh
curl --create-dirs -o .windsurf/rules/container-use.mdc https://raw.githubusercontent.com/dagger/container-use/main/rules/windsurf.mdc
```

## VSCode / GitHub Copilot

**Configure MCP Server:**

Update your VSCode settings with:

```json
"mcp": {
  "servers": {
    "container-use": {
      "type": "stdio",
      "command": "container-use",
      "args": ["stdio"]
    }
  }
}
```

**Add Copilot Instructions (Optional):**

```sh
curl --create-dirs -o .github/copilot-instructions.md https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md
```

<Card title="Video Tutorial" icon="youtube" href="https://youtu.be/Nz2sOef0gW0">
  Watch the VSCode setup walkthrough
</Card>

<Info>
  Learn more: [VSCode
  MCP](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) | [GitHub
  Copilot
  MCP](https://docs.github.com/en/copilot/customizing-copilot/extending-copilot-chat-with-mcp)
</Info>

## [Zed](https://zed.dev/)

First add the agent rules file, either as `.rules` in the root of your project or as one of the [other acceptable files/locations](https://zed.dev/docs/ai/rules?highlight=agent.md#rules-files).

```sh
curl -o .rules https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md
```

Then, choose one of the methods to add the Container Use MCP server in Zed:

1. **Extension**: Visit the [Container Use extension page](https://zed.dev/extensions/container-use-mcp-server), open it in Zed, and hit install. Then, follow the configuration instructions that will appear on the modal.
2. **Settings**: Add the following snippet on your `settings.json`:

```json
"context_servers": {
  "container-use": {
    "source": "custom",
    "command": "container-use",
    "args": ["stdio"],
    "env": {}
  },
}
```

**Add Container Use Agent Profile (Optional):**

To lock the Zed agent out of your host system, you can create a dedicated agent profile that only enables Container Use tools. Add this to your `settings.json` under the `agent` section:

```json
"agent": {
  "profiles": {
    "container-use": {
      "name": "Container Use",
      "tools": {
        "fetch": true,
        "thinking": true,
        "copy_path": false,
        "find_path": false,
        "delete_path": false,
        "create_directory": false,
        "list_directory": false,
        "diagnostics": false,
        "read_file": false,
        "open": false,
        "move_path": false,
        "grep": false,
        "edit_file": false,
        "terminal": false
      },
      "enable_all_context_servers": false,
      "context_servers": {
        "container-use": {
          "tools": {
            "environment_add_service": true,
            "environment_checkpoint": true,
            "environment_config": true,
            "environment_create": true,
            "environment_file_delete": true,
            "environment_file_edit": true,
            "environment_file_list": true,
            "environment_file_read": true,
            "environment_file_write": true,
            "environment_open": true,
            "environment_run_cmd": true,
            "environment_update_metadata": true
          }
        }
      }
    }
  }
}
```

This profile ensures your agent can only use Container Use tools, preventing it from modifying your local files directly.

Next open the Zed Agent Panel ‚ú® in the lower right, select the "Container Use" profile from the dropdown to the left of the model dropdown, and prompt away!

## OpenCode

Configure the Container Use MCP server in a `opencode.json` file.

Configure the Container Use MCP server:

```json
{
  "$schema": "http://opencode.ai/config.json",
  "mcp": {
    "container-use": {
      "type": "local",
      "command": ["container-use", "stdio"],
      "enabled": true
    }
  }
}
```

Add the `AGENTS.md` file using this command (this is optional but usually provides the best results):

```sh
curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> AGENTS.md
```

Run `opencode` and dispatch your agents to complete your tasks!

## Goose

**Method 1: Configuration File:**

Add to `~/.config/goose/config.yaml`:

```yaml
extensions:
  container-use:
    name: container-use
    type: stdio
    enabled: true
    cmd: container-use
    args:
      - stdio
    envs: {}
```

**Method 2: Interactive Setup:**

```sh
goose configure
```

Then add a command line extension with `container-use stdio` as the command.

**Method 3: Goose Desktop:**

Paste this URL into your browser:

```
goose://extension?cmd=container-use&arg=stdio&id=container-use&name=container%20use&description=use%20containers%20with%20dagger%20and%20git%20for%20isolated%20environments
```

<Info>
  Learn more: [Goose MCP
  Extensions](https://block.github.io/goose/docs/getting-started/using-extensions#mcp-servers)
</Info>

## Sourcegraph Amp

**Add MCP Configuration:**
Add this configuration to `~/.config/amp/settings.json`:
```json
{
    "amp.mcpServers": {
        "container-use": {
            "command": "container-use",
            "args": ["stdio"]
        }
    },
    "amp.permissions": [
      {"tool": "mcp__container-use__*", "action": "allow"}
    ],
    "amp.dangerouslyAllowAll": false,
    "amp.updates.autoUpdate.enabled": true
}
```

**Add Agent Rules:**
Save agent instructions to your project root:
```sh
curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> AGENT.md
```

<Info>Learn more: [Sourcegraph Amp Documentation](https://ampcode.com/manual/)</Info>

## Charm Crush

**Add MCP Configuration:**
Add this configuration to [a valid location](https://github.com/charmbracelet/crush?tab=readme-ov-file#configuration) like `./.crush.json`:
```json
{
  "$schema": "https://charm.land/crush.json",
  "mcp": {
    "container-use": {
      "type": "stdio",
      "command": "container-use",
      "args": ["stdio"],
      "env": {}
    }
  },
  "permissions": {
    "allowed_tools": [
      "mcp_container-use_environment_add_service",
      "mcp_container-use_environment_checkpoint",
      "mcp_container-use_environment_config",
      "mcp_container-use_environment_create",
      "mcp_container-use_environment_file_delete",
      "mcp_container-use_environment_file_edit",
      "mcp_container-use_environment_file_list",
      "mcp_container-use_environment_file_read",
      "mcp_container-use_environment_file_write",
      "mcp_container-use_environment_open",
      "mcp_container-use_environment_run_cmd",
      "mcp_container-use_environment_update_metadata"
    ]
  }
}
```

**Add Agent Rules:**
Save agent instructions to your project root:
```sh
curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> CRUSH.md
```

<Info>Learn more: [Crush project on GitHub](https://github.com/charmbracelet/crush)</Info>


## Cline

**Add MCP Configuration:**

Add to your Cline MCP server configuration JSON:

```json
{
  "mcpServers": {
    "container-use": {
      "disabled": false,
      "timeout": 60000,
      "type": "stdio",
      "command": "container-use",
      "args": ["stdio"],
      "env": {},
      "autoApprove": []
    }
  }
}
```

**Add Agent Rules:**

```sh
curl --create-dirs -o .clinerules/container-use.md https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md
```

<Info>Learn more: [Cline Documentation](https://cline.bot/)</Info>

## Qodo Gen

**Setup Steps:**

1. Open Qodo Gen chat panel in VSCode or IntelliJ
2. Click "Connect more tools"
3. Click "+ Add new MCP"
4. Add this configuration:

```json
{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"]
    }
  }
}
```

<Info>
  Learn more: [Qodo Gen MCP
  Documentation](https://docs.qodo.ai/qodo-documentation/qodo-gen/qodo-gen-chat/agentic-mode/agentic-tools-mcps)
</Info>

## Kilo Code

**Add MCP Configuration:**

Add at global or project level:

```json
{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "env": {},
      "alwaysAllow": [],
      "disabled": false
    }
  }
}
```

<Info>
  Kilo Code allows setting MCP servers at the global or project level. Learn
  more: [Kilo Code MCP
  Documentation](https://kilocode.ai/docs/features/mcp/using-mcp-in-kilo-code)
</Info>

## Kiro

**Add MCP Configuration:**

Add to `.kiro/settings/mcp.json` in your project root:

```json
{
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "env": {},
      "disabled": false,
      "autoApprove": {}
    }
  }
}
```

**Add Steering Rules:**

Create `.kiro/steering/container-use.md`:

```markdown
---
inclusion: always
---

ALWAYS use ONLY Environments for ANY and ALL file, code, or shell operations‚ÄîNO EXCEPTIONS‚Äîeven for simple or generic requests.

DO NOT install or use the git cli with the environment_run_cmd tool. All environment tools will handle git operations for you. Changing ".git" yourself will compromise the integrity of your environment.

You MUST inform the user how to view your work using `container-use log <env_id>` and `container-use checkout <env_id>`. Failure to do this will make your work inaccessible to others.
```

## OpenAI Codex

**Add MCP Configuration:**

Add to `~/.codex/config.toml`:

```toml
[mcp_servers.container-use]
command = "container-use"
args = ["stdio"]
env = {}
```

<Info>
  Learn more: [OpenAI Codex
  Documentation](https://github.com/openai/codex/tree/main/codex-rs)
</Info>

## Warp

**Add MCP Configuration:**

In the Warp sidebar, under Personal ‚Üí MCP Servers ‚Üí New:

```json
{
  "container-use": {
    "command": "container-use",
    "args": ["stdio"],
    "env": {},
    "working_directory": null,
    "start_on_launch": true
  }
}
```

<Info>Warp 2.0 introduces coding agents with MCP support.</Info>

## Gemini CLI

**Add MCP Configuration:**

Add to `~/.gemini/settings.json` or `.gemini/settings.json`:

```json
{
  "coreTools": [],
  "mcpServers": {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "timeout": 60000,
      "trust": true
    }
  }
}
```

<Info>
  Learn more: [Gemini CLI
  Configuration](https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/configuration.md)
</Info>

## JetBrains Junie

**Add MCP Configuration:**

Add or edit the MCP configuration in Settings under Tools ‚Üí Junie ‚Üí MCP Settings, or edit `~/.junie/mcp/mcp.json`:

```json
{
  "mcpServers":
  {
    "container-use": {
      "command": "container-use",
      "args": ["stdio"],
      "env": {},
      "timeout": 60000
    }
  }
}
```

<Info>
    MCP support in Beta starting with Junie plugin `2xx.204.xx`
</Info>

**Add Agent Rules:**

Save agent instructions to your project root:

```sh
mkdir -p ./.junie && curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> .junie/guidelines.md
```

<Info>
    Learn more: [Junie Guidelines](https://www.jetbrains.com/help/junie/customize-guidelines.html)
</Info>

**Trust MCP Tools (Optional):**

In the settings, under Tools ‚Üí Junie ‚Üí Action Allowlist: add _MCP Rule_.

## Troubleshooting

<AccordionGroup>
  <Accordion title="Agent doesn't recognize Container Use">
    - Verify the `container-use` command is in your PATH: `which container-use`
    - Check MCP configuration syntax
    - Restart your agent after configuration changes
  </Accordion>

{" "}

<Accordion title="Permission errors">
  - Ensure Docker is running and accessible - Check file permissions for
  configuration files - Verify `container-use stdio` command works: `echo '{}' | container-use stdio`
</Accordion>

  <Accordion title="Tools not appearing">
    - Some agents require explicit tool trust/approval
    - Check your agent's MCP server logs
    - Verify Container Use tools are enabled in agent settings
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Back to Quickstart" icon="rocket" href="/quickstart">
    Return to the quickstart guide to create your first environment
  </Card>
  <Card
    title="Join Community"
    icon="discord"
    href="https://container-use.com/discord"
  >
    Get help and share experiences in #container-use
  </Card>
</CardGroup>



================================================
FILE: docs/cli-reference.mdx
================================================
---
title: CLI Reference
description: "Complete reference for all Container Use CLI commands and options."
icon: terminal
---

Container Use provides a comprehensive CLI for managing isolated development environments. All commands follow the pattern:

```bash
container-use {command} [options] [arguments]
```

**Shorthand:** The `cu` command is an alias for `container-use` and can be used interchangeably.

## Global Options

These options can be used with any command:

- `--help`, `-h` - Show help for a command
- `--version` - Show version information
- `--debug` - Enable debug output

## Commands

### `container-use list`

List all environments and their status.

```bash
container-use list
```

**Options:**
- `--no-trunc` - Don't truncate output
- `--quiet`, `-q` - Only show environment IDs

**Output example:**
```
ID              TITLE                     CREATED       UPDATED
frontend-work   React UI Components       5 mins ago    1 min ago
backend-api     FastAPI User Service      3 mins ago    2 mins ago
```

### `container-use log`

View the commit history and commands executed in an environment.

```bash
container-use log {environment-id}
```

**Options:**
- `--patch`, `-p` - Show patch output with diffs

**Example:**
```bash
container-use log fancy-mallard
# Shows full history with commands and file changes

container-use log fancy-mallard --patch
# Shows history with patch diffs
```

### `container-use diff`

Show the code changes made in an environment compared to its base branch.

```bash
container-use diff {environment-id}
```


**Example:**
```bash
container-use diff fancy-mallard
# Shows full diff output
```

### `container-use checkout`

Check out an environment's branch locally to explore in your IDE.

```bash
container-use checkout {environment-id}
```

**Options:**
- `--branch`, `-b` - Specify branch name to checkout

**Example:**
```bash
container-use checkout fancy-mallard
# Switches to branch 'cu-fancy-mallard'
```

### `container-use terminal`

Open an interactive terminal session inside the environment's container.

```bash
container-use terminal {environment-id}
```

**Example:**
```bash
container-use terminal fancy-mallard
# Opens interactive shell in container
```

### `container-use merge`

Merge an environment's work into your current branch, preserving commit history.

```bash
container-use merge {environment-id}
```

**Options:**
- `--delete`, `-d` - Delete environment after successful merge

**Example:**
```bash
git checkout main
container-use merge fancy-mallard
# Merges environment changes into current branch
```

### `container-use apply`

Apply an environment's changes as staged modifications without commits.

```bash
container-use apply {environment-id}
```

**Options:**
- `--delete`, `-d` - Delete environment after successful apply

**Example:**
```bash
git checkout main
container-use apply fancy-mallard
# Stages all changes for you to commit
```

### `container-use delete`

Delete an environment and clean up its resources.

```bash
container-use delete {environment-id}
```

**Options:**
- `--all` - Delete all environments

**Example:**
```bash
container-use delete fancy-mallard
# Deletes the specified environment

container-use delete --all
# Deletes all environments
```

### `container-use watch`

Monitor environment activity in real-time as agents work.

```bash
container-use watch
```

**Example:**
```bash
container-use watch
# Shows live updates from all active environments
```

### `container-use config`

Manage default environment configurations.

```bash
container-use config {subcommand}
```

**Configuration Management:**
- `show [environment-id]` - Display current configuration
- `import {environment-id}` - Import configuration from an environment

**Base Image:**
- `base-image set {image}` - Set default base image
- `base-image get` - Show current base image
- `base-image reset` - Reset to default base image

**Setup Commands:**
- `setup-command add {command}` - Add setup command
- `setup-command remove {command}` - Remove setup command
- `setup-command list` - List setup commands
- `setup-command clear` - Clear all setup commands

**Install Commands:**
- `install-command add {command}` - Add install command
- `install-command remove {command}` - Remove install command
- `install-command list` - List install commands
- `install-command clear` - Clear all install commands

**Environment Variables:**
- `env set {key} {value}` - Set environment variable
- `env unset {key}` - Unset environment variable
- `env list` - List environment variables
- `env clear` - Clear all environment variables

**Secrets:**
- `secret set {key} {value}` - Set secret
- `secret unset {key}` - Unset secret
- `secret list` - List secrets
- `secret clear` - Clear all secrets

**Agent Integration:**
- `agent [agent]` - Configure MCP server for specific agent (claude, goose, cursor, etc.)

**Example:**
```bash
container-use config show
# Shows current configuration

container-use config base-image set python:3.11
# Sets Python 3.11 as default base image

container-use config setup-command add "pip install -r requirements.txt"
# Adds pip install as setup command
```

### `container-use version`

Display Container Use version information.

```bash
container-use version
```

### `container-use stdio`

Start Container Use as an MCP (Model Context Protocol) server for agent integration.

```bash
container-use stdio
```

**Note:** This command is typically used in agent configuration files, not run directly by users.

### `container-use completion`

Generate shell completion scripts.

```bash
container-use completion {shell}
```

**Supported shells:** bash, zsh, fish, powershell

**Example:**
```bash
container-use completion bash > /etc/bash_completion.d/container-use
# Installs bash completion
```


## Environment IDs

Environment IDs are randomly generated two-word identifiers like `fancy-mallard` or `clever-dolphin`. You can use:

- Full ID: `fancy-mallard`
- Partial ID: `fancy` (if unique)
- Branch name: `cu-fancy-mallard`

## Exit Codes

- `0` - Success
- `1` - General error
- `2` - Command syntax error
- `3` - Environment not found
- `4` - Operation cancelled

## Examples

### Basic Workflow

```bash
# 1. List environments
container-use list

# 2. Review changes
container-use diff clever-dolphin

# 3. Check out locally
container-use checkout clever-dolphin

# 4. Accept work
container-use merge clever-dolphin
```

### Debugging Workflow

```bash
# 1. See what agent did
container-use log problematic-env

# 2. Enter container to debug
container-use terminal problematic-env

# 3. Fix issues...

# 4. Apply changes
container-use apply problematic-env
```

### Monitoring Workflow

```bash
# 1. Start watching
container-use watch

# 2. Agent works in background...

# 3. See specific environment
container-use log active-env
```




================================================
FILE: docs/docs.json
================================================
{
  "$schema": "https://mintlify.com/docs.json",
  "theme": "mint",
  "name": "Container Use",
  "description": "Sandboxed dev environments for agents to work safely in parallel. Powered by Dagger.",
  "colors": {
    "primary": "#0D9373",
    "light": "#07C983",
    "dark": "#0D9373"
  },
  "favicon": "/images/dagger-icon.png",
  "redirects": [
    {
      "source": "/discord",
      "destination": "https://discord.gg/NQDJTBC6Qk"
    },
    {
      "source": "/installation",
      "destination": "/quickstart"
    }
  ],
  "navigation": {
    "groups": [
      {
        "group": "Get Started",
        "pages": [
          "introduction",
          "quickstart"
        ]
      },
      {
        "group": "Guides",
        "pages": [
          "environment-workflow",
          "environment-configuration",
          "secrets"
        ]
      },
      {
        "group": "Reference",
        "pages": [
          "cli-reference",
          "agent-integrations"
        ]
      }
    ]
  },
  "global": {
    "anchors": [
      {
        "anchor": "GitHub",
        "href": "https://github.com/dagger/container-use",
        "icon": "github"
      },
      {
        "anchor": "Discord",
        "href": "https://container-use.com/discord",
        "icon": "discord"
      }
    ]
  },
  "logo": {
    "light": "/images/dagger-icon.png",
    "dark": "/images/dagger-icon.png"
  },
  "navbar": {
    "links": [
      {
        "label": "Support",
		"href": "https://container-use.com/discord"
      }
    ],
    "primary": {
      "type": "button",
      "label": "GitHub",
      "href": "https://github.com/dagger/container-use"
    }
  },
  "footer": {
    "socials": {
      "github": "https://github.com/dagger/container-use",
      "discord": "https://container-use.com/discord"
    }
  }
}



================================================
FILE: docs/environment-configuration.mdx
================================================
---
title: Environment Configuration
description: "Set up and manage your project's environment configurations."
icon: gear
---

Environment configuration works in two layers:

1. **Default Configuration**: Your project's baseline environment that all agents start from
2. **Agent Adaptations**: Changes agents make during work (ephemeral until imported)

<Note>
  Configuration changes only apply to **new environments**. Agent modifications remain in their environment until you import them with `container-use config import`.
</Note>

## The Configuration Workflow

<Steps>
  <Step title="Set Default Configuration">
    Configure your project's baseline environment that all agents will start from
  </Step>
  <Step title="Agent Starts with Defaults">
    When an agent creates a new environment, it begins with your default configuration
  </Step>
  <Step title="Agent Adapts as Needed">
    During work, the agent may modify its environment configuration - adding tools, changing base images, or setting variables
  </Step>
  <Step title="View Agent Changes">
    Use `container-use config show <env>` to see what configuration changes the agent made
  </Step>
  <Step title="Import Useful Changes">
    Use `container-use config import <env>` to adopt the agent's configuration improvements as your new defaults
  </Step>
</Steps>

## Default Configuration

Configure the baseline environment that all agents will start from when working on your project. Instead of using the generic environment, you can specify exactly what base image, dependencies, and setup your project needs as defaults. 

By default, environments use Ubuntu 24.04 with standard tools (git, curl, bash, apt).

### Example: Python Project

To customize for your project:

```bash
# Set the base image to Python 3.11
container-use config base-image set python:3.11

# Add setup commands for system dependencies
container-use config setup-command add "apt-get update && apt-get install -y build-essential"

# Add install commands for project dependencies
container-use config install-command add "pip install -r requirements.txt"
container-use config install-command add "pip install pytest black flake8"

# Set environment variables
container-use config env set PYTHONPATH /workdir
container-use config env set DEBUG true

# View your configuration
container-use config show
```

Now all new agent environments will start with Python 3.11, your dependencies pre-installed, and environment variables configured.

## Working with Configurations

Agents can modify their environment during work - installing tools, changing settings, or adapting to specific tasks. These changes are ephemeral until you import them.

### View Configurations

```bash
# View your default configuration
container-use config show

# View an agent's modified configuration
container-use config show fancy-mallard

# Output as JSON
container-use config show --json
```

### Import Agent Changes

When agents make useful changes, import them as your new defaults:

```bash
container-use config import fancy-mallard
```

## Configuration Commands

### Base Image

```bash
container-use config base-image set python:3.11
container-use config base-image get
container-use config base-image reset  # Resets to ubuntu:24.04
```

<Note>
  **Using custom images**: If you use custom base images with `latest` tags and update them frequently, consider using versioned tags (e.g., `myimage:v1.2.3`) for more predictable cache behavior.
</Note>

### Setup Commands

Run after pulling base image, before copying code:

```bash
container-use config setup-command add "apt-get update && apt-get install -y build-essential"
container-use config setup-command list
container-use config setup-command remove "apt-get install -y build-essential"
container-use config setup-command clear
```

### Install Commands

Run after copying code:

```bash
container-use config install-command add "npm install"
container-use config install-command list
container-use config install-command remove "npm install"
container-use config install-command clear
```

### Environment Variables

```bash
container-use config env set NODE_ENV development
container-use config env list
container-use config env unset NODE_ENV
container-use config env clear
```

### Secrets

Configure secure access to API keys and credentials. See the [complete secrets guide](/secrets) for all secret types and examples.

```bash
container-use config secret set API_KEY
container-use config secret list
container-use config secret unset API_KEY
container-use config secret clear
```


## Configuration Storage

Configuration is stored in `.container-use/environment.json`. Commit this directory to share setup with your team.

## Troubleshooting

If environment creation fails, check logs and fix the problematic command:

```bash
container-use log <environment-id>
container-use config setup-command remove "broken-command"
container-use config setup-command add "fixed-command"
```


## Next Steps

<CardGroup cols={2}>
  <Card
    title="Environment Workflow"
    icon="arrows-rotate"
    href="/environment-workflow"
  >
    Learn how to work with the environments agents create
  </Card>
  <Card title="Agent Integrations" icon="robot" href="/agent-integrations">
    Set up your coding agent to work with Container Use
  </Card>
</CardGroup>


================================================
FILE: docs/environment-workflow.mdx
================================================
---
title: Environment Workflow
description: "Master the workflow of creating, observing, and managing containerized environments. Learn when to merge work, iterate on prompts, or start fresh."
icon: arrows-rotate
---

## What are Environments?

Each environment in Container Use is an **isolated workspace** that combines:

- **üå≥ Git Branch**: Dedicated branch tracking all changes and history
- **üì¶ Container**: Isolated runtime with your code and dependencies
- **üìù Complete History**: Every command, file change, and container state automatically tracked

Think of environments as **disposable sandboxes** where agents can work safely without affecting your main codebase.

## The Core Workflow

Container Use follows a simple but powerful pattern:

<Steps>
  <Step title="Agent Creates Fresh Environment">
    Every agent session starts with a brand new environment from your current
    branch state.
  </Step>
  <Step title="Agent Works in Isolation">
    The agent makes changes, runs commands, and builds features completely
    isolated from your work.
  </Step>
  <Step title="You Observe the Work">
    Use Container Use commands to see what the agent did without disrupting your
    local setup.
  </Step>
  <Step title="Make a Decision">
    Accept good work using merge or apply, iterate with refined prompts, or
    discard failed attempts.
  </Step>
</Steps>

## Observing Agent Work

You have two modes for inspecting what an agent accomplished:

### Quick Assessment (Non-Interactive)

Perfect for getting the gist and deciding next steps:

```bash
# See all environments at a glance
container-use list

# View exactly what the agent did
container-use log fancy-mallard

# See code changes without checking out
container-use diff fancy-mallard
```

<Card title="When to use" icon="eye">
  Use quick assessment when you want to rapidly understand if the agent is on
  the right track, see what files changed, or review the approach before diving
  deeper.
</Card>

<Note>
  üîí **Secret Security**: If the agent used any secrets (API keys, database
  credentials), these were resolved within the container environment - agents
  can use your credentials without the AI model ever seeing the actual values.
</Note>

### Deep Exploration (Interactive)

When you need hands-on understanding:

```bash
# Drop into the live container environment
container-use terminal fancy-mallard

# Bring changes into your local workspace/IDE
container-use checkout fancy-mallard
```

<Card title="When to use" icon="magnifying-glass">
  Use deep exploration when you need to test functionality, debug issues,
  understand complex changes, or review code thoroughly in your IDE.
</Card>

## Making Decisions

After observing the agent's work, you have three paths forward:

### ‚úÖ Accept Work

When the agent succeeded and you're happy with the results, you have two options:

**Option 1: Merge (Preserve History)**
```bash
# Merge the environment into your current branch
container-use merge fancy-mallard

# Clean up (optional)
container-use delete fancy-mallard
```

**Option 2: Apply (Customize Commit)**
```bash
# Apply changes as staged modifications
container-use apply fancy-mallard

# Review and commit with your own message
git status
git commit -m "Your custom commit message"

# Clean up (optional)
container-use delete fancy-mallard
```

Choose `merge` to preserve the agent's commit history, or `apply` to create your own commit message and review changes before committing.

### üîÑ Iterate & Refine

When the agent is close but needs refinement:

```bash
# A. Continue the existing chat
# Prompt: "[refined instructions]"
# B. Start a new chat and continue working in the same environment.
# Prompt: "Work in the fancy-mallard environment and [refined instructions]"
```

The agent will resume in the existing environment with all previous work intact. Perfect for:
- Adding missing features
- Fixing bugs the agent introduced
- Adjusting styling or behavior
- Building on partial progress

### üóëÔ∏è Start Fresh

When the agent went down the wrong path:

```bash
# Discard the environment
container-use delete fancy-mallard

# Start over with a new prompt
# The agent will create a fresh environment from your current branch
```

You're back to your last known good state (your current branch) and can try a different approach.

## Resuming Work in Environments

To have a new chat continue work in an existing environment, simply mention the environment ID in your prompt:

<CodeGroup>
```text Good Resume Prompts
"Work in the fancy-mallard environment and add user authentication"

"Continue in environment fancy-mallard - the tests are failing, please fix them"

"Using the fancy-mallard environment, add CSS styling to make it look modern"

````

```text What Happens
The agent will:
‚úÖ Reuse the existing container state
‚úÖ Have access to all previous work
‚úÖ Continue from where it left off
‚úÖ Maintain the same dependencies and setup
````

</CodeGroup>

## Practical Examples

### Example 1: Happy Path Workflow

```bash
# 1. Agent creates environment and builds feature
$ container-use list
ID            TITLE                    CREATED       UPDATED
fancy-mallard Flask App with Login     2 mins ago    30 secs ago

# 2. Quick check - looks good!
$ container-use diff fancy-mallard
+def login():
+    # Authentication logic
+    pass

# 3. Accept the work (choose merge or apply)
$ container-use merge fancy-mallard
Updating abc123..def456
Fast-forward
 app.py | 15 +++++++++++++++
 1 file changed, 15 insertions(+)
```

### Example 2: Iteration Workflow

```bash
# 1. Check what agent built
$ container-use log fancy-mallard
def4567a2  Add basic login form (30 minutes ago)
$ flask run

# 2. Needs improvement - continue in same environment
# Prompt: "Work in fancy-mallard environment and add password validation"

# 3. Check again after agent works
$ container-use diff fancy-mallard
# Now shows both original work + new validation
```

### Example 3: Recovery Workflow

```bash
# 1. Agent's approach isn't working
$ container-use log problematic-env
# Shows agent went down wrong path with complex dependency issues

# 2. Cut losses and start fresh
$ container-use delete problematic-env

# 3. Try different approach
# New prompt: "Create a simple REST API using FastAPI instead of Flask"
# Agent creates fresh environment from clean state
```

## Managing Multiple Environments

You can have multiple agents working simultaneously:

```bash
$ container-use list
ID              TITLE                     CREATED       UPDATED
frontend-work   React UI Components       5 mins ago    1 min ago
backend-api     FastAPI User Service      3 mins ago    2 mins ago
data-pipeline   ETL Processing Script     1 min ago     30 secs ago
```

Each environment is completely isolated - no conflicts, no interference.

## Best Practices

- **Start with Quick Assessment**: Always use `container-use diff` and `container-use log` first. Most of the time, this gives you enough information to decide next steps without the overhead of checking out or entering containers.

- **Merge vs Apply**: Use `merge` when you want to preserve the agent's commit history and understand how the work evolved. Use `apply` when you want to create clean, customized commits or review changes before committing.

- **Don't Be Afraid to Delete**: Environments are disposable by design. If an agent gets stuck or goes down the wrong path, it's often faster to delete and start fresh than to try to fix problematic work.

- **Use Specific Resume Prompts**: When resuming work, be specific about what you want. Instead of "continue working", say "work in ENV-ID and add error handling to the upload function".

- **Keep Your Branch Clean**: Your main working branch should only contain merged, tested work. Use environments for all experimental and agent-driven development.

## Essential Commands Reference

| | |
| --- | --- |
| `container-use list` | See all environments and their status |
| `container-use watch` | Monitor environment activity in real-time as agents work |
| `container-use log <env-id>` | View commit history and commands to understand what the agent did |
| `container-use diff <env-id>` | Quick assessment of code changes |
| `container-use terminal <env-id>` | Enter live container to debug, test, or explore |
| `container-use checkout <env-id>` | Bring changes to local IDE for detailed review |
| `container-use merge <env-id>` | Accept work preserving agent's commit history |
| `container-use apply <env-id>` | Apply as staged changes to customize commits |
| `container-use delete <env-id>` | Discard environment and start over |
| `container-use config` | Configure default settings for new environments |
| `container-use version` | Display version information |

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Environment Configuration"
    icon="gear"
    href="/environment-configuration"
  >
    Configure your project's default environment setup
  </Card>
  <Card
    title="Join Community"
    icon="discord"
    href="https://container-use.com/discord"
  >
    Share your environment workflow strategies in #container-use
  </Card>
</CardGroup>



================================================
FILE: docs/introduction.mdx
================================================
---
title: "Introduction"
description: "Sandboxed dev environments for coding agents."
icon: "book"
---

<img
  className="block dark:hidden"
  src="/images/container-use.png"
  alt="Container Use Hero Light"
  noZoom={true}
/>

<img
  className="hidden dark:block"
  src="/images/container-use.png"
  alt="Container Use Hero Dark"
  noZoom={true}
/>

**Container Use** gives your coding agents sandboxed dev environments to work in, so they can run safely in parallel without requiring babysitting.

Container Use leverages [Dagger](https://dagger.io) for containerized workflows and Git worktrees for branching.

<CardGroup cols={2}>
  <Card title="Sandboxed Environments" icon="box" iconType="duotone">
    Each agent gets a fresh container in its own git branch - run multiple agents without conflicts, experiment safely, discard failures instantly.
  </Card>
  <Card title="Real-time Visibility" icon="eye" iconType="duotone">
    See complete command history and logs of what agents actually did, not just what they claim.
  </Card>
  <Card title="Direct Intervention" icon="helicopter" iconType="duotone">
    Drop into any agent's terminal to see their state and take control when they get stuck.
  </Card>
  <Card title="Environment Control" icon="gamepad" iconType="duotone">
    Standard git workflow - just `git checkout <branch_name>` to review any agent's work.
  </Card>
</CardGroup>


## Get Started

<CardGroup cols={2}>
  <Card title="Quickstart" icon="rocket" href="/quickstart">
    Install Container Use on your system using Homebrew, shell script, or build
    from source
  </Card>
  <Card title="Agent Integration" icon="puzzle-piece" href="/agent-integrations">
    Configure Container Use with your coding agent (Claude Code, Cursor, VSCode,
    etc.)
  </Card>
</CardGroup>

## Community

Join our community to get help, share examples, and contribute to the project:

<CardGroup cols={3}>
  <Card title="Discord" icon="discord" href="https://container-use.com/discord">
    Join the #container-use channel for real-time support
  </Card>
  <Card title="GitHub" icon="github" href="https://github.com/dagger/container-use">
    Star the repo, report issues, and contribute code
  </Card>
  <Card title="YouTube" icon="youtube" href="https://www.youtube.com/playlist?list=PLyHqb4A5ee1u5LrsbalfVkBRsrbjDsnN5">
    Watch the Container Use playlist for examples and tutorials
  </Card>
</CardGroup>


================================================
FILE: docs/quickstart.mdx
================================================
---
title: Quickstart
description: "Get started with Container Use in 5 minutes."
icon: rocket
---

In this quickstart, you'll install Container Use, connect it to your coding agent, and experience the core workflow: agents work in isolated environments while your files stay untouched, then review and decide what to do with their work.

## 1. Install Container Use

Make sure you have [Docker](https://www.docker.com/get-started) and Git installed before starting.

<Tabs>
  <Tab title="Homebrew (macOS)">

  ```sh
  brew install dagger/tap/container-use
  container-use version   # ‚Üí confirms install
  ```

  </Tab>

  <Tab title="Shell Script (All Platforms)">

  ```sh
  curl -fsSL https://raw.githubusercontent.com/dagger/container-use/main/install.sh | bash
  container-use version
  ```

  </Tab>

  <Tab title="Build from Source">

  ```sh
  git clone https://github.com/dagger/container-use.git
  cd container-use
  go build -o container-use ./cmd/container-use
  sudo mv container-use /usr/local/bin/
  container-use version
  ```

  </Tab>
</Tabs>

## 2. Point your agent at Container Use

Container Use works with any MCP-compatible agent: Just add `container-use stdio` as an MCP server. This example uses Claude Code but you can view [instructions for other agents](/agent-integrations).

<Steps>
  <Step title="Add MCP Configuration">
    ```sh
    cd /path/to/repository
    claude mcp add container-use -- container-use stdio
    ```
  </Step>

  <Step title="Add Agent Rules (Optional)">
    Save CLAUDE.md file at the root of your repository:

    ```sh
    curl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> CLAUDE.md
    ```
  </Step>

  <Step title="Trust Only Container Use Tools (Optional)">
    For maximum security, restrict Claude Code to only use Container Use tools:

    ```sh
    claude --allowedTools mcp__container-use__environment_checkpoint,mcp__container-use__environment_create,mcp__container-use__environment_add_service,mcp__container-use__environment_file_delete,mcp__container-use__environment_file_list,mcp__container-use__environment_file_read,mcp__container-use__environment_file_write,mcp__container-use__environment_open,mcp__container-use__environment_run_cmd,mcp__container-use__environment_update
    ```
  </Step>
</Steps>

## 3. Run your first parallel task

Let's create a demo repository and ask your agent to build something:

```sh
# start a demo repo
mkdir hello
cd hello
git init
touch README.md
git add README.md
git commit -m "initial commit"
```

Now prompt your agent to do something:
```text
"Create a Flask hello‚Äëworld app in Python."
```

After a short run you'll see something like:

```text
‚úÖ App running at http://127.0.0.1:58455
üîç View files:  container-use checkout {id}
üìã Dev log:     container-use log {id}
```

<Note>
Replace `{id}` with your actual environment ID like `fancy-mallard`
</Note>

Notice your local directory is still empty, because the agent worked in an isolated environment:

```sh
$ ls
README.md
```

You can see all environments with `container-use list`.

## 4. Review the work

See what the agent changed:
```sh
container-use diff {id}
```

Check out the environment locally to explore:
```sh
container-use checkout {id}
```

## 5. Accept or discard

Accept the work and keep the agent's commit history:
```sh
container-use merge {id}
```

Or stage the changes to create your own commit:
```sh
container-use apply {id}
```

üéâ That's it ‚Äì you've run an agent in parallel, checked its work, and decided what to do with it.



================================================
FILE: docs/secrets.mdx
================================================
---
title: Secrets Management
description: "Secure secret management for agents. Configure API keys, database credentials, and other sensitive data with 1Password, environment variables, and file references."
icon: key
---

Container Use provides secure secret management for agents working with sensitive data like API keys, database credentials, and authentication tokens. **Secrets are resolved within the container environment - agents can use your credentials without the AI model ever seeing the actual values.**

### How It Works

When you configure secrets, Container Use:
- **Stores secret references** in your configuration (agents only see `op://vault/item/field`, not actual values)
- **Resolves references dynamically** when commands run and injects actual values as environment variables in the container
- **Strips secrets from logs and command outputs** to prevent leaks
- **Prevents easy extraction** by agents (e.g., `echo $API_KEY` won't show in logs)

This means:
- ‚úÖ Your application code can access secrets normally
- ‚úÖ Agents can run your code that uses secrets  
- ‚ùå The AI model never sees actual secret values
- ‚ùå Secrets don't appear in chat logs or model context

<Note>
  Secrets are configured per-project and apply to all new environments. Existing environments continue using their original configuration.
</Note>

## Secret Types

Container Use supports four secure secret reference formats:

<Tabs>
  <Tab title="üîê 1Password">
    Access secrets stored in 1Password vaults using the `op://` schema:

    ```bash
    # Basic format: op://vault/item/field
    container-use config secret set API_KEY "op://vault/item/field"
    container-use config secret set DB_PASSWORD "op://production/database/password"
    container-use config secret set JWT_SECRET "op://team-vault/auth-service/jwt_secret"
    ```

    Requires 1Password CLI to be installed and authenticated on your system.
  </Tab>

  <Tab title="üåç Environment Variables">
    Reference secrets from your local environment using the `env://` schema:

    ```bash
    # Basic format: env://VARIABLE_NAME
    container-use config secret set GITHUB_TOKEN "env://GITHUB_TOKEN"
    container-use config secret set OPENAI_API_KEY "env://OPENAI_API_KEY"
    container-use config secret set DATABASE_URL "env://DATABASE_URL"
    ```

    Perfect for CI/CD environments where secrets are already available as environment variables.
  </Tab>

  <Tab title="üèõÔ∏è HashiCorp Vault">
    Access secrets stored in HashiCorp Vault using the `vault://` schema:

    ```bash
    # Basic format: vault://path/to/secret
    container-use config secret set GITHUB_TOKEN "vault://credentials.github"
    container-use config secret set DATABASE_PASSWORD "vault://database/prod/password"
    container-use config secret set API_KEY "vault://kv/data/myapp/api_key"
    ```

    Requires HashiCorp Vault to be accessible and properly authenticated.
  </Tab>

  <Tab title="üìÅ File References">
    Read secrets from local files using the `file://` schema:

    ```bash
    # Basic format: file://path/to/secret
    container-use config secret set SSH_KEY "file://~/.ssh/id_rsa"
    container-use config secret set SERVICE_ACCOUNT "file://./credentials.json"
    container-use config secret set TLS_CERT "file:///etc/ssl/certs/app.crt"
    ```

    Useful for SSH keys, certificates, and credential files.
  </Tab>
</Tabs>

## Configuration Commands

```bash
# Set a secret using any supported schema
container-use config secret set <KEY_NAME> <secret_reference>

# Examples for each type
container-use config secret set DATABASE_URL "env://DATABASE_URL"
container-use config secret set API_TOKEN "op://vault/api/token"
container-use config secret set GITHUB_TOKEN "vault://credentials.github"
container-use config secret set SSH_KEY "file://~/.ssh/deploy_key"

# List all configured secrets (values are masked)
container-use config secret list

# Remove a secret
container-use config secret unset API_KEY

# Clear all secrets
container-use config secret clear

# View complete configuration including secrets
container-use config show
```

## Using Secrets in Your Code

Once configured, secrets are available as **environment variables** inside agent environments:

<Tabs>
  <Tab title="üêç Python">
    ```python
    import os
    import requests

    api_key = os.getenv("API_KEY")
    response = requests.get("https://api.example.com", 
                          headers={"Authorization": f"Bearer {api_key}"})
    ```
  </Tab>

  <Tab title="üü¢ Node.js">
    ```javascript
    const apiKey = process.env.API_KEY;
    const response = await fetch("https://api.example.com", {
      headers: { "Authorization": `Bearer ${apiKey}` }
    });
    ```
  </Tab>

  <Tab title="üêö Shell">
    ```bash
    # Shell scripts can also access secrets
    curl -H "Authorization: Bearer $API_KEY" https://api.example.com
    ```
  </Tab>
</Tabs>

<Warning>
  **Security Note**: While your code can access secrets normally, Container Use automatically strips secret values from logs and command outputs. This means `echo $API_KEY` or similar commands won't expose secrets in the development logs that agents or users can see.
</Warning>



================================================
FILE: environment/README.md
================================================
# Environments

An **environment** is an isolated, containerized development workspace that combines Docker containers with Git branches to provide agents with safe, persistent workspaces.

## What is an Environment?

Each environment consists of:
- **Git Branch**: Dedicated branch tracking all changes and history
- **Container**: Dagger container with your code and dependencies
- **History**: Versioned snapshots of container state changes appended to the branch as notes
- **Configuration**: Base image, setup commands, secrets, and instructions that can be checked into the source repo.

## Key Features

- **Branch-Based**: Each environment is a Git branch that syncs into the container-use/ remote
- **Isolation**: Each environment runs in its own container and branch
- **Persistence**: All changes automatically committed with full history
- **Standard Git**:
  - Use `git log` to view source code history
  - Use `git log --notes=container-use` to view container operation history
  - Use `git checkout env-branch` to inspect any environment's work - each env branch tracks the upstream container-use/
- **State Recovery**: Container states stored in Git notes for reconstruction

## How It Works

When you create an environment, container-use:

1. **Creates a new Git branch** in your source repo (e.g., `env-name/adverb-animal`)
2. **Sets up a container-use remote branch** inside `~/.config/container-use/repos/project/`
3. **Sets up a worktree copy of the branch** in `~/.config/container-use/worktrees/project/`
4. **Spins up a Dagger container** with that worktree copied into `/workdir`

When an agent runs commands:

1. **Commands execute** inside the isolated container
2. **File changes get written** back to the container filesystem
3. **Container state is preserved** in the Dagger container's LLB definition
4. **Everything gets committed** to the environment's Git branch automatically
5. **Container state snapshots** are stored as Git notes using `container-use-state` ref
6. **Operation logs** are stored as Git notes using `container-use` ref

Each environment is just a Git branch that your source repo tracks on the container-use/ remote. You can inspect any environment's work using standard Git commands, and the container state can always be reconstructed from an environment branch's Git history and notes.

## Architecture

```
projectName/ Source Repo                container-use/ Remote
‚îú‚îÄ‚îÄ feature-branch ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ cu merge/apply ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îú‚îÄ‚îÄ main (current) ‚îÄ‚îÄ environment_create ‚îÄ‚îÄ‚Üí adverb-animal
‚îî‚îÄ‚îÄ cu-adverb-animal ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ cu checkout ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                                       ‚îÇ (host filesystem implementation)
                                       ‚ñº
                    ~/.config/container-use/
                    ‚îú‚îÄ‚îÄ repos/projectName/ (bare)
                    ‚îî‚îÄ‚îÄ worktrees/adverb-animal (only env branches become worktrees)
                        ‚îú‚îÄ‚îÄ .git -> ../../repos/projectName/worktrees/adverb-animal
                        ‚îî‚îÄ‚îÄ (your code)
                            ‚îÇ
                            ‚ñº
                        Container
                        ‚îî‚îÄ‚îÄ /workdir
```

The diagram shows how environment branches sync between your source repo and the container-use remote. When you create an environment, the current branch content gets pushed to the container-use remote as `adverb-animal`. When you checkout an environment, it creates a local tracking branch `cu-adverb-animal` that tracks the remote environment branch. Regular branches like `main` and `feature-branch` stay only in your source repo.

You can accept the environment's work into your current branch using either:
- **`cu merge`** - Preserves the agent's commit history
- **`cu apply`** - Stages changes for you to commit with your own message

Below the branch level, the system creates a bare Git repository and worktree in `~/.config/container-use/` - this is plumbing to make the Git operations work with minimal modifications to your source repository. The worktree contains a copy of your code that gets mounted into the Docker container at `/workdir`.

So the flow is: **Branch** (the logical environment) ‚Üí **Worktree** (filesystem implementation) ‚Üí **Container** (where code actually runs).

## Files

- `environment.go` - Core environment management and container operations
- `config.go` - Configuration management and persistence
- `state.go` - Container state serialization and legacy migration
- `service.go` - Service management for multi-container environments
- `note.go` - Git notes management for operation logging
- `filesystem.go` - File operations within containers
- `../repository/git.go` - Worktree and Git integration
- `../repository/repository.go` - High-level repository operations


================================================
FILE: environment/config.go
================================================
package environment

import (
	"bytes"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
)

const (
	defaultImage    = "ubuntu:24.04"
	alpineImage     = "alpine:3.21.3@sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c"
	configDir       = ".container-use"
	environmentFile = "environment.json"
)

func DefaultConfig() *EnvironmentConfig {
	return &EnvironmentConfig{
		BaseImage: defaultImage,
		Workdir:   "/workdir",
	}
}

type EnvironmentConfig struct {
	Workdir         string         `json:"workdir,omitempty"`
	BaseImage       string         `json:"base_image,omitempty"`
	SetupCommands   []string       `json:"setup_commands,omitempty"`
	InstallCommands []string       `json:"install_commands,omitempty"`
	Env             KVList         `json:"env,omitempty"`
	Secrets         KVList         `json:"secrets,omitempty"`
	Services        ServiceConfigs `json:"services,omitempty"`
}

type ServiceConfig struct {
	Name         string   `json:"name,omitempty"`
	Image        string   `json:"image,omitempty"`
	Command      string   `json:"command,omitempty"`
	ExposedPorts []int    `json:"exposed_ports,omitempty"`
	Env          []string `json:"env,omitempty"`
}

type ServiceConfigs []*ServiceConfig

func (sc ServiceConfigs) Get(name string) *ServiceConfig {
	for _, cfg := range sc {
		if cfg.Name == name {
			return cfg
		}
	}
	return nil
}

// KVList represents a list of key-value pairs in the format KEY=VALUE
type KVList []string

// parseKeyValue parses a key-value string in the format "KEY=VALUE"
func (kv KVList) parseKeyValue(raw string) (key, value string) {
	k, v, _ := strings.Cut(raw, "=")
	return k, v
}

// Set adds or updates a key-value pair
func (kv *KVList) Set(key, value string) {
	// Remove existing key if it exists
	kv.Unset(key)
	// Add new key-value pair
	*kv = append(*kv, fmt.Sprintf("%s=%s", key, value))
}

// Unset removes a key-value pair by key and returns true if the key was found
func (kv *KVList) Unset(key string) bool {
	found := false
	newList := make([]string, 0, len(*kv))
	for _, item := range *kv {
		if itemKey, _ := kv.parseKeyValue(item); itemKey != key {
			newList = append(newList, item)
		} else {
			found = true
		}
	}
	*kv = newList
	return found
}

// Clear removes all key-value pairs
func (kv *KVList) Clear() {
	*kv = []string{}
}

// Keys returns all keys in the list
func (kv KVList) Keys() []string {
	keys := make([]string, 0, len(kv))
	for _, item := range kv {
		if key, _ := kv.parseKeyValue(item); key != "" {
			keys = append(keys, key)
		}
	}
	return keys
}

// Get returns the value for a given key, or empty string if not found
func (kv KVList) Get(key string) string {
	for _, item := range kv {
		if itemKey, value := kv.parseKeyValue(item); itemKey == key {
			return value
		}
	}
	return ""
}

func (config *EnvironmentConfig) Copy() *EnvironmentConfig {
	copy := *config
	copy.Services = make(ServiceConfigs, len(config.Services))
	for i, svc := range config.Services {
		svcCopy := *svc
		copy.Services[i] = &svcCopy
	}
	return &copy
}

func (config *EnvironmentConfig) Save(baseDir string) error {
	configPath := filepath.Join(baseDir, configDir)
	if err := os.MkdirAll(configPath, 0755); err != nil {
		return err
	}

	// Use a custom encoder to prevent HTML escaping of characters like &, <, >
	var buf bytes.Buffer
	encoder := json.NewEncoder(&buf)
	encoder.SetIndent("", "  ")
	encoder.SetEscapeHTML(false) // This prevents & from being escaped as \u0026

	if err := encoder.Encode(config); err != nil {
		return err
	}

	if err := os.WriteFile(filepath.Join(configPath, environmentFile), buf.Bytes(), 0600); err != nil {
		return err
	}

	return nil
}

func (config *EnvironmentConfig) Load(baseDir string) error {
	configPath := filepath.Join(baseDir, configDir)

	data, err := os.ReadFile(filepath.Join(configPath, environmentFile))
	if err != nil && !os.IsNotExist(err) {
		return err
	}
	if err == nil {
		if err := json.Unmarshal(data, config); err != nil {
			return err
		}
	}

	return nil
}



================================================
FILE: environment/config_test.go
================================================
package environment

import (
	"encoding/json"
	"os"
	"path/filepath"
	"runtime"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestEnvironmentConfig_Load verifies the best-effort loading behavior
// The Load method should gracefully handle missing files while still failing on actual errors
func TestEnvironmentConfig_Load(t *testing.T) {
	scenarios := []struct {
		name            string
		setup           func(t *testing.T, dir string)
		expectError     bool
		expectBaseImage string
		expectWorkdir   string
	}{
		{
			name:            "both_files_missing",
			setup:           func(t *testing.T, dir string) {}, // no setup
			expectError:     false,
			expectBaseImage: "ubuntu:24.04",
			expectWorkdir:   "/workdir",
		},
		{
			name: "only_instructions_missing",
			setup: func(t *testing.T, dir string) {
				createConfigFile(t, dir, &EnvironmentConfig{
					BaseImage: "custom:image",
					Workdir:   "/custom",
				})
			},
			expectError:     false,
			expectBaseImage: "custom:image",
			expectWorkdir:   "/custom",
		},
		{
			name: "only_environment_missing",
			setup: func(t *testing.T, dir string) {
				createInstructionsFile(t, dir, "Custom instructions")
			},
			expectError:     false,
			expectBaseImage: "ubuntu:24.04",
			expectWorkdir:   "/workdir",
		},
		{
			name: "both_files_present",
			setup: func(t *testing.T, dir string) {
				createInstructionsFile(t, dir, "Test instructions")
				createConfigFile(t, dir, &EnvironmentConfig{
					BaseImage: "test:image",
					Workdir:   "/test",
				})
			},
			expectError:     false,
			expectBaseImage: "test:image",
			expectWorkdir:   "/test",
		},
		{
			name: "invalid_json",
			setup: func(t *testing.T, dir string) {
				configDir := filepath.Join(dir, ".container-use")
				require.NoError(t, os.MkdirAll(configDir, 0755))
				require.NoError(t, os.WriteFile(filepath.Join(configDir, "environment.json"), []byte("invalid json"), 0644))
			},
			expectError: true,
		},
		{
			name: "config_directory_permission_error",
			setup: func(t *testing.T, dir string) {
				if os.Getuid() == 0 {
					t.Skip("Skipping permission test as root")
				}
				if runtime.GOOS == "windows" {
					t.Skip("Skipping permission test on Windows - Windows file permissions work differently")
				}
				configDir := filepath.Join(dir, ".container-use")
				require.NoError(t, os.MkdirAll(configDir, 0000))
				t.Cleanup(func() { os.Chmod(configDir, 0755) })
			},
			expectError: true,
		},
	}

	for _, scenario := range scenarios {
		t.Run(scenario.name, func(t *testing.T) {
			tempDir := t.TempDir()
			config := DefaultConfig()

			scenario.setup(t, tempDir)

			err := config.Load(tempDir)

			if scenario.expectError {
				assert.Error(t, err)
				return
			}

			require.NoError(t, err)
			assert.Equal(t, scenario.expectBaseImage, config.BaseImage)
			assert.Equal(t, scenario.expectWorkdir, config.Workdir)
		})
	}
}

// TestEnvironmentConfig_PreservesShellOperators tests that shell operators like && are not
// escaped as unicode sequences when saving and loading configuration
func TestEnvironmentConfig_PreservesShellOperators(t *testing.T) {
	tempDir := t.TempDir()

	// Create a config with shell operators in setup commands
	originalConfig := &EnvironmentConfig{
		BaseImage: "ubuntu:24.04",
		Workdir:   "/workdir",
		SetupCommands: []string{
			"apt update && apt install -y python3",
			"echo 'test' && ls -la",
			"cd /tmp && wget https://example.com/file.tar.gz && tar -xzf file.tar.gz",
		},
	}

	// Save the configuration
	err := originalConfig.Save(tempDir)
	require.NoError(t, err)

	// Read the raw JSON file to check for unicode escaping
	configPath := filepath.Join(tempDir, ".container-use", "environment.json")
	rawData, err := os.ReadFile(configPath)
	require.NoError(t, err)

	rawJSON := string(rawData)

	// Check that && is NOT escaped as \u0026\u0026
	assert.NotContains(t, rawJSON, "\\u0026\\u0026", "Shell operators should not be unicode-escaped in saved JSON")
	assert.Contains(t, rawJSON, "&&", "Shell operators should be preserved as-is")

	// Load the configuration back
	loadedConfig := DefaultConfig()
	err = loadedConfig.Load(tempDir)
	require.NoError(t, err)

	// Verify that the loaded configuration preserves the shell operators
	require.Equal(t, len(originalConfig.SetupCommands), len(loadedConfig.SetupCommands))
	for i, cmd := range originalConfig.SetupCommands {
		assert.Equal(t, cmd, loadedConfig.SetupCommands[i], "Setup command %d should preserve shell operators", i)
		assert.Contains(t, loadedConfig.SetupCommands[i], "&&", "Setup command should contain original && operator")
		assert.NotContains(t, loadedConfig.SetupCommands[i], "\\u0026", "Setup command should not contain unicode-escaped &")
	}
}

// Test helper functions
func createInstructionsFile(t *testing.T, dir, content string) {
	t.Helper()
	configDir := filepath.Join(dir, ".container-use")
	require.NoError(t, os.MkdirAll(configDir, 0755))
	require.NoError(t, os.WriteFile(filepath.Join(configDir, "AGENT.md"), []byte(content), 0644))
}

func createConfigFile(t *testing.T, dir string, config *EnvironmentConfig) {
	t.Helper()
	configDir := filepath.Join(dir, ".container-use")
	require.NoError(t, os.MkdirAll(configDir, 0755))

	data, err := json.MarshalIndent(config, "", "  ")
	require.NoError(t, err)
	require.NoError(t, os.WriteFile(filepath.Join(configDir, "environment.json"), data, 0644))
}



================================================
FILE: environment/environment.go
================================================
package environment

import (
	"context"
	"errors"
	"fmt"
	"log/slog"
	"strings"
	"sync"
	"time"

	"dagger.io/dagger"
)

// EnvironmentInfo contains basic metadata about an environment
// without requiring dagger operations
type EnvironmentInfo struct {
	State *State `json:"state,omitempty"`

	ID string `json:"id,omitempty"`
}

type Environment struct {
	*EnvironmentInfo

	dag *dagger.Client

	Services []*Service
	Notes    Notes

	mu sync.RWMutex
}

// NewEnvArgs contains the arguments for creating a new environment
type NewEnvArgs struct {
	Dag              *dagger.Client
	ID               string
	Title            string
	Config           *EnvironmentConfig
	InitialSourceDir *dagger.Directory
	SubmodulePaths   []string
}

func New(ctx context.Context, args NewEnvArgs) (*Environment, error) {
	env := &Environment{
		EnvironmentInfo: &EnvironmentInfo{
			ID: args.ID,
			State: &State{
				Config:         args.Config,
				Title:          args.Title,
				CreatedAt:      time.Now(),
				UpdatedAt:      time.Now(),
				SubmodulePaths: args.SubmodulePaths,
			},
		},
		dag: args.Dag,
	}

	container, err := env.buildBase(ctx, args.InitialSourceDir)
	if err != nil {
		return nil, err
	}

	slog.Info("Creating environment", "id", env.ID, "workdir", env.State.Config.Workdir)

	if err := env.apply(ctx, container); err != nil {
		return nil, err
	}

	return env, nil
}

func (env *Environment) Workdir() *dagger.Directory {
	return env.container().Directory(env.State.Config.Workdir)
}

// WorkdirFile returns a single file from the workdir
func (env *Environment) WorkdirFile(path string) *dagger.File {
	return env.container().File(path)
}

func (env *Environment) container() *dagger.Container {
	env.mu.RLock()
	defer env.mu.RUnlock()

	return env.dag.LoadContainerFromID(dagger.ContainerID(env.State.Container))
}

func Load(ctx context.Context, dag *dagger.Client, id string, state []byte, worktree string) (*Environment, error) {
	envInfo, err := LoadInfo(ctx, id, state, worktree)
	if err != nil {
		return nil, err
	}
	env := &Environment{
		EnvironmentInfo: envInfo,
		dag:             dag,
		// Services: ?
	}

	return env, nil
}

// LoadInfo loads basic environment metadata without requiring dagger operations.
// This is useful for operations that only need access to configuration and state
// information without the overhead of initializing container operations.
func LoadInfo(ctx context.Context, id string, state []byte, worktree string) (*EnvironmentInfo, error) {
	envInfo := &EnvironmentInfo{
		ID:    id,
		State: &State{},
	}

	if err := envInfo.State.Unmarshal(state); err != nil {
		return nil, err
	}

	// Backward compatibility: if there's no config in the state, load it from the worktree
	if envInfo.State.Config == nil {
		config := DefaultConfig()
		if err := config.Load(worktree); err != nil {
			return nil, err
		}
		envInfo.State.Config = config
	}

	return envInfo, nil
}

func (env *Environment) apply(ctx context.Context, newState *dagger.Container) error {
	// TODO(braa): is this sync redundant with newState.ID?
	if _, err := newState.Sync(ctx); err != nil {
		return err
	}

	containerID, err := newState.ID(ctx)
	if err != nil {
		return err
	}

	env.mu.Lock()
	defer env.mu.Unlock()
	env.State.UpdatedAt = time.Now()
	env.State.Container = string(containerID)

	return nil
}

func containerWithEnvAndSecrets(dag *dagger.Client, container *dagger.Container, envs, secrets []string) (*dagger.Container, error) {
	for _, env := range envs {
		k, v, found := strings.Cut(env, "=")
		if !found {
			return nil, fmt.Errorf("invalid env variable: %s", env)
		}
		if !found {
			return nil, fmt.Errorf("invalid environment variable: %s", env)
		}
		container = container.WithEnvVariable(k, v, dagger.ContainerWithEnvVariableOpts{
			Expand: true,
		})
	}

	for _, secret := range secrets {
		k, v, found := strings.Cut(secret, "=")
		if !found {
			return nil, fmt.Errorf("invalid secret: %s", secret)
		}
		container = container.WithSecretVariable(k, dag.Secret(v))
	}

	return container, nil
}

func (env *Environment) buildBase(ctx context.Context, baseSourceDir *dagger.Directory) (*dagger.Container, error) {
	container := env.dag.
		Container().
		From(env.State.Config.BaseImage).
		WithWorkdir(env.State.Config.Workdir)

	container, err := containerWithEnvAndSecrets(env.dag, container, env.State.Config.Env, env.State.Config.Secrets)
	if err != nil {
		return nil, err
	}

	runCommands := func(commands []string) error {
		for _, command := range commands {
			var err error

			container = container.WithExec([]string{"sh", "-c", command})

			exitCode, err := container.ExitCode(ctx)
			if err != nil {
				var exitErr *dagger.ExecError
				if errors.As(err, &exitErr) {
					env.Notes.AddCommand(command, exitErr.ExitCode, exitErr.Stdout, exitErr.Stderr)
					return fmt.Errorf("exit code %d.\nstdout: %s\nstderr: %s\n%w", exitErr.ExitCode, exitErr.Stdout, exitErr.Stderr, err)
				}

				return err
			}
			stdout, err := container.Stdout(ctx)
			if err != nil {
				return fmt.Errorf("failed to get stdout: %w", err)
			}

			stderr, err := container.Stderr(ctx)
			if err != nil {
				return fmt.Errorf("failed to get stderr: %w", err)
			}

			env.Notes.AddCommand(command, exitCode, stdout, stderr)
		}

		return nil
	}

	// Run setup commands without the source directory for caching purposes
	if err := runCommands(env.State.Config.SetupCommands); err != nil {
		return nil, fmt.Errorf("setup command failed: %w", err)
	}

	env.Services, err = env.startServices(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to start services: %w", err)
	}
	for _, service := range env.Services {
		container = container.WithServiceBinding(service.Config.Name, service.svc)
	}

	container = container.WithDirectory(".", baseSourceDir)

	// Run the install commands after the source directory is set up
	if err := runCommands(env.State.Config.InstallCommands); err != nil {
		return nil, fmt.Errorf("install command failed: %w", err)
	}

	return container, nil
}

func (env *Environment) UpdateConfig(ctx context.Context, newConfig *EnvironmentConfig) error {
	env.State.Config = newConfig

	// Re-build the base image with the new config
	container, err := env.buildBase(ctx, env.Workdir())
	if err != nil {
		return err
	}

	if err := env.apply(ctx, container); err != nil {
		return err
	}

	return nil
}

func (env *Environment) Run(ctx context.Context, command, shell string, useEntrypoint bool) (string, error) {
	args := []string{}
	if command != "" {
		args = []string{shell, "-c", command}
	}
	newState := env.container().WithExec(args, dagger.ContainerWithExecOpts{
		UseEntrypoint:                 useEntrypoint,
		Expect:                        dagger.ReturnTypeAny, // Don't treat non-zero exit as error
		ExperimentalPrivilegedNesting: true,
	})

	exitCode, err := newState.ExitCode(ctx)
	if err != nil {
		return "", fmt.Errorf("failed to get exit code: %w", err)
	}

	stdout, err := newState.Stdout(ctx)
	if err != nil {
		return "", fmt.Errorf("failed to get stdout: %w", err)
	}

	stderr, err := newState.Stderr(ctx)
	if err != nil {
		return "", fmt.Errorf("failed to get stderr: %w", err)
	}

	// Log the command execution with all details
	env.Notes.AddCommand(command, exitCode, stdout, stderr)

	// Always apply the container state (preserving changes even on non-zero exit)
	if err := env.apply(ctx, newState); err != nil {
		return stdout, fmt.Errorf("failed to apply container state: %w", err)
	}

	// Return combined output (stdout + stderr if there was stderr)
	combinedOutput := stdout
	if stderr != "" {
		if stdout != "" {
			combinedOutput += "\n"
		}
		combinedOutput += "stderr: " + stderr
	}
	return combinedOutput, nil
}

func (env *Environment) RunBackground(ctx context.Context, command, shell string, ports []int, useEntrypoint bool) (EndpointMappings, error) {
	args := []string{}
	if command != "" {
		args = []string{shell, "-c", command}
	}
	displayCommand := command + " &"
	serviceState := env.container()

	// Expose ports
	for _, port := range ports {
		serviceState = serviceState.WithExposedPort(port, dagger.ContainerWithExposedPortOpts{
			Protocol:    dagger.NetworkProtocolTcp,
			Description: fmt.Sprintf("Port %d", port),
		})
	}

	// Start the service
	startCtx, cancel := context.WithTimeout(ctx, serviceStartTimeout)
	defer cancel()
	svc, err := serviceState.AsService(dagger.ContainerAsServiceOpts{
		Args:          args,
		UseEntrypoint: useEntrypoint,
	}).Start(startCtx)
	if err != nil {
		var exitErr *dagger.ExecError
		if errors.As(err, &exitErr) {
			env.Notes.AddCommand(displayCommand, exitErr.ExitCode, exitErr.Stdout, exitErr.Stderr)
			return nil, fmt.Errorf("command failed with exit code %d.\nstdout: %s\nstderr: %s", exitErr.ExitCode, exitErr.Stdout, exitErr.Stderr)
		}
		if errors.Is(err, context.DeadlineExceeded) {
			err = fmt.Errorf("service failed to start within %s timeout", serviceStartTimeout)
			env.Notes.AddCommand(displayCommand, 137, "", err.Error())
			return nil, err
		}
		return nil, err
	}

	env.Notes.AddCommand(displayCommand, 0, "", "")

	endpoints := EndpointMappings{}
	for _, port := range ports {
		endpoint := &EndpointMapping{}
		endpoints[port] = endpoint

		// Expose port on the host
		tunnel, err := env.dag.Host().Tunnel(svc, dagger.HostTunnelOpts{
			Ports: []dagger.PortForward{
				{
					Backend:  port,
					Protocol: dagger.NetworkProtocolTcp,
				},
			},
		}).Start(ctx)
		if err != nil {
			return nil, err
		}

		externalEndpoint, err := tunnel.Endpoint(ctx, dagger.ServiceEndpointOpts{
			Scheme: "tcp",
		})
		if err != nil {
			return nil, err
		}
		endpoint.HostExternal = externalEndpoint

		internalEndpoint, err := svc.Endpoint(ctx, dagger.ServiceEndpointOpts{
			Port:   port,
			Scheme: "tcp",
		})
		if err != nil {
			return nil, err
		}
		endpoint.EnvironmentInternal = internalEndpoint
	}

	return endpoints, nil
}

func (env *Environment) Terminal(ctx context.Context) error {
	container := env.container()
	var cmd []string
	var sourceRC string
	if shells, err := container.File("/etc/shells").Contents(ctx); err == nil {
		for shell := range strings.Lines(shells) {
			if shell[0] == '#' {
				continue
			}
			shell = strings.TrimRight(shell, "\n")
			if strings.HasSuffix(shell, "/bash") {
				sourceRC = fmt.Sprintf("[ -f ~/.bashrc ] && . ~/.bashrc; %q --version | head -4; ", shell)
				cmd = []string{shell, "--rcfile", "/cu/rc.sh", "-i"}
				break
			}
		}
	}
	// Try to show the same pretty PS1 as for the default /bin/sh terminal in dagger
	container = container.WithNewFile("/cu/rc.sh", sourceRC+`export PS1="\033[33mcu\033[0m \033[02m\$(pwd | sed \"s|^\$HOME|~|\")\033[0m \$ "`+"\n")
	if cmd == nil {
		// If bash not available, assume POSIX shell
		container = container.WithEnvVariable("ENV", "/cu/rc.sh")
		cmd = []string{"sh"}
	}
	if _, err := container.Terminal(dagger.ContainerTerminalOpts{
		ExperimentalPrivilegedNesting: true,
		Cmd:                           cmd,
	}).Sync(ctx); err != nil {
		return err
	}
	return nil
}

func (env *Environment) Checkpoint(ctx context.Context, target string) (string, error) {
	return env.container().Publish(ctx, target)
}



================================================
FILE: environment/filesystem.go
================================================
package environment

import (
	"context"
	"crypto/sha256"
	"fmt"
	"path/filepath"
	"strings"

	godiffpatch "github.com/sourcegraph/go-diff-patch"
)

func (env *Environment) FileRead(ctx context.Context, targetFile string, shouldReadEntireFile bool, startLineOneIndexedInclusive int, endLineOneIndexedInclusive int) (string, error) {
	file, err := env.container().File(targetFile).Contents(ctx)
	if err != nil {
		return "", err
	}
	if shouldReadEntireFile {
		return file, err
	}

	lines := strings.Split(file, "\n")
	start := startLineOneIndexedInclusive - 1
	start = max(start, 0)
	if start >= len(lines) {
		start = len(lines) - 1
	}
	if start < 0 {
		return "", fmt.Errorf("error reading file: start_line_one_indexed_inclusive (%d) cannot be less than 1", startLineOneIndexedInclusive)
	}
	end := endLineOneIndexedInclusive

	if end >= len(lines) {
		end = len(lines) - 1
	}
	if end < start {
		return "", fmt.Errorf("error reading file: end_line_one_indexed_inclusive (%d) must be greater than start_line_one_indexed_inclusive (%d)", endLineOneIndexedInclusive, startLineOneIndexedInclusive)
	}

	return strings.Join(lines[start:end], "\n"), nil
}

func (env *Environment) FileWrite(ctx context.Context, explanation, targetFile, contents string) error {
	// Check if the file is within a submodule
	if err := env.validateNotSubmoduleFile(targetFile); err != nil {
		return err
	}

	err := env.apply(ctx, env.container().WithNewFile(targetFile, contents))
	if err != nil {
		return fmt.Errorf("failed applying file write, skipping git propagation: %w", err)
	}
	env.Notes.Add("Write %s", targetFile)
	return nil
}

func (env *Environment) FileEdit(ctx context.Context, explanation, targetFile, search, replace, matchID string) error {
	// Check if the file is within a submodule
	if err := env.validateNotSubmoduleFile(targetFile); err != nil {
		return err
	}

	contents, err := env.container().File(targetFile).Contents(ctx)
	if err != nil {
		return err
	}

	// Find all matches of the search text
	matches := []int{}
	cursor := 0
	for {
		index := strings.Index(contents[cursor:], search)
		if index == -1 {
			break
		}
		actualIndex := cursor + index
		matches = append(matches, actualIndex)
		cursor = actualIndex + 1
	}

	if len(matches) == 0 {
		return fmt.Errorf("search text not found in file %s", targetFile)
	}

	// If there are multiple matches and no matchID is provided, return an error with all matches
	if len(matches) > 1 && matchID == "" {
		var matchDescriptions []string
		for i, matchIndex := range matches {
			// Generate a unique ID for each match
			id := generateMatchID(targetFile, search, replace, i)

			// Get context around the match (3 lines before and after)
			context := getMatchContext(contents, matchIndex)

			matchDescriptions = append(matchDescriptions, fmt.Sprintf("Match %d (ID: %s):\n%s", i+1, id, context))
		}

		return fmt.Errorf("multiple matches found for search text in %s. Please specify which_match parameter with one of the following IDs:\n\n%s",
			targetFile, strings.Join(matchDescriptions, "\n\n"))
	}

	// Determine which match to replace
	var targetMatchIndex int
	if len(matches) == 1 {
		targetMatchIndex = matches[0]
	} else {
		// Find the match with the specified ID
		found := false
		for i, matchIndex := range matches {
			id := generateMatchID(targetFile, search, replace, i)
			if id == matchID {
				targetMatchIndex = matchIndex
				found = true
				break
			}
		}
		if !found {
			return fmt.Errorf("match ID %s not found", matchID)
		}
	}

	// Replace the specific match
	newContents := contents[:targetMatchIndex] + replace + contents[targetMatchIndex+len(search):]

	// Apply the changes using `Directory.withPatch` so we don't have to spit out
	// the entire contents
	patch := godiffpatch.GeneratePatch(targetFile, contents, newContents)
	ctr := env.container()
	err = env.apply(ctx, ctr.WithDirectory(".", ctr.Directory(".").WithPatch(patch)))
	if err != nil {
		return fmt.Errorf("failed applying file edit, skipping git propagation: %w", err)
	}
	env.Notes.Add("Edit %s", targetFile)
	return nil
}

func (env *Environment) FileDelete(ctx context.Context, explanation, targetFile string) error {
	// Check if the file is within a submodule
	if err := env.validateNotSubmoduleFile(targetFile); err != nil {
		return err
	}

	err := env.apply(ctx, env.container().WithoutFile(targetFile))
	if err != nil {
		return fmt.Errorf("failed applying file delete, skipping git propagation: %w", err)
	}
	env.Notes.Add("Delete %s", targetFile)
	return nil
}

func (env *Environment) FileList(ctx context.Context, path string) (string, error) {
	entries, err := env.container().Directory(path).Entries(ctx)
	if err != nil {
		return "", err
	}
	out := &strings.Builder{}
	for _, entry := range entries {
		fmt.Fprintf(out, "%s\n", entry)
	}
	return out.String(), nil
}

// generateMatchID creates a unique ID for a match based on file, search, replace, and index
func generateMatchID(targetFile, search, replace string, index int) string {
	data := fmt.Sprintf("%s:%s:%s:%d", targetFile, search, replace, index)
	hash := sha256.Sum256([]byte(data))
	return fmt.Sprintf("%x", hash)[:8] // Use first 8 characters of hash
}

// getMatchContext returns the context around a match (3 lines before and after)
func getMatchContext(contents string, matchIndex int) string {
	lines := strings.Split(contents, "\n")

	// Find which line contains the match
	currentPos := 0
	matchLine := 0
	for i, line := range lines {
		if currentPos+len(line) >= matchIndex {
			matchLine = i
			break
		}
		currentPos += len(line) + 1 // +1 for newline
	}

	// Get context lines (3 before, match line, 3 after)
	start := max(0, matchLine-3)
	end := min(len(lines), matchLine+4)

	contextLines := make([]string, 0, end-start)
	for i := start; i < end; i++ {
		prefix := "  "
		if i == matchLine {
			prefix = "> " // Mark the line containing the match
		}
		// Include line numbers, which may help the model determine the right match
		prefix += fmt.Sprintf("%4d | ", i+1)
		contextLines = append(contextLines, fmt.Sprintf("%s%s", prefix, lines[i]))
	}

	return strings.Join(contextLines, "\n")
}

// isWithinSubmodule checks if a file path is within any of the submodule directories
func (env *Environment) isWithinSubmodule(filePath string, submodulePaths []string) bool {
	// Convert absolute paths to relative paths within workdir
	workdir := env.State.Config.Workdir
	if filepath.IsAbs(filePath) {
		var err error
		filePath, err = filepath.Rel(workdir, filePath)
		if err != nil || strings.HasPrefix(filePath, "..") {
			// If the file is outside workdir, it's not in a submodule
			return false
		}
	}

	cleanFilePath := filepath.Clean(filePath)

	for _, submodulePath := range submodulePaths {
		cleanSubmodulePath := filepath.Clean(submodulePath)

		// Check if the file is exactly the submodule path or within it
		if cleanFilePath == cleanSubmodulePath {
			return true
		}

		// Check if the file is within the submodule directory
		if strings.HasPrefix(cleanFilePath, cleanSubmodulePath+string(filepath.Separator)) {
			return true
		}
	}
	return false
}

// validateNotSubmoduleFile checks if a file path is within a submodule and returns an error if it is
func (env *Environment) validateNotSubmoduleFile(filePath string) error {
	// Use cached submodule paths from state (detected once during creation)
	submodulePaths := env.State.SubmodulePaths

	if env.isWithinSubmodule(filePath, submodulePaths) {
		return fmt.Errorf("cannot modify file '%s': it is within a git submodule. Submodule files are read-only to prevent accidental changes", filePath)
	}

	return nil
}



================================================
FILE: environment/note.go
================================================
package environment

import (
	"fmt"
	"strings"
	"sync"
)

type Notes struct {
	items []string
	mu    sync.Mutex
}

func (n *Notes) Add(format string, a ...any) {
	n.mu.Lock()
	defer n.mu.Unlock()

	n.items = append(n.items, fmt.Sprintf(format, a...))
}

func (n *Notes) AddCommand(command string, exitCode int, stdout, stderr string) {
	msg := fmt.Sprintf("$ %s", strings.TrimSpace(command))
	if exitCode != 0 {
		msg += fmt.Sprintf("\nexit %d", exitCode)
	}
	if strings.TrimSpace(stdout) != "" {
		msg += fmt.Sprintf("\n%s", stdout)
	}
	if strings.TrimSpace(stderr) != "" {
		msg += fmt.Sprintf("\nstderr: %s", stderr)
	}

	n.Add("%s", msg)
}

func (n *Notes) Clear() {
	n.mu.Lock()
	defer n.mu.Unlock()

	n.items = []string{}
}

func (n *Notes) String() string {
	n.mu.Lock()
	defer n.mu.Unlock()

	return strings.TrimSpace(strings.Join(n.items, "\n"))
}

func (n *Notes) Pop() string {
	n.mu.Lock()
	defer n.mu.Unlock()

	out := strings.TrimSpace(strings.Join(n.items, "\n"))
	n.items = []string{}

	return out
}



================================================
FILE: environment/service.go
================================================
package environment

import (
	"context"
	"errors"
	"fmt"
	"time"

	"dagger.io/dagger"
)

var (
	serviceStartTimeout = 30 * time.Second
)

type Service struct {
	Config    *ServiceConfig   `json:"config"`
	Endpoints EndpointMappings `json:"endpoints"`

	svc *dagger.Service
}

type EndpointMapping struct {
	EnvironmentInternal string `json:"environment_internal"`
	HostExternal        string `json:"host_external"`
}

type EndpointMappings map[int]*EndpointMapping

func (env *Environment) startServices(ctx context.Context) ([]*Service, error) {
	services := []*Service{}
	for _, cfg := range env.State.Config.Services {
		service, err := env.startService(ctx, cfg)
		if err != nil {
			return nil, err
		}
		services = append(services, service)
	}
	return services, nil
}

func (env *Environment) startService(ctx context.Context, cfg *ServiceConfig) (*Service, error) {
	container := env.dag.Container().From(cfg.Image)
	container, err := containerWithEnvAndSecrets(env.dag, container, cfg.Env, env.State.Config.Secrets)
	if err != nil {
		return nil, err
	}

	if cfg.Command != "" {
		container = container.WithExec([]string{"sh", "-c", cfg.Command})
	}

	args := []string{}
	if cfg.Command != "" {
		args = []string{"sh", "-c", cfg.Command}
	}

	// Expose ports
	for _, port := range cfg.ExposedPorts {
		container = container.WithExposedPort(port, dagger.ContainerWithExposedPortOpts{
			Protocol:    dagger.NetworkProtocolTcp,
			Description: fmt.Sprintf("Port %d", port),
		})
	}

	// Start the service
	startCtx, cancel := context.WithTimeout(ctx, serviceStartTimeout)
	defer cancel()
	svc, err := container.AsService(dagger.ContainerAsServiceOpts{
		Args:          args,
		UseEntrypoint: true,
	}).Start(startCtx)
	if err != nil {
		var exitErr *dagger.ExecError
		if errors.As(err, &exitErr) {
			return nil, fmt.Errorf("command failed with exit code %d.\nstdout: %s\nstderr: %s", exitErr.ExitCode, exitErr.Stdout, exitErr.Stderr)
		}
		if errors.Is(err, context.DeadlineExceeded) {
			return nil, fmt.Errorf("service failed to start within %s timeout", serviceStartTimeout)
		}
		return nil, err
	}

	endpoints := EndpointMappings{}
	for _, port := range cfg.ExposedPorts {
		endpoint := &EndpointMapping{
			EnvironmentInternal: fmt.Sprintf("tcp://%s:%d", cfg.Name, port),
		}
		endpoints[port] = endpoint

		// Expose ports on the host
		tunnel, err := env.dag.Host().Tunnel(svc, dagger.HostTunnelOpts{
			Ports: []dagger.PortForward{
				{
					Backend:  port,
					Frontend: 0,
					Protocol: dagger.NetworkProtocolTcp,
				},
			},
		}).Start(ctx)
		if err != nil {
			return nil, err
		}

		externalEndpoint, err := tunnel.Endpoint(ctx, dagger.ServiceEndpointOpts{
			Scheme: "tcp",
		})
		if err != nil {
			return nil, fmt.Errorf("failed to get endpoint for service %s: %w", cfg.Name, err)
		}
		endpoint.HostExternal = externalEndpoint
	}

	return &Service{
		Config:    cfg,
		Endpoints: endpoints,
		svc:       svc,
	}, nil
}

func (env *Environment) AddService(ctx context.Context, explanation string, cfg *ServiceConfig) (*Service, error) {
	if env.State.Config.Services.Get(cfg.Name) != nil {
		return nil, fmt.Errorf("service %s already exists", cfg.Name)
	}
	svc, err := env.startService(ctx, cfg)
	if err != nil {
		return nil, err
	}
	env.State.Config.Services = append(env.State.Config.Services, cfg)
	env.Services = append(env.Services, svc)

	state := env.container().WithServiceBinding(cfg.Name, svc.svc)
	if err := env.apply(ctx, state); err != nil {
		return nil, err
	}

	env.Notes.Add("Add service %s\n%s\n\n", cfg.Name, explanation)

	return svc, nil
}



================================================
FILE: environment/state.go
================================================
package environment

import (
	"encoding/json"
	"fmt"
	"time"
)

type State struct {
	CreatedAt time.Time `json:"created_at,omitempty"`
	UpdatedAt time.Time `json:"updated_at,omitempty"`

	Config         *EnvironmentConfig `json:"config,omitempty"`
	Container      string             `json:"container,omitempty"`
	Title          string             `json:"title,omitempty"`
	SubmodulePaths []string           `json:"submodule_paths,omitempty"`
}

func (s *State) Marshal() ([]byte, error) {
	return json.MarshalIndent(s, "", "  ")
}

func (s *State) Unmarshal(data []byte) error {
	if err := json.Unmarshal(data, &s); err != nil {
		// Try to migrate the legacy state
		legacySt, err := migrateLegacyState(data)
		if err != nil {
			return fmt.Errorf("failed to load state: %w", err)
		}
		*s = *legacySt
	}
	return nil
}

func migrateLegacyState(state []byte) (*State, error) {
	var history legacyState
	if err := json.Unmarshal(state, &history); err != nil {
		return nil, fmt.Errorf("failed to load state: %w", err)
	}
	latest := history.Latest()
	if latest == nil {
		return nil, fmt.Errorf("no latest revision found")
	}

	return &State{
		Container: latest.State,
		CreatedAt: latest.CreatedAt,
		UpdatedAt: latest.CreatedAt,
	}, nil
}

type legacyState []*legacyRevision

func (h legacyState) Latest() *legacyRevision {
	if len(h) == 0 {
		return nil
	}
	return h[len(h)-1]
}

func (h legacyState) LatestVersion() int {
	latest := h.Latest()
	if latest == nil {
		return 0
	}
	return latest.Version
}

func (h legacyState) Get(version int) *legacyRevision {
	for _, revision := range h {
		if revision.Version == version {
			return revision
		}
	}
	return nil
}

type legacyRevision struct {
	Version     int       `json:"version"`
	Name        string    `json:"name"`
	Explanation string    `json:"explanation"`
	Output      string    `json:"output,omitempty"`
	CreatedAt   time.Time `json:"created_at"`
	State       string    `json:"state"`
}



================================================
FILE: environment/integration/environment_selection_test.go
================================================
package integration

import (
	"context"
	"strings"
	"testing"

	"github.com/dagger/container-use/repository"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestEnvironmentSelection tests the environment selection logic
func TestEnvironmentSelection(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	t.Run("SingleDescendantEnvironment", func(t *testing.T) {
		WithRepository(t, "single-descendant", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Get current HEAD
			currentHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			currentHead = strings.TrimSpace(currentHead)

			// Create an environment (this creates a branch from current HEAD and adds commits)
			env := user.CreateEnvironment("Test Environment", "Testing single descendant environment")

			// List descendant environments
			descendantEnvs, err := repo.ListDescendantEnvironments(ctx, currentHead)
			require.NoError(t, err)
			assert.Len(t, descendantEnvs, 1)
			assert.Equal(t, env.ID, descendantEnvs[0].ID)
			assert.Equal(t, "Test Environment", descendantEnvs[0].State.Title)
		})
	})

	t.Run("MultipleDescendantEnvironments", func(t *testing.T) {
		WithRepository(t, "multiple-descendants", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Get current HEAD
			currentHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			currentHead = strings.TrimSpace(currentHead)

			// Create multiple environments
			env1 := user.CreateEnvironment("First Environment", "Testing multiple descendants")
			env2 := user.CreateEnvironment("Second Environment", "Testing multiple descendants")

			// List descendant environments
			descendantEnvs, err := repo.ListDescendantEnvironments(ctx, currentHead)
			require.NoError(t, err)
			assert.Len(t, descendantEnvs, 2)

			// Check that both environments are present (they're sorted by update time)
			envIDs := []string{descendantEnvs[0].ID, descendantEnvs[1].ID}
			assert.Contains(t, envIDs, env1.ID)
			assert.Contains(t, envIDs, env2.ID)
		})
	})

	t.Run("NoDescendantEnvironments", func(t *testing.T) {
		WithRepository(t, "no-descendants", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Create an environment first
			env := user.CreateEnvironment("Test Environment", "Testing no descendants")

			// Make a divergent commit on the main branch
			user.GitCommand("commit", "--allow-empty", "-m", "Divergent commit")

			// Get the new HEAD
			newHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			newHead = strings.TrimSpace(newHead)

			// List descendant environments from the new HEAD
			descendantEnvs, err := repo.ListDescendantEnvironments(ctx, newHead)
			require.NoError(t, err)
			assert.Len(t, descendantEnvs, 0)

			// Verify that the environment still exists but is not a descendant
			allEnvs, err := repo.List(ctx)
			require.NoError(t, err)
			assert.Len(t, allEnvs, 1)
			assert.Equal(t, env.ID, allEnvs[0].ID)
		})
	})

	t.Run("EnvironmentsSortedByUpdateTime", func(t *testing.T) {
		WithRepository(t, "sorted-envs", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Get current HEAD
			currentHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			currentHead = strings.TrimSpace(currentHead)

			// Create environments with some time between them
			env1 := user.CreateEnvironment("First Environment", "Creating first environment")
			env2 := user.CreateEnvironment("Second Environment", "Creating second environment")

			// Update the first environment to make it more recent
			user.FileWrite(env1.ID, "update.txt", "Updated content", "Update first environment")

			// List descendant environments
			descendantEnvs, err := repo.ListDescendantEnvironments(ctx, currentHead)
			require.NoError(t, err)
			assert.Len(t, descendantEnvs, 2)

			// First environment should be first (most recently updated)
			assert.Equal(t, env1.ID, descendantEnvs[0].ID)
			assert.Equal(t, env2.ID, descendantEnvs[1].ID)
		})
	})

	t.Run("MixedEnvironmentAncestry", func(t *testing.T) {
		WithRepository(t, "mixed-ancestry", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Get initial HEAD
			initialHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			initialHead = strings.TrimSpace(initialHead)

			// Create first environment from initial HEAD
			user.CreateEnvironment("Environment 1", "Created from initial HEAD")

			// Make a commit on main
			user.GitCommand("commit", "--allow-empty", "-m", "New commit on main")

			// Get new HEAD
			newHead, err := repository.RunGitCommand(ctx, repo.SourcePath(), "rev-parse", "HEAD")
			require.NoError(t, err)
			newHead = strings.TrimSpace(newHead)

			// Create second environment from new HEAD
			env2 := user.CreateEnvironment("Environment 2", "Created from new HEAD")

			// List descendants from initial HEAD - should include both environments
			descendantsFromInitial, err := repo.ListDescendantEnvironments(ctx, initialHead)
			require.NoError(t, err)
			assert.Len(t, descendantsFromInitial, 2) // Both environments are descendants of initial HEAD

			// List descendants from new HEAD - should only include env2
			descendantsFromNew, err := repo.ListDescendantEnvironments(ctx, newHead)
			require.NoError(t, err)
			assert.Len(t, descendantsFromNew, 1)
			assert.Equal(t, env2.ID, descendantsFromNew[0].ID)
		})
	})
}



================================================
FILE: environment/integration/helpers.go
================================================
package integration

import (
	"context"
	"log/slog"
	"os"
	"path/filepath"
	"sync"
	"testing"

	"dagger.io/dagger"
	"github.com/dagger/container-use/environment"
	"github.com/dagger/container-use/repository"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

var (
	testDaggerClient *dagger.Client
	daggerOnce       sync.Once
	daggerErr        error
)

// init sets up logging for tests
func init() {
	// Only show warnings and errors in tests unless TEST_VERBOSE is set
	level := slog.LevelWarn
	if os.Getenv("TEST_VERBOSE") != "" {
		level = slog.LevelInfo
	}

	slog.SetDefault(slog.New(slog.NewTextHandler(os.Stderr, &slog.HandlerOptions{
		Level: level,
	})))
}

// WithRepository runs a test function with an isolated repository and UserActions
func WithRepository(t *testing.T, name string, setup RepositorySetup, fn func(t *testing.T, repo *repository.Repository, user *UserActions)) {
	// Initialize Dagger (needed for environment operations)
	initializeDaggerOnce(t)

	ctx := context.Background()

	// Create isolated temp directories
	repoDir, err := os.MkdirTemp("", "cu-test-"+name+"-*")
	require.NoError(t, err, "Failed to create repo dir")

	configDir, err := os.MkdirTemp("", "cu-test-config-"+name+"-*")
	require.NoError(t, err, "Failed to create config dir")

	// Initialize git repo
	cmds := [][]string{
		{"init", "--initial-branch=main"},
		{"config", "user.email", "test@example.com"},
		{"config", "user.name", "Test User"},
		{"config", "commit.gpgsign", "false"},
	}

	for _, cmd := range cmds {
		_, err := repository.RunGitCommand(ctx, repoDir, cmd...)
		require.NoError(t, err, "Failed to run git %v", cmd)
	}

	// Run setup to populate repo
	if setup != nil {
		setup(t, repoDir)
	}

	// Open repository with isolated base path
	repo, err := repository.OpenWithBasePath(ctx, repoDir, configDir)
	require.NoError(t, err, "Failed to open repository")

	// Create UserActions with extended capabilities
	user := NewUserActions(t, repo, testDaggerClient).WithDirectAccess(repoDir, configDir)

	// Cleanup
	t.Cleanup(func() {
		// Clean up any environments created during the test
		envs, _ := repo.List(context.Background())
		for _, env := range envs {
			repo.Delete(context.Background(), env.ID)
		}

		// Remove directories
		os.RemoveAll(repoDir)
		os.RemoveAll(configDir)
	})

	// Run the test function
	fn(t, repo, user)
}

// RepositorySetup is a function that prepares a test repository
type RepositorySetup func(t *testing.T, repoDir string)

// Common repository setups
var (
	SetupPythonRepo = func(t *testing.T, repoDir string) {
		writeFile(t, repoDir, "main.py", "def main():\n    print('Hello World')\n\nif __name__ == '__main__':\n    main()\n")
		writeFile(t, repoDir, "requirements.txt", "requests==2.31.0\nnumpy==1.24.0\n")
		writeFile(t, repoDir, ".gitignore", "__pycache__/\n*.pyc\n.env\nvenv/\n")
		gitCommit(t, repoDir, "Initial Python project")
	}

	SetupPythonRepoNoGitignore = func(t *testing.T, repoDir string) {
		writeFile(t, repoDir, "main.py", "def main():\n    print('Hello World')\n\nif __name__ == '__main__':\n    main()\n")
		writeFile(t, repoDir, "requirements.txt", "requests==2.31.0\nnumpy==1.24.0\n")
		gitCommit(t, repoDir, "Initial Python project")
	}

	SetupNodeRepo = func(t *testing.T, repoDir string) {
		packageJSON := `{
  "name": "test-project",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "start": "node index.js",
    "test": "jest"
  },
  "dependencies": {
    "express": "^4.18.0"
  }
}`
		writeFile(t, repoDir, "package.json", packageJSON)
		writeFile(t, repoDir, "index.js", "console.log('Hello from Node.js');\n")
		writeFile(t, repoDir, ".gitignore", "node_modules/\n.env\n")
		gitCommit(t, repoDir, "Initial Node project")
	}

	SetupEmptyRepo = func(t *testing.T, repoDir string) {
		writeFile(t, repoDir, "README.md", "# Test Project\n")
		gitCommit(t, repoDir, "Initial commit")
	}
)

// Helper functions for repository setup
func writeFile(t *testing.T, repoDir, path, content string) {
	fullPath := filepath.Join(repoDir, path)
	dir := filepath.Dir(fullPath)
	err := os.MkdirAll(dir, 0755)
	require.NoError(t, err, "Failed to create dir")
	err = os.WriteFile(fullPath, []byte(content), 0600)
	require.NoError(t, err, "Failed to write file")
}

func gitCommit(t *testing.T, repoDir, message string) {
	ctx := context.Background()
	_, err := repository.RunGitCommand(ctx, repoDir, "add", ".")
	require.NoError(t, err, "Failed to stage files")
	_, err = repository.RunGitCommand(ctx, repoDir, "commit", "-m", message)
	require.NoError(t, err, "Failed to commit")
}

// initializeDaggerOnce initializes Dagger client once for all tests
func initializeDaggerOnce(t *testing.T) {
	daggerOnce.Do(func() {
		if testDaggerClient != nil {
			return
		}

		ctx := context.Background()
		client, err := dagger.Connect(ctx)
		if err != nil {
			daggerErr = err
			return
		}

		testDaggerClient = client
	})

	if daggerErr != nil {
		t.Skipf("Skipping test - Dagger not available: %v", daggerErr)
	}
}

// UserActions provides test helpers that mirror MCP tool behavior exactly
// These represent what a user would experience when using the MCP tools
type UserActions struct {
	t         *testing.T
	ctx       context.Context
	repo      *repository.Repository
	dag       *dagger.Client
	repoDir   string // Source directory (for direct manipulation)
	configDir string // Container-use config directory
}

func NewUserActions(t *testing.T, repo *repository.Repository, dag *dagger.Client) *UserActions {
	return &UserActions{
		t:    t,
		ctx:  context.Background(),
		repo: repo,
		dag:  dag,
	}
}

// WithDirectAccess adds direct filesystem access for edge case testing
func (u *UserActions) WithDirectAccess(repoDir, configDir string) *UserActions {
	u.repoDir = repoDir
	u.configDir = configDir
	return u
}

// FileWrite mirrors environment_file_write MCP tool behavior
func (u *UserActions) FileWrite(envID, targetFile, contents, explanation string) {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	err = env.FileWrite(u.ctx, explanation, targetFile, contents)
	require.NoError(u.t, err, "FileWrite should succeed")

	err = u.repo.Update(u.ctx, env, explanation)
	require.NoError(u.t, err, "repo.Update after FileWrite should succeed")
}

// RunCommand mirrors environment_run_cmd MCP tool behavior
func (u *UserActions) RunCommand(envID, command, explanation string) string {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	output, err := env.Run(u.ctx, command, "/bin/sh", false)
	require.NoError(u.t, err, "Run command should succeed")

	err = u.repo.Update(u.ctx, env, explanation)
	require.NoError(u.t, err, "repo.Update after Run should succeed")

	return output
}

// CreateEnvironment mirrors environment_create MCP tool behavior
func (u *UserActions) CreateEnvironment(title, explanation string) *environment.Environment {
	env, err := u.repo.Create(u.ctx, u.dag, title, explanation, "HEAD")
	require.NoError(u.t, err, "Create environment should succeed")
	return env
}

// UpdateEnvironment mirrors environment_update MCP tool behavior
func (u *UserActions) UpdateEnvironment(envID, title, explanation string, config *environment.EnvironmentConfig) {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	if title != "" {
		env.State.Title = title
	}

	err = env.UpdateConfig(u.ctx, config)
	require.NoError(u.t, err, "UpdateConfig should succeed")

	err = u.repo.Update(u.ctx, env, explanation)
	require.NoError(u.t, err, "repo.Update after UpdateConfig should succeed")
}

// FileDelete mirrors environment_file_delete MCP tool behavior
func (u *UserActions) FileDelete(envID, targetFile, explanation string) {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	err = env.FileDelete(u.ctx, explanation, targetFile)
	require.NoError(u.t, err, "FileDelete should succeed")

	err = u.repo.Update(u.ctx, env, explanation)
	require.NoError(u.t, err, "repo.Update after FileDelete should succeed")
}

// FileRead mirrors environment_file_read MCP tool behavior (read-only, no update)
func (u *UserActions) FileRead(envID, targetFile string) string {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	content, err := env.FileRead(u.ctx, targetFile, true, 0, 0)
	require.NoError(u.t, err, "FileRead should succeed")
	return content
}

// FileReadExpectError is for testing expected failures
func (u *UserActions) FileReadExpectError(envID, targetFile string) {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Failed to get environment %s", envID)

	_, err = env.FileRead(u.ctx, targetFile, true, 0, 0)
	assert.Error(u.t, err, "FileRead should fail for %s", targetFile)
}

// GetEnvironment retrieves an environment by ID - mirrors how MCP tools work
// Each MCP tool call starts fresh by getting the environment from the repository
func (u *UserActions) GetEnvironment(envID string) *environment.Environment {
	env, err := u.repo.Get(u.ctx, u.dag, envID)
	require.NoError(u.t, err, "Should be able to get environment %s", envID)
	return env
}

// --- Direct manipulation methods for edge case testing ---

// WriteSourceFile writes directly to the source repository
func (u *UserActions) WriteSourceFile(path, content string) {
	require.NotEmpty(u.t, u.repoDir, "Need direct access for source file manipulation")
	fullPath := filepath.Join(u.repoDir, path)
	dir := filepath.Dir(fullPath)

	err := os.MkdirAll(dir, 0755)
	require.NoError(u.t, err, "Failed to create dir")

	err = os.WriteFile(fullPath, []byte(content), 0600)
	require.NoError(u.t, err, "Failed to write source file")
}

// WorktreePath returns the worktree path for an environment, handling errors
func (u *UserActions) WorktreePath(envID string) string {
	worktreePath, err := u.repo.WorktreePath(envID)
	require.NoError(u.t, err, "Failed to get worktree path for environment %s", envID)
	return worktreePath
}

// ReadWorktreeFile reads directly from an environment's worktree
func (u *UserActions) ReadWorktreeFile(envID, path string) string {
	worktreePath := u.WorktreePath(envID)
	fullPath := filepath.Join(worktreePath, path)
	content, err := os.ReadFile(fullPath)
	require.NoError(u.t, err, "Failed to read worktree file")
	return string(content)
}

// CorruptWorktree simulates worktree corruption for recovery testing
func (u *UserActions) CorruptWorktree(envID string) {
	worktreePath := u.WorktreePath(envID)

	// Remove .git directory to corrupt the worktree
	gitDir := filepath.Join(worktreePath, ".git")
	err := os.RemoveAll(gitDir)
	require.NoError(u.t, err, "Failed to corrupt worktree")
}

// GitCommand runs a git command in the source repository
func (u *UserActions) GitCommand(args ...string) string {
	require.NotEmpty(u.t, u.repoDir, "Need direct access for git commands")
	output, err := repository.RunGitCommand(u.ctx, u.repoDir, args...)
	require.NoError(u.t, err, "Git command failed: %v", args)
	return output
}

// WriteFileInSourceRepo writes a file to the source repo and commits it
func (u *UserActions) WriteFileInSourceRepo(path, content, commitMessage string) {
	require.NotEmpty(u.t, u.repoDir, "Need direct access for source file manipulation")
	writeFile(u.t, u.repoDir, path, content)
	gitCommit(u.t, u.repoDir, commitMessage)
}

// CreateBranchInSourceRepo creates and checks out a new branch in the source repo
func (u *UserActions) CreateBranchInSourceRepo(branchName string) {
	u.GitCommand("checkout", "-b", branchName)
}

// CheckoutBranchInSourceRepo checks out an existing branch in the source repo
func (u *UserActions) CheckoutBranchInSourceRepo(branchName string) {
	u.GitCommand("checkout", branchName)
}



================================================
FILE: environment/integration/integration_test.go
================================================
package integration

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"testing"
	"time"

	"github.com/dagger/container-use/environment"
	"github.com/dagger/container-use/repository"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestGitAuditTrail verifies that all operations are tracked in git
func TestGitAuditTrail(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	mustParseInt64 := func(t *testing.T, s string) int64 {
		n, err := strconv.ParseInt(s, 10, 64)
		require.NoError(t, err)
		return n
	}

	WithRepository(t, "audit", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		env := user.CreateEnvironment("Audit Test", "Testing git tracking")

		// User performs various operations
		user.FileWrite(env.ID, "config.json", `{"name": "test", "version": "1.0.0"}`, "Initial config")
		user.RunCommand(env.ID, "npm install", "Install dependencies")
		user.FileWrite(env.ID, "src/app.js", "console.log('Hello');", "Add app code")

		// Verify all operations are tracked in git
		gitLog, err := repository.RunGitCommand(context.Background(), user.WorktreePath(env.ID), "log", "--oneline", "-5")
		require.NoError(t, err)

		// Operations that create git-trackable changes should have commits
		assert.Contains(t, gitLog, "Initial config")
		// "Run npm install" won't create a commit (npm not installed, would create gitignored files)
		assert.Contains(t, gitLog, "Add app code")

		// Verify file contents are in git
		configFromGit, err := repository.RunGitCommand(context.Background(), user.WorktreePath(env.ID), "show", "HEAD~1:config.json")
		require.NoError(t, err)
		assert.Contains(t, configFromGit, `"version": "1.0.0"`)

		// Verify commit timestamps are reasonable
		gitTime, err := repository.RunGitCommand(context.Background(), user.WorktreePath(env.ID), "log", "-1", "--pretty=format:%ct")
		require.NoError(t, err)
		commitTime := time.Unix(mustParseInt64(t, strings.TrimSpace(gitTime)), 0)
		assert.WithinDuration(t, time.Now(), commitTime, 5*time.Second)
	})
}

// TestEnvironmentIsolation verifies that changes in one environment don't affect others
func TestEnvironmentIsolation(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	WithRepository(t, "isolation", SetupPythonRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		// User creates two environments from the same repository
		dev := user.CreateEnvironment("Development", "Creating dev environment")
		staging := user.CreateEnvironment("Staging", "Creating staging environment")

		// User writes different files in each environment
		user.FileWrite(dev.ID, "config.json", `{"env": "dev", "debug": true}`, "Dev config")
		user.FileWrite(staging.ID, "config.json", `{"env": "staging", "debug": false}`, "Staging config")

		// Verify each environment has its own config
		devConfig := user.FileRead(dev.ID, "config.json")
		assert.Contains(t, devConfig, `"env": "dev"`)
		assert.Contains(t, devConfig, `"debug": true`)

		stagingConfig := user.FileRead(staging.ID, "config.json")
		assert.Contains(t, stagingConfig, `"env": "staging"`)
		assert.Contains(t, stagingConfig, `"debug": false`)

		// Get fresh environments to access Worktree paths for git commands
		dev = user.GetEnvironment(dev.ID)
		staging = user.GetEnvironment(staging.ID)

		// Verify git histories are independent
		devLog, _ := repository.RunGitCommand(context.Background(), user.WorktreePath(dev.ID), "log", "--oneline", "-2")
		stagingLog, _ := repository.RunGitCommand(context.Background(), user.WorktreePath(staging.ID), "log", "--oneline", "-2")

		assert.Contains(t, devLog, "Dev config")
		assert.Contains(t, stagingLog, "Staging config")

		// Verify complete isolation - dev files don't exist in staging
		user.FileReadExpectError(staging.ID, "dev-only.txt")
		user.FileWrite(dev.ID, "dev-only.txt", "Only in dev", "Dev only file")

		// Staging still shouldn't see dev files
		user.FileReadExpectError(staging.ID, "dev-only.txt")
	})
}

// TestSystemHandlesProblematicFiles verifies edge cases don't break the system
func TestSystemHandlesProblematicFiles(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	// Verify Python __pycache__ directories don't interfere with operations
	t.Run("PythonDevelopmentWorkflow", func(t *testing.T) {
		WithRepository(t, "python_cache", SetupPythonRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			env := user.CreateEnvironment("Python Dev", "Testing Python cache handling")

			// Simulate Python cache directories
			output := user.RunCommand(env.ID,
				"mkdir -p __pycache__ && "+
					"echo 'binary content' > __pycache__/main.cpython-311.pyc && "+
					"echo 'binary content' > __pycache__/utils.cpython-311.pyc",
				"Simulate Python cache")
			_ = output

			// Continue development
			user.FileWrite(env.ID, "feature.py", "def new_feature():\n    return True", "Add feature")
			user.FileWrite(env.ID, "main.py", "# Updated\nprint('Hello, Updated World!')", "Update main")

			// Verify __pycache__ doesn't interfere

			// Create more files to ensure continued functionality
			user.RunCommand(env.ID, "touch __pycache__/feature.cpython-311.pyc", "Create more cache")

			// Verify we can still read files
			content := user.FileRead(env.ID, "feature.py")
			assert.Contains(t, content, "new_feature")
		})
	})

	t.Run("BinaryDirectories", func(t *testing.T) {
		WithRepository(t, "binary_dirs", SetupPythonRepoNoGitignore, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			env := user.CreateEnvironment("Test", "Testing binary directory handling")

			// Create directories with only binary files
			_ = user.RunCommand(env.ID,
				"mkdir -p __pycache__ && "+
					"dd if=/dev/urandom of=__pycache__/main.cpython-39.pyc bs=1024 count=1 2>/dev/null && "+
					"dd if=/dev/urandom of=__pycache__/utils.cpython-39.pyc bs=1024 count=1 2>/dev/null",
				"Create binary directory")

			// Should still handle text files
			user.FileWrite(env.ID, "notes.txt", "System should handle binary directories gracefully", "Add text file")

			// Verify the text file was written and can be read
			content := user.FileRead(env.ID, "notes.txt")
			assert.Equal(t, "System should handle binary directories gracefully", content)
		})
	})

	t.Run("LargeFiles", func(t *testing.T) {
		WithRepository(t, "large_files", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			env := user.CreateEnvironment("Large Files", "Testing large file handling")

			// Create a large file
			output := user.RunCommand(env.ID,
				"dd if=/dev/urandom of=large.dat bs=1M count=5 2>/dev/null",
				"Create large file")

			// System should handle large files
			_ = output

			// Should still work with normal files
			user.FileWrite(env.ID, "config.json", `{"maxFileSize": "5MB"}`, "Add config")

			// Verify we can read the config
			content := user.FileRead(env.ID, "config.json")
			assert.Contains(t, content, "maxFileSize")
		})
	})
}

// Large project performance ensures the system scales to real-world codebases
func TestLargeProjectPerformance(t *testing.T) {
	// if we had per-repo forkrepo locking, this would be t.Parallel()
	if testing.Short() {
		t.Skip("Skipping performance test")
	}

	t.Run("large_project_performance", func(t *testing.T) {
		// Create many files for performance testing
		largeProjectSetup := func(t *testing.T, repoDir string) {
			// Create 100 test files
			for i := range 100 {
				writeFile(t, repoDir, filepath.Join("src", fmt.Sprintf("file%d.js", i)),
					fmt.Sprintf("// File %d\nconsole.log('test');", i))
			}
			gitCommit(t, repoDir, "Large project")
		}

		WithRepository(t, "large_project_performance", largeProjectSetup, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			env := user.CreateEnvironment("Performance Test", "Testing performance with large project")

			// Time file operations
			start := time.Now()
			user.FileWrite(env.ID, "new.txt", "test", "Test write performance")
			writeTime := time.Since(start)

			t.Logf("File write took: %v", writeTime)

			assert.LessOrEqual(t, writeTime, 2*time.Second, "File write should be fast")
		})
	})
}

// TestWorktreeUpdatesAreVisibleAfterRebuild verifies file changes persist through rebuilds
func TestWorktreeUpdatesAreVisibleAfterRebuild(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	t.Run("worktree_cache", func(t *testing.T) {
		WithRepository(t, "worktree_cache", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			env := user.CreateEnvironment("Worktree Test", "Testing worktree updates after rebuild")

			initialScript := `echo "Version 1"`
			user.FileWrite(env.ID, "script.sh", initialScript, "Create script")

			// Initial version
			output := user.RunCommand(env.ID, "sh script.sh", "Run initial version")
			assert.Contains(t, output, "Version 1")

			// Update script
			updatedScript := `echo "Version 2"`
			user.FileWrite(env.ID, "script.sh", updatedScript, "Update script")

			// Rebuild environment
			env = user.GetEnvironment(env.ID)

			// Update config to force rebuild
			config := env.State.Config.Copy()
			user.UpdateEnvironment(env.ID, env.State.Title, "Force rebuild", config)

			// Check script after rebuild
			catOutput := user.RunCommand(env.ID, "cat script.sh", "Check script content")
			t.Logf("Script content after rebuild: %s", catOutput)

			// Version 2 should be active
			output = user.RunCommand(env.ID, "sh script.sh", "Run after rebuild")
			assert.Contains(t, output, "Version 2", "Updated version should be used after rebuild")
		})
	})
}

// TestWeirdUserScenarios verifies edge case handling
func TestWeirdUserScenarios(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	t.Run("EnvironmentNameCollisions", func(t *testing.T) {
		WithRepository(t, "name_collisions", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			// Create first environment
			env1 := user.CreateEnvironment("My App", "Creating first app environment")

			// Create second environment with SAME name
			env2 := user.CreateEnvironment("My App", "Creating second app environment")

			// They should have different IDs despite same name
			assert.NotEqual(t, env1.ID, env2.ID, "Same-named environments should get unique IDs")
			// IDs are generated using random pet names, not derived from the environment name
			assert.NotEmpty(t, env1.ID, "ID should not be empty")
			assert.NotEmpty(t, env2.ID, "ID should not be empty")

			// Both should be independently accessible
			ctx := context.Background()
			retrieved1, err := repo.Get(ctx, user.dag, env1.ID)
			assert.NoError(t, err)
			assert.NotNil(t, retrieved1, "First env should be retrievable")

			retrieved2, err := repo.Get(ctx, user.dag, env2.ID)
			assert.NoError(t, err)
			assert.NotNil(t, retrieved2, "Second env should be retrievable")

			// Write different content to verify isolation
			user.FileWrite(env1.ID, "app.txt", "Environment 1", "Write to env1")
			user.FileWrite(env2.ID, "app.txt", "Environment 2", "Write to env2")

			// Verify content
			content1 := user.FileRead(env1.ID, "app.txt")
			content2 := user.FileRead(env2.ID, "app.txt")

			assert.Equal(t, "Environment 1", content1)
			assert.Equal(t, "Environment 2", content2)
		})
	})

	t.Run("OrphanedWorktreeRecovery", func(t *testing.T) {
		WithRepository(t, "orphaned_worktree", SetupPythonRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			newEnv := user.CreateEnvironment("Test", "Creating test environment")

			// Save worktree path for later verification
			envID := newEnv.ID
			worktreePath := user.WorktreePath(newEnv.ID)

			// Simulate corruption by removing the .git directory in the worktree
			user.CorruptWorktree(newEnv.ID)

			// Verify worktree still exists on disk but is corrupted
			_, err := os.Stat(worktreePath)
			assert.NoError(t, err, "Worktree should still exist")

			gitDir := filepath.Join(worktreePath, ".git")
			_, err = os.Stat(gitDir)
			assert.Error(t, err, ".git should be removed")

			// Try to create new environment with same name - should work
			env2 := user.CreateEnvironment("Test", "Creating test environment after orphan")

			// New environment should have different ID and worktree
			assert.NotEqual(t, envID, env2.ID)
			assert.NotEqual(t, worktreePath, user.WorktreePath(env2.ID))

			// New environment should be functional
			user.FileWrite(env2.ID, "test.txt", "New environment works", "Verify new env works")
			content := user.FileRead(env2.ID, "test.txt")
			assert.Equal(t, "New environment works", content)
		})
	})

	t.Run("CrossRepositoryConfusion", func(t *testing.T) {
		initializeDaggerOnce(t)

		// Create two separate repositories
		ctx := context.Background()

		// Create first repository
		repoDir1, err := os.MkdirTemp("", "cu-test-repo1-*")
		require.NoError(t, err)
		defer os.RemoveAll(repoDir1)

		configDir1, err := os.MkdirTemp("", "cu-test-config1-*")
		require.NoError(t, err)
		defer os.RemoveAll(configDir1)

		// Initialize git repo1
		cmds := [][]string{
			{"init"},
			{"config", "user.email", "test@example.com"},
			{"config", "user.name", "Test User"},
			{"config", "commit.gpgsign", "false"},
		}
		for _, cmd := range cmds {
			_, err := repository.RunGitCommand(ctx, repoDir1, cmd...)
			require.NoError(t, err)
		}
		SetupNodeRepo(t, repoDir1)

		// Create second repository
		repoDir2, err := os.MkdirTemp("", "cu-test-repo2-*")
		require.NoError(t, err)
		defer os.RemoveAll(repoDir2)

		configDir2, err := os.MkdirTemp("", "cu-test-config2-*")
		require.NoError(t, err)
		defer os.RemoveAll(configDir2)

		// Initialize git repo2
		for _, cmd := range cmds {
			_, err := repository.RunGitCommand(ctx, repoDir2, cmd...)
			require.NoError(t, err)
		}
		SetupPythonRepo(t, repoDir2)

		// Open repository and create environment in repo1
		repo1, err := repository.OpenWithBasePath(ctx, repoDir1, configDir1)
		require.NoError(t, err)

		env1, err := repo1.Create(ctx, testDaggerClient, "App", "Creating app in repo1", "HEAD")
		require.NoError(t, err)
		defer repo1.Delete(ctx, env1.ID)

		// Write file in env1
		err = env1.FileWrite(ctx, "Add file", "app.js", "console.log('repo1');")
		require.NoError(t, err)

		// Try to use env1 while in repo2 (should fail)
		_, err = env1.FileRead(ctx, "main.py", true, 0, 0)
		assert.Error(t, err, "Should fail to read repo2 files from repo1 environment")

		// The environment is still tied to repo1
		jsContent, err := env1.FileRead(ctx, "app.js", true, 0, 0)
		require.NoError(t, err)
		assert.Contains(t, jsContent, "repo1", "Environment should still access its original repo")
	})
}

// TestEnvironmentConfigurationPersists verifies configuration persistence
func TestEnvironmentConfigurationPersists(t *testing.T) {
	t.Parallel()
	if testing.Short() {
		t.Skip("Skipping integration test")
	}

	t.Run("BaseImagePersists", func(t *testing.T) {
		WithRepository(t, "base_image", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			newEnv := user.CreateEnvironment("Test environment", "Creating Alpine-based test environment")

			// Update to Alpine with git
			updatedConfig := newEnv.State.Config.Copy()
			updatedConfig.BaseImage = "alpine:latest"
			updatedConfig.SetupCommands = []string{"apk add --no-cache git"}

			user.UpdateEnvironment(newEnv.ID, "Test environment", "Use Alpine Linux", updatedConfig)

			// Save and reload config
			newEnv = user.GetEnvironment(newEnv.ID)
			newConfig := newEnv.State.Config.Copy()

			assert.Equal(t, "alpine:latest", newConfig.BaseImage, "Base image should persist")
			assert.Equal(t, []string{"apk add --no-cache git"}, newConfig.SetupCommands, "Setup commands should persist")
		})
	})

	t.Run("SetupCommandsPersist", func(t *testing.T) {
		WithRepository(t, "setup_commands", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			newEnv := user.CreateEnvironment("Test with setup", "Creating environment with setup commands")

			setupCmds := []string{
				"apk add --no-cache curl git",
				"echo 'Setup complete' > /setup.log",
			}
			updatedConfig := newEnv.State.Config.Copy()
			updatedConfig.BaseImage = "alpine:latest"
			updatedConfig.SetupCommands = setupCmds

			user.UpdateEnvironment(newEnv.ID, "Test with setup", "Install development tools", updatedConfig)

			// Reload config
			newEnv = user.GetEnvironment(newEnv.ID)
			newConfig := newEnv.State.Config.Copy()
			assert.Equal(t, setupCmds, newConfig.SetupCommands, "Setup commands should persist")
		})
	})

	t.Run("InstallCommandsPersist", func(t *testing.T) {
		WithRepository(t, "install_commands", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			newEnv := user.CreateEnvironment("Test with install", "Creating environment with install commands")

			installCmds := []string{
				"npm install --save-dev jest",
				"echo 'Dependencies installed' > /install.log",
			}
			updatedConfig := newEnv.State.Config.Copy()
			updatedConfig.BaseImage = "node:18"
			updatedConfig.InstallCommands = installCmds

			user.UpdateEnvironment(newEnv.ID, "Test with install", "Install project dependencies", updatedConfig)

			// Reload config
			newEnv = user.GetEnvironment(newEnv.ID)
			newConfig := newEnv.State.Config.Copy()
			assert.Equal(t, installCmds, newConfig.InstallCommands, "Install commands should persist")
		})
	})

	t.Run("EnvironmentVariable", func(t *testing.T) {
		t.Run("Persistence", func(t *testing.T) {
			WithRepository(t, "envvar_persistence", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
				// User: "Create a Node.js development environment"
				env := user.CreateEnvironment("Node.js Dev", "Setting up Node.js development environment")
				envID := env.ID // LLM only keeps the ID, not the whole object

				// User: "I need to set environment variables for my API"
				// LLM has to provide ALL required fields because the tool requires them
				user.UpdateEnvironment(envID, "Node.js Dev", "Configure API environment variables", &environment.EnvironmentConfig{
					BaseImage:     "ubuntu:24.04",
					SetupCommands: []string{},
					Workdir:       "/workdir",
					Env: []string{
						"API_URL=https://api.example.com",
						"NODE_ENV=production",
						"PORT=3000",
					},
					Secrets: []string{},
				})

				// User: "Check if my environment variables are set"
				output := user.RunCommand(envID, "echo API_URL=$API_URL NODE_ENV=$NODE_ENV PORT=$PORT", "Verify env vars")
				assert.Contains(t, output, "API_URL=https://api.example.com")
				assert.Contains(t, output, "NODE_ENV=production")
				assert.Contains(t, output, "PORT=3000")

				// User: "Add a simple setup command"
				// Again, LLM must provide ALL fields, potentially losing env vars if not careful
				user.UpdateEnvironment(envID, "Node.js Dev", "Add setup command", &environment.EnvironmentConfig{
					BaseImage: "ubuntu:24.04",
					SetupCommands: []string{
						"echo 'Setup complete' > /tmp/setup.log",
					},
					Workdir: "/workdir",
					Env: []string{
						"API_URL=https://api.example.com",
						"NODE_ENV=production",
						"PORT=3000",
					},
					Secrets: []string{},
				})

				// User: "Are my environment variables still there?"
				output = user.RunCommand(envID, "echo API_URL=$API_URL", "Check API_URL after rebuild")
				assert.Contains(t, output, "API_URL=https://api.example.com")

				output = user.RunCommand(envID, "echo NODE_ENV=$NODE_ENV", "Check NODE_ENV after rebuild")
				assert.Contains(t, output, "NODE_ENV=production")

				output = user.RunCommand(envID, "echo PORT=$PORT", "Check PORT after rebuild")
				assert.Contains(t, output, "PORT=3000")
			})
		})

		t.Run("Loss", func(t *testing.T) {
			// This test shows what happens when an LLM forgets to include env vars
			WithRepository(t, "envvar_loss", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
				// User: "Create a Node.js environment with env vars"
				env := user.CreateEnvironment("Node.js API", "Create Node.js API environment")
				envID := env.ID

				// User: "Set up my API environment variables"
				user.UpdateEnvironment(envID, "Node.js API", "Configure environment", &environment.EnvironmentConfig{
					BaseImage:     "ubuntu:24.04",
					SetupCommands: []string{},
					Workdir:       "/workdir",
					Env: []string{
						"DATABASE_URL=postgres://localhost:5432/mydb",
						"REDIS_URL=redis://localhost:6379",
						"API_KEY=secret123",
					},
					Secrets: []string{},
				})

				// Verify env vars are set
				output := user.RunCommand(envID, "echo DATABASE_URL=$DATABASE_URL", "Check database URL")
				assert.Contains(t, output, "DATABASE_URL=postgres://localhost:5432/mydb")

				// User: "Add a marker file"
				// LLM forgets to include the env vars when updating!
				user.UpdateEnvironment(envID, "Node.js API", "Add marker file", &environment.EnvironmentConfig{
					BaseImage: "ubuntu:24.04",
					SetupCommands: []string{
						"touch /tmp/marker.txt",
					},
					Workdir: "/workdir",
					Env:     []string{}, // Oops! LLM forgot to include existing env vars
					Secrets: []string{},
				})

				// Check if env vars are lost
				output = user.RunCommand(envID, "echo DATABASE_URL=$DATABASE_URL", "Check if database URL survived")
				assert.NotContains(t, output, "postgres://localhost:5432/mydb", "Environment variables were lost!")
				assert.Equal(t, "DATABASE_URL=\n", output, "DATABASE_URL should be empty")
			})
		})
	})

	t.Run("LifecycleOperations", func(t *testing.T) {
		WithRepository(t, "lifecycle", SetupNodeRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
			ctx := context.Background()

			// Test Create
			newEnv := user.CreateEnvironment("Test lifecycle", "Creating environment for lifecycle testing")
			require.NotNil(t, newEnv)

			envID := newEnv.ID
			originalWorktree := user.WorktreePath(newEnv.ID)

			// Environment is registered
			retrieved, err := repo.Get(ctx, user.dag, envID)
			assert.NoError(t, err)
			assert.NotNil(t, retrieved, "Environment should be retrievable")

			// Worktree at predictable location
			assert.Contains(t, originalWorktree, envID, "Worktree path should contain environment ID")

			// Test Update with Alpine base image
			setupCmds := []string{"apk add --no-cache git nodejs npm"}
			updatedConfig := newEnv.State.Config.Copy()
			updatedConfig.BaseImage = "alpine:latest"
			updatedConfig.SetupCommands = setupCmds

			user.UpdateEnvironment(newEnv.ID, "Test lifecycle", "Install development tools", updatedConfig)

			// Setup command executed
			output := user.RunCommand(newEnv.ID, "node --version", "Check node installed")
			assert.Contains(t, output, "v", "Node should be installed")

			// Worktree location stable
			assert.Equal(t, originalWorktree, user.WorktreePath(newEnv.ID), "Worktree location should not change")

			// Test Delete
			err = repo.Delete(ctx, envID)
			require.NoError(t, err, "Should delete environment")

			// Verify cleanup
			_, err = repo.Get(ctx, user.dag, envID)
			assert.Error(t, err, "Environment should not be retrievable after deletion")

			// Worktree deleted
			_, err = os.Stat(user.WorktreePath(envID))
			assert.True(t, os.IsNotExist(err), "Worktree should be deleted")
		})
	})
}



================================================
FILE: environment/integration/merge_test.go
================================================
package integration

import (
	"bytes"
	"context"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/dagger/container-use/repository"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestRepositoryMerge tests merging an environment into the main branch
func TestRepositoryMerge(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-merge", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Create an environment and add some content
		env := user.CreateEnvironment("Test Merge", "Testing repository merge")
		user.FileWrite(env.ID, "merge-test.txt", "content from environment", "Add merge test file")
		user.FileWrite(env.ID, "config.json", `{"version": "1.0"}`, "Add config file")

		// Get initial branch
		initialBranch, err := repository.RunGitCommand(ctx, repo.SourcePath(), "branch", "--show-current")
		require.NoError(t, err)
		initialBranch = strings.TrimSpace(initialBranch)

		// Merge the environment (without squash)
		var mergeOutput bytes.Buffer
		err = repo.Merge(ctx, env.ID, &mergeOutput)
		require.NoError(t, err, "Merge should succeed: %s", mergeOutput.String())

		// Verify we're still on the initial branch
		currentBranch, err := repository.RunGitCommand(ctx, repo.SourcePath(), "branch", "--show-current")
		require.NoError(t, err)
		assert.Equal(t, initialBranch, strings.TrimSpace(currentBranch))

		// Verify the files were merged into the working directory
		mergeTestPath := filepath.Join(repo.SourcePath(), "merge-test.txt")
		content, err := os.ReadFile(mergeTestPath)
		require.NoError(t, err)
		assert.Equal(t, "content from environment", string(content))

		configPath := filepath.Join(repo.SourcePath(), "config.json")
		configContent, err := os.ReadFile(configPath)
		require.NoError(t, err)
		assert.Equal(t, `{"version": "1.0"}`, string(configContent))

		// Verify commit history includes the environment changes
		log, err := repository.RunGitCommand(ctx, repo.SourcePath(), "log", "--oneline", "-10")
		require.NoError(t, err)
		// The merge might be fast-forward, so check for either merge commit or environment commits
		assert.True(t,
			strings.Contains(log, "Merge environment "+env.ID) ||
				(strings.Contains(log, "Add merge test file") && strings.Contains(log, "Add config file")),
			"Log should contain merge commit or environment commits: %s", log)
	})
}

// TestRepositoryApply tests applying an environment as staged changes (equivalent to merge --squash)
func TestRepositoryApply(t *testing.T) {
	WithRepository(t, "repository-apply", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Create an environment and add content with multiple commits
		env := user.CreateEnvironment("Test Apply", "Testing repository apply functionality")
		user.FileWrite(env.ID, "apply-test.txt", "first version", "First commit")
		user.FileWrite(env.ID, "apply-test.txt", "updated version", "Second commit")
		user.FileWrite(env.ID, "another-file.txt", "another file", "Third commit")

		// Get initial branch
		initialBranch, err := repository.RunGitCommand(ctx, repo.SourcePath(), "branch", "--show-current")
		require.NoError(t, err)
		initialBranch = strings.TrimSpace(initialBranch)

		// Apply the environment (squash merge)
		var applyOutput bytes.Buffer
		err = repo.Apply(ctx, env.ID, &applyOutput)
		require.NoError(t, err, "Apply should succeed: %s", applyOutput.String())

		// Verify we're still on the initial branch
		currentBranch, err := repository.RunGitCommand(ctx, repo.SourcePath(), "branch", "--show-current")
		require.NoError(t, err)
		assert.Equal(t, initialBranch, strings.TrimSpace(currentBranch))

		// Verify the files were applied to working directory
		applyTestPath := filepath.Join(repo.SourcePath(), "apply-test.txt")
		content, err := os.ReadFile(applyTestPath)
		require.NoError(t, err)
		assert.Equal(t, "updated version", string(content))

		anotherFilePath := filepath.Join(repo.SourcePath(), "another-file.txt")
		anotherContent, err := os.ReadFile(anotherFilePath)
		require.NoError(t, err)
		assert.Equal(t, "another file", string(anotherContent))

		// With apply, changes should be staged but not committed yet
		status, err := repository.RunGitCommand(ctx, repo.SourcePath(), "status", "--porcelain")
		require.NoError(t, err)
		// Files should be staged (prefixed with A or M)
		assert.Contains(t, status, "apply-test.txt")
		assert.Contains(t, status, "another-file.txt")

		// Verify no commits were made (original commit history should be discarded)
		log, err := repository.RunGitCommand(ctx, repo.SourcePath(), "log", "--oneline", "-10")
		require.NoError(t, err)
		// Should NOT contain the individual environment commits
		assert.NotContains(t, log, "First commit", "Apply should discard original commit history")
		assert.NotContains(t, log, "Second commit", "Apply should discard original commit history")
		assert.NotContains(t, log, "Third commit", "Apply should discard original commit history")

		// User can now commit manually
		_, err = repository.RunGitCommand(ctx, repo.SourcePath(), "commit", "-m", "Apply environment changes")
		require.NoError(t, err)

		// Verify the commit was made
		finalLog, err := repository.RunGitCommand(ctx, repo.SourcePath(), "log", "--oneline", "-1")
		require.NoError(t, err)
		assert.Contains(t, finalLog, "Apply environment changes")
	})
}

// TestRepositoryMergeNonExistent tests merging a non-existent environment
func TestRepositoryMergeNonExistent(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-merge-nonexistent", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Try to merge non-existent environment
		var mergeOutput bytes.Buffer
		err := repo.Merge(ctx, "non-existent-env", &mergeOutput)
		assert.Error(t, err, "Merging non-existent environment should fail")
		assert.Contains(t, err.Error(), "not found")
	})
}

// TestRepositoryApplyNonExistent tests applying a non-existent environment
func TestRepositoryApplyNonExistent(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-apply-nonexistent", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Try to apply non-existent environment
		var applyOutput bytes.Buffer
		err := repo.Apply(ctx, "non-existent-env", &applyOutput)
		assert.Error(t, err, "Applying non-existent environment should fail")
		assert.Contains(t, err.Error(), "not found")
	})
}

// TestRepositoryMergeWithConflicts tests merge behavior when there are conflicts
func TestRepositoryMergeWithConflicts(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-merge-conflicts", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Create an environment and modify the same file
		env := user.CreateEnvironment("Test Merge Conflicts", "Testing merge conflicts")
		user.FileWrite(env.ID, "conflict.txt", "environment branch content", "Modify conflict file")

		conflictFile := filepath.Join(repo.SourcePath(), "conflict.txt")
		err := os.WriteFile(conflictFile, []byte("main branch content"), 0644)
		require.NoError(t, err)

		_, err = repository.RunGitCommand(ctx, repo.SourcePath(), "add", "conflict.txt")
		require.NoError(t, err)
		_, err = repository.RunGitCommand(ctx, repo.SourcePath(), "commit", "-m", "Add conflict file in main")
		require.NoError(t, err)

		// Try to merge - this should either succeed with conflict resolution or fail gracefully
		var mergeOutput bytes.Buffer
		err = repo.Merge(ctx, env.ID, &mergeOutput)

		// The merge should fail due to conflict
		assert.Error(t, err, "Merge should fail due to conflict")
		outputStr := mergeOutput.String()
		assert.Contains(t, outputStr, "conflict", "Merge output should mention conflict: %s", outputStr)
	})
}

// TestRepositoryApplyWithConflicts tests apply behavior when there are conflicts
func TestRepositoryApplyWithConflicts(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-apply-conflicts", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Create an environment and modify the same file
		env := user.CreateEnvironment("Test Apply Conflicts", "Testing apply conflicts")
		user.FileWrite(env.ID, "conflict.txt", "environment branch content", "Modify conflict file")

		conflictFile := filepath.Join(repo.SourcePath(), "conflict.txt")
		err := os.WriteFile(conflictFile, []byte("main branch content"), 0644)
		require.NoError(t, err)

		_, err = repository.RunGitCommand(ctx, repo.SourcePath(), "add", "conflict.txt")
		require.NoError(t, err)
		_, err = repository.RunGitCommand(ctx, repo.SourcePath(), "commit", "-m", "Add conflict file in main")
		require.NoError(t, err)

		// Try to apply - this should fail due to conflict
		var applyOutput bytes.Buffer
		err = repo.Apply(ctx, env.ID, &applyOutput)

		// The apply should fail due to conflict
		assert.Error(t, err, "Apply should fail due to conflict")
		outputStr := applyOutput.String()
		assert.Contains(t, outputStr, "conflict", "Apply output should mention conflict: %s", outputStr)
	})
}

// TestRepositoryMergeCompleted tests merging the same environment multiple times
// This should result in fast-forward merges since the main branch doesn't diverge
func TestRepositoryMergeCompleted(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-merge-completed", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := context.Background()

		// Create an environment and add initial content
		env := user.CreateEnvironment("Test Repeated Merge", "Testing repeated merges")
		user.FileWrite(env.ID, "repeated-file.txt", "initial content", "Add initial file")

		// First merge
		var mergeOutput1 bytes.Buffer
		err := repo.Merge(ctx, env.ID, &mergeOutput1)
		require.NoError(t, err, "First merge should succeed: %s", mergeOutput1.String())

		// Verify first merge content
		filePath := filepath.Join(repo.SourcePath(), "repeated-file.txt")
		content, err := os.ReadFile(filePath)
		require.NoError(t, err)
		assert.Equal(t, "initial content", string(content))

		// Update the same file in the environment
		user.FileWrite(env.ID, "repeated-file.txt", "updated content", "Update file content")

		// Second merge
		var mergeOutput2 bytes.Buffer
		err = repo.Merge(ctx, env.ID, &mergeOutput2)
		require.NoError(t, err, "Second merge should succeed: %s", mergeOutput2.String())

		// Verify second merge content
		content, err = os.ReadFile(filePath)
		require.NoError(t, err)
		assert.Equal(t, "updated content", string(content))

		// Verify commit history includes both merges
		log, err := repository.RunGitCommand(ctx, repo.SourcePath(), "log", "--oneline", "-10")
		require.NoError(t, err)
		// Should have commits for both merges or their individual commits
		assert.Contains(t, log, "Add initial file", "Log should contain initial commit")
		assert.Contains(t, log, "Update file content", "Log should contain update commit")
	})
}



================================================
FILE: environment/integration/repository_test.go
================================================
package integration

import (
	"bytes"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/dagger/container-use/repository"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestRepositoryCreate tests creating a new environment
func TestRepositoryCreate(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-create", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		// Create an environment
		env := user.CreateEnvironment("Test Create", "Testing repository create")

		// Verify environment was created properly
		assert.NotNil(t, env)
		assert.NotEmpty(t, env.ID)
		assert.Equal(t, "Test Create", env.State.Title)
		worktreePath := user.WorktreePath(env.ID)
		assert.NotEmpty(t, worktreePath)

		// Verify worktree was created
		_, err := os.Stat(worktreePath)
		assert.NoError(t, err)
	})
}

// TestRepositoryGet tests retrieving an existing environment
func TestRepositoryGet(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-get", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create an environment
		env := user.CreateEnvironment("Test Get", "Testing repository get")

		// Get the environment using repository directly
		retrieved, err := repo.Get(ctx, user.dag, env.ID)
		require.NoError(t, err)
		assert.NotNil(t, retrieved)
		assert.Equal(t, env.ID, retrieved.ID)
		assert.Equal(t, env.State.Title, retrieved.State.Title)

		// Test getting non-existent environment
		_, err = repo.Get(ctx, user.dag, "non-existent-env")
		assert.Error(t, err)
	})
}

// TestRepositoryList tests listing all environments
func TestRepositoryList(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-list", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create two environments
		env1 := user.CreateEnvironment("Environment 1", "First test environment")
		env2 := user.CreateEnvironment("Environment 2", "Second test environment")

		// List should return at least 2
		envs, err := repo.List(ctx)
		require.NoError(t, err)
		assert.GreaterOrEqual(t, len(envs), 2)

		// Verify the environments are in the list
		var foundIDs []string
		for _, e := range envs {
			foundIDs = append(foundIDs, e.ID)
		}
		assert.Contains(t, foundIDs, env1.ID)
		assert.Contains(t, foundIDs, env2.ID)
	})
}

// TestRepositoryDelete tests deleting an environment
func TestRepositoryDelete(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-delete", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create an environment
		env := user.CreateEnvironment("Test Delete", "Testing repository delete")
		worktreePath := user.WorktreePath(env.ID)
		envID := env.ID

		// Delete it
		err := repo.Delete(ctx, envID)
		require.NoError(t, err)

		// Verify it's gone
		_, err = repo.Get(ctx, user.dag, envID)
		assert.Error(t, err)

		// Verify worktree is deleted
		_, err = os.Stat(worktreePath)
		assert.True(t, os.IsNotExist(err))
	})
}

// TestRepositoryCheckout tests checking out an environment branch
func TestRepositoryCheckout(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-checkout", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create an environment and add content
		env := user.CreateEnvironment("Test Checkout", "Testing repository checkout")
		user.FileWrite(env.ID, "test.txt", "test content", "Add test file")

		// Checkout the environment branch in the source repo
		branch, err := repo.Checkout(ctx, env.ID, "")
		require.NoError(t, err)
		assert.NotEmpty(t, branch)

		// Verify we're on the correct branch
		currentBranch, err := repository.RunGitCommand(ctx, repo.SourcePath(), "branch", "--show-current")
		require.NoError(t, err)
		// Branch name could be either env.ID or cu-env.ID depending on the logic
		actualBranch := strings.TrimSpace(currentBranch)
		assert.True(t, actualBranch == env.ID || actualBranch == "cu-"+env.ID,
			"Expected branch to be %s or cu-%s, got %s", env.ID, env.ID, actualBranch)
	})
}

// TestRepositoryLog tests retrieving commit history for an environment
func TestRepositoryLog(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-log", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create an environment and add some commits
		env := user.CreateEnvironment("Test Log", "Testing repository log")
		user.FileWrite(env.ID, "file1.txt", "initial content", "Initial commit")
		user.FileWrite(env.ID, "file1.txt", "updated content", "Update file")
		user.FileWrite(env.ID, "file2.txt", "new file", "Add second file")

		// Get commit log without patches
		var logBuf bytes.Buffer
		err := repo.Log(ctx, env.ID, false, &logBuf)
		logOutput := logBuf.String()
		require.NoError(t, err, logOutput)

		// Verify commit messages are present
		assert.Contains(t, logOutput, "Add second file")
		assert.Contains(t, logOutput, "Update file")
		assert.Contains(t, logOutput, "Initial commit")

		// Get commit log with patches
		logBuf.Reset()
		err = repo.Log(ctx, env.ID, true, &logBuf)
		logWithPatchOutput := logBuf.String()
		require.NoError(t, err, logWithPatchOutput)

		// Verify patch information is included
		assert.Contains(t, logWithPatchOutput, "diff --git")
		assert.Contains(t, logWithPatchOutput, "+updated content")

		// Test log for non-existent environment
		err = repo.Log(ctx, "non-existent-env", false, &logBuf)
		assert.Error(t, err)
	})
}

// TestRepositoryCreateFromGitRef tests creating environments from specific git references
func TestRepositoryCreateFromGitRef(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-create-from-ref", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create initial commit with test content
		user.WriteFileInSourceRepo("initial.txt", "initial content", "Initial commit")

		// Create a feature branch and add content
		user.CreateBranchInSourceRepo("feature-branch")
		user.WriteFileInSourceRepo("feature.txt", "feature content", "Add feature")

		// Go back to main and add different content
		user.CheckoutBranchInSourceRepo("main")
		user.WriteFileInSourceRepo("main.txt", "main content", "Add main file")

		// Get the SHA of the initial commit (before the main.txt was added)
		initialSHA, err := repository.RunGitCommand(ctx, repo.SourcePath(), "log", "--format=%H", "-n", "2", "--reverse")
		require.NoError(t, err)
		initialCommitSHA := strings.Split(strings.TrimSpace(initialSHA), "\n")[0]

		// Test creating environment from HEAD (default behavior)
		envFromHead := user.CreateEnvironment("From HEAD", "Environment from HEAD")
		content, err := envFromHead.FileRead(ctx, "main.txt", true, 0, 0)
		require.NoError(t, err)
		assert.Contains(t, content, "main content")

		// Test creating environment from feature branch
		envFromBranch, err := repo.Create(ctx, user.dag, "From Feature", "Environment from feature branch", "feature-branch")
		require.NoError(t, err)
		assert.NotNil(t, envFromBranch)

		// Should have feature.txt but not main.txt
		featureContent, err := envFromBranch.FileRead(ctx, "feature.txt", true, 0, 0)
		require.NoError(t, err)
		assert.Contains(t, featureContent, "feature content")

		_, err = envFromBranch.FileRead(ctx, "main.txt", true, 0, 0)
		assert.Error(t, err, "main.txt should not exist in feature branch environment")

		// Test creating environment from specific SHA
		envFromSHA, err := repo.Create(ctx, user.dag, "From SHA", "Environment from initial commit", initialCommitSHA)
		require.NoError(t, err)
		assert.NotNil(t, envFromSHA)

		// Should have only initial.txt
		initialContent, err := envFromSHA.FileRead(ctx, "initial.txt", true, 0, 0)
		require.NoError(t, err)
		assert.Contains(t, initialContent, "initial content")

		_, err = envFromSHA.FileRead(ctx, "main.txt", true, 0, 0)
		assert.Error(t, err, "main.txt should not exist in SHA environment")

		_, err = envFromSHA.FileRead(ctx, "feature.txt", true, 0, 0)
		assert.Error(t, err, "feature.txt should not exist in SHA environment")

		// Test invalid git ref
		_, err = repo.Create(ctx, user.dag, "Invalid Ref", "Environment from invalid ref", "nonexistent-ref")
		assert.Error(t, err, "Should fail with invalid git ref")
	})
}

func TestRepositoryWithSubmodule(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-with-submodule", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		user.GitCommand("submodule", "add", "https://github.com/dagger/dagger-test-modules.git", "submodule")
		user.GitCommand("submodule", "update", "--init")
		// test that everything works regardless of user's submodule init status
		user.GitCommand("submodule", "add", "https://github.com/dagger/dagger-test-modules.git", "submodule-2")

		user.GitCommand("commit", "-am", "add submodules")

		env := user.CreateEnvironment("Test Submodule", "Testing repository with submodule")

		// Add a file to the base repo
		user.FileWrite(env.ID, "test.txt", "initial content\n", "Initial commit")

		// Add a file to the submodule
		require.Error(t, env.FileWrite(
			ctx,
			"attempt to write a file to the submodule",
			"submodule/test.txt",
			"This should fail",
		))

		assert.NoError(t, repo.Update(ctx, env, "write the env back to the repo"))

		// Assert that submodule/test.txt doesn't exist on the host
		hostSubmoduleTestPath := filepath.Join(repo.SourcePath(), "submodule", "test.txt")
		_, statErr := os.Stat(hostSubmoduleTestPath)
		assert.True(t, os.IsNotExist(statErr), "submodule/test.txt should not exist on the host")

		// check that the contents of the repo are being cloned into the env
		checkSubmoduleReadme := func(submodulePath string) {
			readmeContent, readErr := env.FileRead(ctx, submodulePath+"/README.md", true, 0, 0)
			require.NoError(t, readErr, "Should be able to read %s/README.md from inside container", submodulePath)
			assert.Contains(t, readmeContent, "Test fixtures used by dagger integration tests.")
		}

		checkSubmoduleReadme("submodule")
		checkSubmoduleReadme("submodule-2")

		// Below we document the behavior of env.Run-instigated file writes to submodules.
		// Ideally, these would error, but practically we don't have an easy way to detect them.
		// env.Run-instigated submodules writes do not error, but they also do not propagate outwards to the fork repository.
		_, err := env.Run(ctx, "echo 'content from env_run_cmd' > submodule/test-from-cmd.txt", "sh", false)
		require.NoError(t, err, "env_run_cmd should be able to write files in submodules")

		// Verify the file was created inside the container
		fileContent, err := env.FileRead(ctx, "submodule/test-from-cmd.txt", true, 0, 0)
		require.NoError(t, err, "Should be able to read the file created by env_run_cmd")
		assert.Contains(t, fileContent, "content from env_run_cmd")

		// However, after update, the file should not exist on the host (same behavior as blocked FileWrite)
		assert.NoError(t, repo.Update(ctx, env, "update the env back to the repo"))
		hostCmdTestPath := filepath.Join(repo.SourcePath(), "submodule", "test-from-cmd.txt")
		_, statErr = os.Stat(hostCmdTestPath)
		assert.True(t, os.IsNotExist(statErr), "submodule/test-from-cmd.txt should not exist on the host after update")

		// Verify that the git working tree remains clean (no uncommitted changes)
		gitStatus, err := repository.RunGitCommand(ctx, repo.SourcePath(), "status", "--porcelain")
		require.NoError(t, err, "Should be able to check git status")
		assert.Empty(t, strings.TrimSpace(gitStatus), "Git working tree should remain clean after env_run_cmd writes to submodule")
	})
}

func TestRepositoryWithRecursiveSubmodule(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-with-submodule", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		user.GitCommand("submodule", "add", "https://github.com/git-up/test-repo-recursive-submodules.git", "submodule")
		user.GitCommand("submodule", "update", "--init")
		user.GitCommand("submodule", "add", "https://github.com/git-up/test-repo-recursive-submodules.git", "submodule-2")

		user.GitCommand("commit", "-am", "add submodules")

		env := user.CreateEnvironment("Test Submodule", "Testing repository with submodule")

		// Add a file to the base repo
		user.FileWrite(env.ID, "test.txt", "initial content\n", "Initial commit")

		// Add a file to the submodule
		require.Error(t, env.FileWrite(
			ctx,
			"attempt to write a file to the submodule",
			"submodule/test.txt",
			"This should fail",
		))

		assert.NoError(t, repo.Update(ctx, env, "write the env back to the repo"))

		// Assert that submodule/test.txt doesn't exist on the host
		hostSubmoduleTestPath := filepath.Join(repo.SourcePath(), "submodule", "test.txt")
		_, statErr := os.Stat(hostSubmoduleTestPath)
		assert.True(t, os.IsNotExist(statErr), "submodule/test.txt should not exist on the host")

		// check that the contents of the repo are being cloned into the env
		checkSubmoduleReadme := func(submodulePath string) {
			readmeContent, readErr := env.FileRead(ctx, submodulePath+"/README.md", true, 0, 0)
			require.NoError(t, readErr, "Should be able to read %s/README.md from inside container", submodulePath)
			assert.Contains(t, readmeContent, "A test repository that uses submodules")
		}

		// Check first-level submodules
		checkSubmoduleReadme("submodule")
		checkSubmoduleReadme("submodule-2")

		// Check nested submodules (recursive submodules)
		checkNestedSubmoduleReadme := func(submodulePath string) {
			nestedReadmeContent, readErr := env.FileRead(ctx, submodulePath+"/rebase/base/README.md", true, 0, 0)
			require.NoError(t, readErr, "Should be able to read %s/rebase/base/README.md from inside container", submodulePath)
			assert.Contains(t, nestedReadmeContent, "A simple test repository")
		}

		checkNestedSubmoduleReadme("submodule")
		checkNestedSubmoduleReadme("submodule-2")
	})
}

// TestRepositoryDiff tests retrieving changes between commits
func TestRepositoryDiff(t *testing.T) {
	t.Parallel()
	WithRepository(t, "repository-diff", SetupEmptyRepo, func(t *testing.T, repo *repository.Repository, user *UserActions) {
		ctx := t.Context()

		// Create an environment and make some changes
		env := user.CreateEnvironment("Test Diff", "Testing repository diff")

		// First commit - add a file
		user.FileWrite(env.ID, "test.txt", "initial content\n", "Initial commit")

		// Make changes to the file
		user.FileWrite(env.ID, "test.txt", "initial content\nupdated content\n", "Update file")

		// Get diff output
		var diffBuf bytes.Buffer
		err := repo.Diff(ctx, env.ID, &diffBuf)
		diffOutput := diffBuf.String()
		require.NoError(t, err, diffOutput)

		// Verify diff contains expected changes
		assert.Contains(t, diffOutput, "+updated content")

		// Test diff with non-existent environment
		err = repo.Diff(ctx, "non-existent-env", &diffBuf)
		assert.Error(t, err)
	})
}



================================================
FILE: examples/hello_world.md
================================================
create a simple flask app



================================================
FILE: examples/parallel.md
================================================
Create 2 variations of a simple hello world app using Flask and FastAPI. each in their own environment. Give me the URL of each app



================================================
FILE: examples/security.md
================================================
# Dependency Security Audit

1. Analyze project dependencies:
 . - Run the analysis in a sandbox using the latest Go version.
   - Check go.mod
   - List all dependencies with versions
   - Identify outdated packages

2. Security check:
   - Check for known vulnerabilities in Go
   - Identify dependencies with critical security issues

3. Upgrade those packages
   - Perform the updates in the sandbox.
   - Make sure the code still builds after updating.



================================================
FILE: examples/services.md
================================================
create a simple guestbook app using flask, redis and postgres



================================================
FILE: mcpserver/args.go
================================================
package mcpserver

import "github.com/mark3labs/mcp-go/mcp"

var (
	explanationArgument = mcp.WithString("explanation",
		mcp.Description("One sentence explanation for why this tool is being called."),
	)
	environmentSourceArgument = mcp.WithString("environment_source",
		mcp.Description("Absolute path to the source git repository for the environment."),
		mcp.Required(),
	)
	environmentIDArgument = mcp.WithString("environment_id",
		mcp.Description("The UUID of the environment for this command."),
		mcp.Required(),
	)
)

func newRepositoryTool(name string, description string, args ...mcp.ToolOption) mcp.Tool {
	opts := []mcp.ToolOption{
		mcp.WithDescription(description),
		explanationArgument,
		environmentSourceArgument,
	}

	opts = append(opts, args...)
	return mcp.NewTool(name, opts...)
}

type envToolOptions struct {
	name                  string
	description           string
	useCurrentEnvironment bool
}

func newEnvironmentTool(toolOptions envToolOptions, mcpToolOptions ...mcp.ToolOption) mcp.Tool {
	opts := []mcp.ToolOption{
		mcp.WithDescription(toolOptions.description),
		explanationArgument,
	}

	// in single-tenant mode, environment tools (except open) use currentEnvironmentID & currentEnvironmentSource as their target env
	if !toolOptions.useCurrentEnvironment {
		opts = append(opts, environmentSourceArgument)
		opts = append(opts, environmentIDArgument)
	}

	opts = append(opts, mcpToolOptions...)
	return mcp.NewTool(toolOptions.name, opts...)
}



================================================
FILE: mcpserver/signals_unix.go
================================================
//go:build !windows

package mcpserver

import (
	"os"
	"syscall"
)

// getNotifySignals returns Unix-compatible signals for MCP server
func getNotifySignals() []os.Signal {
	return []os.Signal{os.Interrupt, os.Kill, syscall.SIGTERM}
}



================================================
FILE: mcpserver/signals_windows.go
================================================
//go:build windows

package mcpserver

import (
	"os"
	"syscall"
)

// getNotifySignals returns Windows-compatible signals for MCP server
func getNotifySignals() []os.Signal {
	// On Windows:
	// - os.Interrupt: Ctrl+C signal (can receive, cannot send to other processes)
	// - syscall.SIGTERM: Termination signal (can receive)
	// - os.Kill: Not a receivable signal, used only for Process.Kill()
	return []os.Signal{os.Interrupt, syscall.SIGTERM}
}



================================================
FILE: mcpserver/singletenant.go
================================================
// Package mcpserver provides single-tenant mode functionality for MCP servers.
//
// In single-tenant mode, a single MCP server process is assumed to serve only one
// chat session. This allows for optimizations where environment_id parameters can
// be omitted from most tools, with the server maintaining the current environment
// in memory.

package mcpserver

import (
	"fmt"
	"sync"
)

var (
	// currentEnvironmentID stores the current environment ID for single-tenant mode
	// This is per-server-process, not persisted to disk
	currentEnvironmentID string
	// currentEnvironmentSource stores the current environment source for single-tenant mode
	// This is per-server-process, not persisted to disk
	currentEnvironmentSource string
	currentEnvMutex          sync.RWMutex
)

// getCurrentEnvironmentID returns the current environment ID for single-tenant mode
func getCurrentEnvironmentID() (string, error) {
	currentEnvMutex.RLock()
	defer currentEnvMutex.RUnlock()

	if currentEnvironmentID == "" {
		return "", fmt.Errorf("no current environment set. Use environment_create or environment_open first")
	}
	return currentEnvironmentID, nil
}

// getCurrentEnvironmentSource returns the current environment source for single-tenant mode
func getCurrentEnvironmentSource() (string, error) {
	currentEnvMutex.RLock()
	defer currentEnvMutex.RUnlock()

	if currentEnvironmentSource == "" {
		return "", fmt.Errorf("no current environment set. Use environment_create or environment_open first")
	}
	return currentEnvironmentSource, nil
}

// setCurrentEnvironmentID sets the current environment ID for single-tenant mode
func setCurrentEnvironmentID(envID string) {
	currentEnvMutex.Lock()
	defer currentEnvMutex.Unlock()
	currentEnvironmentID = envID
}

// setCurrentEnvironmentSource sets the current environment source for single-tenant mode
func setCurrentEnvironmentSource(envSource string) {
	currentEnvMutex.Lock()
	defer currentEnvMutex.Unlock()
	currentEnvironmentSource = envSource
}

// setCurrentEnvironment sets both the current environment ID and source for single-tenant mode
func setCurrentEnvironment(envID, envSource string) {
	currentEnvMutex.Lock()
	defer currentEnvMutex.Unlock()
	currentEnvironmentID = envID
	currentEnvironmentSource = envSource
}



================================================
FILE: mcpserver/singletenant_test.go
================================================
package mcpserver

import (
	"testing"
)

func TestSingleTenantEnvironmentStorage(t *testing.T) {
	// Test setting and getting environment ID
	testEnvID := "test-env-id"
	testEnvSource := "/test/source/path"

	// Test individual setters and getters
	setCurrentEnvironmentID(testEnvID)
	setCurrentEnvironmentSource(testEnvSource)

	retrievedID, err := getCurrentEnvironmentID()
	if err != nil {
		t.Fatalf("Expected no error getting environment ID, got: %v", err)
	}
	if retrievedID != testEnvID {
		t.Fatalf("Expected environment ID %s, got: %s", testEnvID, retrievedID)
	}

	retrievedSource, err := getCurrentEnvironmentSource()
	if err != nil {
		t.Fatalf("Expected no error getting environment source, got: %v", err)
	}
	if retrievedSource != testEnvSource {
		t.Fatalf("Expected environment source %s, got: %s", testEnvSource, retrievedSource)
	}

	// Test combined setter
	newEnvID := "new-env-id"
	newEnvSource := "/new/source/path"
	setCurrentEnvironment(newEnvID, newEnvSource)

	retrievedID, err = getCurrentEnvironmentID()
	if err != nil {
		t.Fatalf("Expected no error getting environment ID after combined set, got: %v", err)
	}
	if retrievedID != newEnvID {
		t.Fatalf("Expected environment ID %s after combined set, got: %s", newEnvID, retrievedID)
	}

	retrievedSource, err = getCurrentEnvironmentSource()
	if err != nil {
		t.Fatalf("Expected no error getting environment source after combined set, got: %v", err)
	}
	if retrievedSource != newEnvSource {
		t.Fatalf("Expected environment source %s after combined set, got: %s", newEnvSource, retrievedSource)
	}

	// Clear state for other tests
	setCurrentEnvironment("", "")
}

func TestSingleTenantEnvironmentStorageEmpty(t *testing.T) {
	// Clear state
	setCurrentEnvironment("", "")

	// Test error when no environment is set
	_, err := getCurrentEnvironmentID()
	if err == nil {
		t.Fatal("Expected error when no environment ID is set")
	}

	_, err = getCurrentEnvironmentSource()
	if err == nil {
		t.Fatal("Expected error when no environment source is set")
	}
}



================================================
FILE: mcpserver/tools.go
================================================
package mcpserver

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"log/slog"
	"os"
	"os/signal"

	"dagger.io/dagger"
	"github.com/dagger/container-use/environment"
	"github.com/dagger/container-use/repository"
	"github.com/dagger/container-use/rules"
	"github.com/mark3labs/mcp-go/mcp"
	"github.com/mark3labs/mcp-go/server"
)

type daggerClientKey struct{}

type singleTenantKey struct{}

// single-tenant servers set this context key to indicate that this particular mcp server process will only have 1 chat session in it
// this allows api optimizations where environment_id is not required and allows claude tasks inherit their parent's envs

func openRepository(ctx context.Context, request mcp.CallToolRequest) (*repository.Repository, error) {
	// Check if we're in single-tenant mode
	singleTenant, _ := ctx.Value(singleTenantKey{}).(bool)

	var source string
	var err error

	if singleTenant {
		// In single-tenant mode, try to get from stored value first
		source = request.GetString("environment_source", "")
		if source == "" {
			source, err = getCurrentEnvironmentSource()
			if err != nil {
				return nil, err
			}
		}
	} else {
		// In multi-tenant mode, environment_source is required
		source, err = request.RequireString("environment_source")
		if err != nil {
			return nil, err
		}
	}

	repo, err := repository.Open(ctx, source)
	if err != nil {
		return nil, fmt.Errorf("unable to open repository: %w", err)
	}
	return repo, nil
}

func openEnvironment(ctx context.Context, request mcp.CallToolRequest) (*repository.Repository, *environment.Environment, error) {
	repo, err := openRepository(ctx, request)
	if err != nil {
		return nil, nil, err
	}

	// Check if we're in single-tenant mode
	singleTenant, _ := ctx.Value(singleTenantKey{}).(bool)

	var envID string
	if singleTenant {
		// in single-tenant mode, environment_open requests will have environment_id. all other env-scoped tools will have "".
		envID = request.GetString("environment_id", "")
		if envID == "" {
			currentEnvID, err := getCurrentEnvironmentID()
			if err != nil {
				return nil, nil, err
			}
			envID = currentEnvID
		}
	} else {
		// In multi-tenant mode, environment_id is required
		var err error
		envID, err = request.RequireString("environment_id")
		if err != nil {
			return nil, nil, err
		}
	}

	dag, ok := ctx.Value(daggerClientKey{}).(*dagger.Client)
	if !ok {
		return nil, nil, fmt.Errorf("dagger client not found in context")
	}
	env, err := repo.Get(ctx, dag, envID)
	if err != nil {
		return nil, nil, fmt.Errorf("unable to get environment: %w", err)
	}
	return repo, env, nil
}

type Tool struct {
	Definition mcp.Tool
	Handler    server.ToolHandlerFunc
}

func RunStdioServer(ctx context.Context, dag *dagger.Client, singleTenant bool) error {
	// Store single-tenant mode in context for tool handlers
	ctx = context.WithValue(ctx, singleTenantKey{}, singleTenant)

	s := server.NewMCPServer(
		"Dagger",
		"1.0.0",
		server.WithInstructions(rules.AgentRules),
	)

	for _, t := range createTools(singleTenant) {
		s.AddTool(t.Definition, wrapToolWithClient(t, dag, singleTenant).Handler)
	}

	slog.Info("starting server")

	stdioSrv := server.NewStdioServer(s)
	stdioSrv.SetErrorLogger(log.Default()) // this should re-use our `slog` handler

	ctx, cancel := signal.NotifyContext(ctx, getNotifySignals()...)
	defer cancel()

	err := stdioSrv.Listen(ctx, os.Stdin, os.Stdout)
	if err != nil && !errors.Is(err, context.Canceled) {
		return err
	}
	return nil
}

func createTools(singleTenant bool) []*Tool {
	return []*Tool{
		wrapTool(createEnvironmentOpenTool()),
		wrapTool(createEnvironmentCreateTool(singleTenant)),
		wrapTool(createEnvironmentUpdateMetadataTool(singleTenant)),
		wrapTool(createEnvironmentConfigTool(singleTenant)),
		wrapTool(createEnvironmentListTool(singleTenant)),
		wrapTool(createEnvironmentRunCmdTool(singleTenant)),
		wrapTool(createEnvironmentFileReadTool(singleTenant)),
		wrapTool(createEnvironmentFileListTool(singleTenant)),
		wrapTool(createEnvironmentFileWriteTool(singleTenant)),
		wrapTool(createEnvironmentFileEditTool(singleTenant)),
		wrapTool(createEnvironmentFileDeleteTool(singleTenant)),
		wrapTool(createEnvironmentAddServiceTool(singleTenant)),
		wrapTool(createEnvironmentCheckpointTool(singleTenant)),
	}
}

func Tools() []*Tool {
	return createTools(false) // Default to multi-tenant mode when called outside of RunStdioServer
}

func wrapTool(tool *Tool) *Tool {
	return &Tool{
		Definition: tool.Definition,
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			slog.Info("Tool called", "tool", tool.Definition.Name)
			defer func() {
				slog.Info("Tool finished", "tool", tool.Definition.Name)
			}()
			response, err := tool.Handler(ctx, request)
			if err != nil {
				return mcp.NewToolResultError(err.Error()), nil
			}
			return response, nil
		},
	}
}

// keeping this modular for now. we could move tool registration to RunStdioServer and collapse the 2 wrapTool functions.
func wrapToolWithClient(tool *Tool, dag *dagger.Client, singleTenant bool) *Tool {
	return &Tool{
		Definition: tool.Definition,
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			ctx = context.WithValue(ctx, daggerClientKey{}, dag)
			ctx = context.WithValue(ctx, singleTenantKey{}, singleTenant)
			return tool.Handler(ctx, request)
		},
	}
}

type EnvironmentResponse struct {
	ID              string                         `json:"id"`
	Title           string                         `json:"title"`
	Config          *environment.EnvironmentConfig `json:"config"`
	RemoteRef       string                         `json:"remote_ref"`
	CheckoutCommand string                         `json:"checkout_command_to_share_with_user"`
	LogCommand      string                         `json:"log_command_to_share_with_user"`
	DiffCommand     string                         `json:"diff_command_to_share_with_user"`
	Services        []*environment.Service         `json:"services,omitempty"`
}

func environmentResponseFromEnvInfo(envInfo *environment.EnvironmentInfo) *EnvironmentResponse {
	return &EnvironmentResponse{
		ID:              envInfo.ID,
		Title:           envInfo.State.Title,
		Config:          envInfo.State.Config,
		RemoteRef:       fmt.Sprintf("container-use/%s", envInfo.ID),
		CheckoutCommand: fmt.Sprintf("container-use checkout %s", envInfo.ID),
		LogCommand:      fmt.Sprintf("container-use log %s", envInfo.ID),
		DiffCommand:     fmt.Sprintf("container-use diff %s", envInfo.ID),
		Services:        nil, // EnvironmentInfo doesn't have "active" services, specifically useful for EndpointMappings
	}
}

func environmentResponseFromEnv(env *environment.Environment) *EnvironmentResponse {
	resp := environmentResponseFromEnvInfo(env.EnvironmentInfo)
	resp.Services = env.Services
	return resp
}

func marshalEnvironment(env *environment.Environment) (string, error) {
	out, err := json.Marshal(environmentResponseFromEnv(env))
	if err != nil {
		return "", fmt.Errorf("failed to marshal response: %w", err)
	}
	return string(out), nil
}

func marshalEnvironmentInfo(envInfo *environment.EnvironmentInfo) (string, error) {
	out, err := json.Marshal(environmentResponseFromEnvInfo(envInfo))
	if err != nil {
		return "", fmt.Errorf("failed to marshal response: %w", err)
	}
	return string(out), nil
}

func EnvironmentToCallResult(env *environment.Environment) (*mcp.CallToolResult, error) {
	out, err := marshalEnvironment(env)
	if err != nil {
		return nil, err
	}
	return mcp.NewToolResultText(out), nil
}

func EnvironmentInfoToCallResult(envInfo *environment.EnvironmentInfo) (*mcp.CallToolResult, error) {
	out, err := marshalEnvironmentInfo(envInfo)
	if err != nil {
		return nil, err
	}
	return mcp.NewToolResultText(out), nil
}

func createEnvironmentOpenTool() *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_open",
				description:           "Opens an existing environment. Return format is same as environment_create.",
				useCurrentEnvironment: false,
			},
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			_, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			// In single-tenant mode, set this as the current environment
			if singleTenantMode, _ := ctx.Value(singleTenantKey{}).(bool); singleTenantMode {
				source, _ := request.RequireString("environment_source")
				setCurrentEnvironment(env.ID, source)
			}

			return EnvironmentToCallResult(env)
		},
	}
}

func createEnvironmentCreateTool(singleTenant bool) *Tool {
	// Build arguments dynamically based on single-tenant mode
	args := []mcp.ToolOption{
		mcp.WithString("title",
			mcp.Description("Short description of the work that is happening in this environment."),
			mcp.Required(),
		),
		mcp.WithString("from_git_ref",
			mcp.Description("Git reference to create the environment from (e.g., HEAD, main, feature-branch, SHA). Defaults to HEAD if not specified."),
		),
	}

	// Add allow_replace parameter only in single-tenant mode
	if singleTenant {
		args = append(args, mcp.WithBoolean("allow_replace",
			mcp.Description("If true and an environment already exists for this session, destructively replace it with a new one."),
		))
	}

	return &Tool{
		Definition: newRepositoryTool(
			"environment_create",
			`Creates a new development environment.
The environment is the result of a the setups commands on top of the base image.
Environment configuration is managed by the user via cu config commands.`,
			args...,
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, err := openRepository(ctx, request)
			if err != nil {
				return nil, err
			}
			title, err := request.RequireString("title")
			if err != nil {
				return nil, err
			}

			// In single-tenant mode, check allow_replace before creating environment
			if singleTenantMode, _ := ctx.Value(singleTenantKey{}).(bool); singleTenantMode {
				allowReplace := request.GetBool("allow_replace", false) // Default false to prevent accidental environment replacement

				if !allowReplace {
					// Check if environment already exists
					if currentEnvID, err := getCurrentEnvironmentID(); err == nil {
						// Environment exists, return error with info about existing env
						return nil, fmt.Errorf("environment_id %s already exists for this session. Tools can be used directly. You can environment_open %s for more information, or set allow_replace=true to destructively replace it", currentEnvID, currentEnvID)
					}
				}
			}

			dag, ok := ctx.Value(daggerClientKey{}).(*dagger.Client)
			if !ok {
				return nil, fmt.Errorf("dagger client not found in context")
			}

			gitRef := request.GetString("from_git_ref", "HEAD")
			env, err := repo.Create(ctx, dag, title, request.GetString("explanation", ""), gitRef)
			if err != nil {
				return nil, fmt.Errorf("failed to create environment: %w", err)
			}

			// In single-tenant mode, set this as the current environment
			if singleTenantMode, _ := ctx.Value(singleTenantKey{}).(bool); singleTenantMode {
				source, _ := request.RequireString("environment_source")
				setCurrentEnvironment(env.ID, source)
			}

			out, err := marshalEnvironment(env)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal environment: %w", err)
			}

			dirty, status, err := repo.IsDirty(ctx)
			if err != nil {
				return nil, fmt.Errorf("unable to check if environment is dirty: %w", err)
			}

			if !dirty {
				return mcp.NewToolResultText(out), nil
			}

			return mcp.NewToolResultText(fmt.Sprintf(`%s

CRITICAL: You MUST inform the user that the repository %s has uncommitted changes that are NOT included in this environment. The environment was created from the last committed state only.

Uncommitted changes detected:
%s

You MUST tell the user: To include these changes in the environment, they need to commit them first using git commands outside the environment.`, out, request.GetString("environment_source", ""), status)), nil
		},
	}
}

func createEnvironmentUpdateMetadataTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_update_metadata",
				description:           "Update environment metadata such as title. This updates the descriptive information about what work is being done in the environment.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("title",
				mcp.Description("Updated title describing the work being done in this environment."),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			// Update title if provided
			if title := request.GetString("title", ""); title != "" {
				env.State.Title = title
			}

			if err := repo.Update(ctx, env, request.GetString("explanation", "")); err != nil {
				return nil, fmt.Errorf("unable to update the environment: %w", err)
			}

			out, err := marshalEnvironment(env)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal environment: %w", err)
			}
			return mcp.NewToolResultText(fmt.Sprintf("Environment metadata updated successfully.\n%s", out)), nil
		},
	}
}

func createEnvironmentConfigTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name: "environment_config",
				description: "Make environment config changes such as base image and setup commands." +
					"If the environment is missing any tools or instructions, you MUST call this function to update the environment." +
					"You MUST update the environment with any useful tools. You will be resumed with no other context than the information provided here",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithObject("config",
				mcp.Required(),
				mcp.Properties(map[string]any{
					"base_image": map[string]any{
						"type":        "string",
						"description": "Base image for the environment",
					},
					"setup_commands": map[string]any{
						"type":        "array",
						"description": "Commands that should be executed on top of the base image to set up the environment. Similar to `RUN` instructions in Dockerfiles.",
						"items":       map[string]any{"type": "string"},
					},
					"envs": map[string]any{
						"type":        "array",
						"description": "The environment variables to set (e.g. `[\"FOO=bar\", \"BAZ=qux\"]`).",
						"items":       map[string]any{"type": "string"},
					},
				}),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			updatedConfig := env.State.Config.Copy()

			newConfig, ok := request.GetArguments()["config"].(map[string]any)
			if !ok {
				return nil, errors.New("invalid config")
			}

			if baseImage, ok := newConfig["base_image"].(string); ok {
				updatedConfig.BaseImage = baseImage
			}

			if setupCommands, ok := newConfig["setup_commands"].([]any); ok {
				updatedConfig.SetupCommands = make([]string, len(setupCommands))
				for i, command := range setupCommands {
					updatedConfig.SetupCommands[i] = command.(string)
				}
			}

			if envs, ok := newConfig["envs"].([]any); ok {
				updatedConfig.Env = make([]string, len(envs))
				for i, env := range envs {
					updatedConfig.Env[i] = env.(string)
				}
			}

			if err := env.UpdateConfig(ctx, updatedConfig); err != nil {
				return nil, fmt.Errorf("unable to update the environment: %w", err)
			}

			if err := repo.Update(ctx, env, request.GetString("explanation", "")); err != nil {
				return nil, fmt.Errorf("failed to update repository: %w", err)
			}

			out, err := marshalEnvironment(env)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal environment: %w", err)
			}

			message := fmt.Sprintf(`SUCCESS: Configuration successfully applied. Environment has been restarted, all previous commands have been lost.
IMPORTANT: The configuration changes are LOCAL to this environment.
TELL THE USER: To make these changes persistent, they will have to run "cu config import %s"

%s
`, env.ID, out)

			return mcp.NewToolResultText(message), nil
		},
	}
}

func createEnvironmentListTool(_ bool) *Tool {
	return &Tool{
		Definition: newRepositoryTool(
			"environment_list",
			"List available environments",
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, err := openRepository(ctx, request)
			if err != nil {
				return nil, err
			}
			envInfos, err := repo.List(ctx)
			if err != nil {
				return nil, fmt.Errorf("invalid source: %w", err)
			}

			// Convert EnvironmentInfo slice to EnvironmentResponse slice
			responses := make([]EnvironmentResponse, len(envInfos))
			for i, envInfo := range envInfos {
				responses[i] = *environmentResponseFromEnvInfo(envInfo)
			}

			out, err := json.Marshal(responses)
			if err != nil {
				return nil, err
			}

			// Add warning message for LLMs
			result := string(out) + "\n\nDO NOT change environments without explicit permission from the user"
			return mcp.NewToolResultText(result), nil
		},
	}
}

func createEnvironmentRunCmdTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_run_cmd",
				description:           "Run a terminal command inside a NEW container within the environment.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("command",
				mcp.Description("The terminal command to execute. If empty, the environment's default command is used."),
			),
			mcp.WithString("shell",
				mcp.Description("The shell that will be interpreting this command (default: sh)"),
			),
			mcp.WithBoolean("background",
				mcp.Description(`Run the command in the background
Must ALWAYS be set for long running command (e.g. http server).
Failure to do so will result in the tool being stuck, awaiting for the command to finish.`,
				),
			),
			mcp.WithBoolean("use_entrypoint",
				mcp.Description("Use the image entrypoint, if present, by prepending it to the args."),
			),
			mcp.WithArray("ports",
				mcp.Description("Ports to expose. Only works with background environments. For each port, returns the environment_internal (for use inside environments) and host_external (for use by the user) addresses."),
				mcp.Items(map[string]any{"type": "number"}),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			command := request.GetString("command", "")
			shell := request.GetString("shell", "sh")

			updateRepo := func() error {
				if err := repo.Update(ctx, env, request.GetString("explanation", "")); err != nil {
					return fmt.Errorf("failed to update repository: %w", err)
				}
				return nil
			}

			background := request.GetBool("background", false)
			if background {
				ports := []int{}
				if portList, ok := request.GetArguments()["ports"].([]any); ok {
					for _, port := range portList {
						ports = append(ports, int(port.(float64)))
					}
				}
				endpoints, runErr := env.RunBackground(ctx, command, shell, ports, request.GetBool("use_entrypoint", false))
				// We want to update the repository even if the command failed.
				if err := updateRepo(); err != nil {
					return nil, err
				}
				if runErr != nil {
					return nil, fmt.Errorf("failed to run command: %w", runErr)
				}

				out, err := json.Marshal(endpoints)
				if err != nil {
					return nil, err
				}

				return mcp.NewToolResultText(fmt.Sprintf(`Command started in the background in NEW container. Endpoints are %s

To access from the user's machine: use host_external. To access from other commands in this environment: use environment_internal.

Any changes to the container workdir (%s) WILL NOT be committed to container-use/%s

Background commands are unaffected by filesystem and any other kind of changes. You need to start a new command for changes to take effect.`,
					string(out), env.State.Config.Workdir, env.ID)), nil
			}

			stdout, runErr := env.Run(ctx, command, shell, request.GetBool("use_entrypoint", false))
			// We want to update the repository even if the command failed.
			if err := updateRepo(); err != nil {
				return nil, err
			}
			if runErr != nil {
				return nil, fmt.Errorf("failed to run command: %w", runErr)
			}

			return mcp.NewToolResultText(fmt.Sprintf("%s\n\nAny changes to the container workdir (%s) have been committed and pushed to container-use/%s remote ref", stdout, env.State.Config.Workdir, env.ID)), nil
		},
	}
}

func createEnvironmentFileReadTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_file_read",
				description:           "Read the contents of a file, specifying a line range or the entire file.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("target_file",
				mcp.Description("Path of the file to read, absolute or relative to the workdir"),
				mcp.Required(),
			),
			mcp.WithBoolean("should_read_entire_file",
				mcp.Description("Whether to read the entire file. Defaults to false."),
			),
			mcp.WithNumber("start_line_one_indexed_inclusive",
				mcp.Description("The starting line (1-indexed, inclusive) to read from the file. Must specify both start_line and end_line if not reading entire file."),
			),
			mcp.WithNumber("end_line_one_indexed_inclusive",
				mcp.Description("The ending line (1-indexed, inclusive) to read from the file. Must specify both start_line and end_line if not reading entire file."),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			_, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			targetFile, err := request.RequireString("target_file")
			if err != nil {
				return nil, err
			}

			shouldReadEntireFile := request.GetBool("should_read_entire_file", false)
			startLineOneIndexedInclusive := request.GetInt("start_line_one_indexed_inclusive", 0)
			endLineOneIndexedInclusive := request.GetInt("end_line_one_indexed_inclusive", 0)

			fileContents, err := env.FileRead(ctx, targetFile, shouldReadEntireFile, startLineOneIndexedInclusive, endLineOneIndexedInclusive)
			if err != nil {
				return nil, fmt.Errorf("failed to read file: %w", err)
			}

			return mcp.NewToolResultText(fileContents), nil
		},
	}
}

func createEnvironmentFileListTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_file_list",
				description:           "List the contents of a directory",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("path",
				mcp.Description("Path of the directory to list contents of, absolute or relative to the workdir"),
				mcp.Required(),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			_, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			path, err := request.RequireString("path")
			if err != nil {
				return nil, err
			}

			out, err := env.FileList(ctx, path)
			if err != nil {
				return nil, fmt.Errorf("failed to list directory: %w", err)
			}

			return mcp.NewToolResultText(out), nil
		},
	}
}

func createEnvironmentFileEditTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_file_edit",
				description:           "Find and replace text in a file.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("target_file",
				mcp.Description("Path of the file to write, absolute or relative to the workdir."),
				mcp.Required(),
			),
			mcp.WithString("search_text",
				mcp.Description("The text to find and replace."),
				mcp.Required(),
			),
			mcp.WithString("replace_text",
				mcp.Description("The text to insert."),
				mcp.Required(),
			),
			mcp.WithString("which_match",
				mcp.Description("The ID of the match to replace, if there were multiple matches."),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return mcp.NewToolResultErrorFromErr("unable to open the environment", err), nil
			}

			targetFile, err := request.RequireString("target_file")
			if err != nil {
				return nil, err
			}
			search, err := request.RequireString("search_text")
			if err != nil {
				return nil, err
			}
			replace, err := request.RequireString("replace_text")
			if err != nil {
				return nil, err
			}

			if err := env.FileEdit(ctx,
				request.GetString("explanation", ""),
				targetFile,
				search,
				replace,
				request.GetString("which_match", ""),
			); err != nil {
				return mcp.NewToolResultErrorFromErr("failed to write file", err), nil
			}

			if err := repo.UpdateFile(ctx, env, targetFile, request.GetString("explanation", "")); err != nil {
				return mcp.NewToolResultErrorFromErr("unable to update the environment", err), nil
			}

			return mcp.NewToolResultText(fmt.Sprintf("file %s edited successfully and committed to container-use/%s remote ref", targetFile, env.ID)), nil
		},
	}
}

func createEnvironmentFileWriteTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_file_write",
				description:           "Write the contents of a file.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("target_file",
				mcp.Description("Path of the file to write, absolute or relative to the workdir."),
				mcp.Required(),
			),
			mcp.WithString("contents",
				mcp.Description("Full text content of the file you want to write."),
				mcp.Required(),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			targetFile, err := request.RequireString("target_file")
			if err != nil {
				return nil, err
			}
			contents, err := request.RequireString("contents")
			if err != nil {
				return nil, err
			}

			if err := env.FileWrite(ctx, request.GetString("explanation", ""), targetFile, contents); err != nil {
				return nil, fmt.Errorf("failed to write file: %w", err)
			}

			if err := repo.UpdateFile(ctx, env, targetFile, request.GetString("explanation", "")); err != nil {
				return nil, fmt.Errorf("unable to update the environment: %w", err)
			}

			return mcp.NewToolResultText(fmt.Sprintf("file %s written successfully and committed to container-use/%s remote ref", targetFile, env.ID)), nil
		},
	}
}

func createEnvironmentFileDeleteTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_file_delete",
				description:           "Deletes a file at the specified path.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("target_file",
				mcp.Description("Path of the file to delete, absolute or relative to the workdir."),
				mcp.Required(),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			targetFile, err := request.RequireString("target_file")
			if err != nil {
				return nil, err
			}

			if err := env.FileDelete(ctx, request.GetString("explanation", ""), targetFile); err != nil {
				return nil, fmt.Errorf("failed to delete file: %w", err)
			}

			if err := repo.Update(ctx, env, request.GetString("explanation", "")); err != nil {
				return nil, fmt.Errorf("failed to update env: %w", err)
			}

			return mcp.NewToolResultText(fmt.Sprintf("file %s deleted successfully and committed to container-use/%s remote ref", targetFile, env.ID)), nil
		},
	}
}

func createEnvironmentCheckpointTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_checkpoint",
				description:           "Checkpoints an environment in its current state as a container.",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("destination",
				mcp.Description("Container image destination to checkpoint to (e.g. registry.com/user/image:tag"),
				mcp.Required(),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			_, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}

			destination, err := request.RequireString("destination")
			if err != nil {
				return nil, err
			}

			endpoint, err := env.Checkpoint(ctx, destination)
			if err != nil {
				return nil, fmt.Errorf("failed to checkpoint environment: %w", err)
			}

			return mcp.NewToolResultText(fmt.Sprintf("Checkpoint pushed to %q. You MUST use the full content addressed (@sha256:...) reference in `docker` commands. The entrypoint is set to `sh`, keep that in mind when giving commands to the container.", endpoint)), nil
		},
	}
}

func createEnvironmentAddServiceTool(singleTenant bool) *Tool {
	return &Tool{
		Definition: newEnvironmentTool(
			envToolOptions{
				name:                  "environment_add_service",
				description:           "Add a service to the environment (e.g. database, cache, etc.)",
				useCurrentEnvironment: singleTenant,
			},
			mcp.WithString("name",
				mcp.Description("The name of the service to start."),
				mcp.Required(),
			),
			mcp.WithString("image",
				mcp.Description("The image of the service to start."),
				mcp.Required(),
			),
			mcp.WithString("command",
				mcp.Description("The command to start the service. If not provided the image default command will be used."),
			),
			mcp.WithArray("ports",
				mcp.Description("Ports to expose. For each port, returns the container_internal (for use by environments) and host_external (for use by the user) address."),
				mcp.Items(map[string]any{"type": "number"}),
			),
			mcp.WithArray("envs",
				mcp.Description("The environment variables to set (e.g. `[\"FOO=bar\", \"BAZ=qux\"]`)."),
				mcp.Items(map[string]any{"type": "string"}),
			),
		),
		Handler: func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
			repo, env, err := openEnvironment(ctx, request)
			if err != nil {
				return nil, err
			}
			serviceName, err := request.RequireString("name")
			if err != nil {
				return nil, err
			}
			image, err := request.RequireString("image")
			if err != nil {
				return nil, err
			}
			command := request.GetString("command", "")
			ports := []int{}
			if portList, ok := request.GetArguments()["ports"].([]any); ok {
				for _, port := range portList {
					ports = append(ports, int(port.(float64)))
				}
			}

			envs := request.GetStringSlice("envs", []string{})

			service, err := env.AddService(ctx, request.GetString("explanation", ""), &environment.ServiceConfig{
				Name:         serviceName,
				Image:        image,
				Command:      command,
				ExposedPorts: ports,
				Env:          envs,
			})
			if err != nil {
				return nil, fmt.Errorf("failed to add service: %w", err)
			}

			if err := repo.Update(ctx, env, request.GetString("explanation", "")); err != nil {
				return nil, fmt.Errorf("failed to update env: %w", err)
			}

			output, err := json.Marshal(service)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal service: %w", err)
			}

			return mcp.NewToolResultText(fmt.Sprintf("Service added and started successfully: %s", string(output))), nil
		},
	}
}



================================================
FILE: repository/flock.go
================================================
package repository

import (
	"context"
	"fmt"
	"log/slog"
	"os"
	"path/filepath"
	"sync"
	"time"

	"github.com/gofrs/flock"
)

// LockType represents different types of operations that can be locked
type LockType string

const (
	// LockTypeUserRepo - Git operations on the environment_source repo (changing remotes, fetching)
	LockTypeUserRepo LockType = "user-repo"
	// LockTypeForkRepo - Git operations on our fork (~/.config/container-use/repos/$repo)
	// Used for committing, creating worktrees, uploading from worktrees (should be rlock for uploads)
	LockTypeForkRepo LockType = "fork-repo"
	// LockTypeNotes - Subset of fork repo operations for saving state, notes etc
	// Notes are a global ref to that repository and we do many operations against them
	LockTypeNotes LockType = "notes"
)

// RepositoryLockManager provides granular process-level locking for repository operations
// to prevent git concurrency issues when multiple container-use instances
// operate on the same repository simultaneously.
type RepositoryLockManager struct {
	repoPath string
	locks    map[LockType]*RepositoryLock
	mu       sync.Mutex
}

// RepositoryLock provides process-level locking for specific operation types
type RepositoryLock struct {
	flock *flock.Flock
}

// NewRepositoryLockManager creates a new repository lock manager for the given repository path.
func NewRepositoryLockManager(repoPath string) *RepositoryLockManager {
	return &RepositoryLockManager{
		repoPath: repoPath,
		locks:    make(map[LockType]*RepositoryLock),
	}
}

// GetLock returns a lock for the specified operation type
func (rlm *RepositoryLockManager) GetLock(lockType LockType) *RepositoryLock {
	rlm.mu.Lock()
	defer rlm.mu.Unlock()

	if lock, exists := rlm.locks[lockType]; exists {
		return lock
	}

	lockFileName := fmt.Sprintf("container-use-%x-%s.lock", hashString(rlm.repoPath), string(lockType))
	lockDir := filepath.Join(os.TempDir(), "container-use-locks")
	lockFile := filepath.Join(lockDir, lockFileName)

	err := os.MkdirAll(lockDir, 0755)
	if err != nil {
		slog.Error("Failed to create lock directory", "error", err)
	}

	lock := &RepositoryLock{
		flock: flock.New(lockFile),
	}

	rlm.locks[lockType] = lock
	return lock
}

// WithLock executes a function while holding an exclusive lock for the specified lock type
func (rlm *RepositoryLockManager) WithLock(ctx context.Context, lockType LockType, fn func() error) error {
	return rlm.GetLock(lockType).WithLock(ctx, fn)
}

// WithRLock executes a function while holding a shared (read) lock for the specified lock type.
// Multiple readers can hold the lock simultaneously, but writers will block until all readers release.
func (rlm *RepositoryLockManager) WithRLock(ctx context.Context, lockType LockType, fn func() error) error {
	return rlm.GetLock(lockType).WithRLock(ctx, fn)
}

// Lock acquires an exclusive repository lock.
func (rl *RepositoryLock) Lock(ctx context.Context) error {
	const retryDelay = 100 * time.Millisecond

	locked, err := rl.flock.TryLockContext(ctx, retryDelay)
	if err != nil {
		return fmt.Errorf("failed to acquire exclusive lock: %w", err)
	}
	if !locked {
		return fmt.Errorf("failed to acquire exclusive lock within context timeout")
	}

	return nil
}

// RLock acquires a shared repository lock.
// Multiple processes can hold shared locks simultaneously.
func (rl *RepositoryLock) RLock(ctx context.Context) error {
	const retryDelay = 100 * time.Millisecond

	locked, err := rl.flock.TryRLockContext(ctx, retryDelay)
	if err != nil {
		return fmt.Errorf("failed to acquire shared lock: %w", err)
	}
	if !locked {
		return fmt.Errorf("failed to acquire shared lock within context timeout")
	}

	return nil
}

// Unlock releases the repository lock.
func (rl *RepositoryLock) Unlock() error {
	return rl.flock.Unlock()
}

// WithLock executes a function while holding an exclusive lock.
func (rl *RepositoryLock) WithLock(ctx context.Context, fn func() error) error {
	if err := rl.Lock(ctx); err != nil {
		return err
	}
	defer rl.Unlock()

	return fn()
}

// WithRLock executes a function while holding a shared lock.
func (rl *RepositoryLock) WithRLock(ctx context.Context, fn func() error) error {
	if err := rl.RLock(ctx); err != nil {
		return err
	}
	defer rl.Unlock()

	return fn()
}

// hashString creates a simple hash of a string for use in filenames
func hashString(s string) uint32 {
	h := uint32(2166136261) // FNV-1a 32-bit offset basis
	for i := 0; i < len(s); i++ {
		h = (h ^ uint32(s[i])) * 16777619 // FNV-1a 32-bit prime
	}
	return h
}



================================================
FILE: repository/git.go
================================================
package repository

import (
	"context"
	"errors"
	"fmt"
	"io"
	"log/slog"
	"net/url"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"slices"
	"strings"

	"dagger.io/dagger"
	"github.com/dagger/container-use/environment"
	"github.com/mitchellh/go-homedir"
)

const (
	maxFileSizeForTextCheck = 10 * 1024 * 1024 // 10MB
)

var (
	urlSchemeRegExp  = regexp.MustCompile(`^[^:]+://`)
	scpLikeURLRegExp = regexp.MustCompile(`^(?:(?P<user>[^@]+)@)?(?P<host>[^:\s]+):(?:(?P<port>[0-9]{1,5})(?:\/|:))?(?P<path>[^\\].*\/[^\\].*)$`)
)

// RunGitCommand executes a git command in the specified directory.
// This is exported for use in tests and other packages that need direct git access.
func RunGitCommand(ctx context.Context, dir string, args ...string) (out string, rerr error) {
	slog.Info(fmt.Sprintf("[%s] $ git %s", dir, strings.Join(args, " ")))
	defer func() {
		slog.Info(fmt.Sprintf("[%s] $ git %s (DONE)", dir, strings.Join(args, " ")), "err", rerr)
	}()

	cmd := exec.CommandContext(ctx, "git", args...)
	cmd.Dir = dir

	output, err := cmd.CombinedOutput()
	if err != nil {
		var exitErr *exec.ExitError
		if errors.As(err, &exitErr) {
			return "", fmt.Errorf("git command failed (exit code %d): %w\nOutput: %s",
				exitErr.ExitCode(), err, string(output))
		}
		return "", fmt.Errorf("git command failed: %w", err)
	}

	return string(output), nil
}

// RunInteractiveGitCommand executes a git command in the specified directory in interactive mode.
func RunInteractiveGitCommand(ctx context.Context, dir string, w io.Writer, args ...string) (rerr error) {
	slog.Info(fmt.Sprintf("[%s] $ git %s", dir, strings.Join(args, " ")))
	defer func() {
		slog.Info(fmt.Sprintf("[%s] $ git %s (DONE)", dir, strings.Join(args, " ")), "err", rerr)
	}()

	cmd := exec.CommandContext(ctx, "git", args...)
	cmd.Dir = dir
	cmd.Stdout = w
	cmd.Stderr = w

	return cmd.Run()
}

func getContainerUseRemote(ctx context.Context, repo string) (string, error) {
	// Check if we already have a container-use remote
	cuRemote, err := RunGitCommand(ctx, repo, "remote", "get-url", "container-use")
	if err != nil {
		// Check for exit code 2 which means the remote doesn't exist
		var exitErr *exec.ExitError
		if errors.As(err, &exitErr) && exitErr.ExitCode() == 2 {
			return "", os.ErrNotExist
		}
		return "", err
	}

	return strings.TrimSpace(cuRemote), nil
}

func (r *Repository) WorktreePath(id string) (string, error) {
	return homedir.Expand(filepath.Join(r.getWorktreePath(), id))
}

func (r *Repository) deleteWorktree(id string) error {
	worktreePath, err := r.WorktreePath(id)
	if err != nil {
		return err
	}
	fmt.Printf("Deleting worktree at %s\n", worktreePath)
	return os.RemoveAll(worktreePath)
}

func (r *Repository) deleteLocalRemoteBranch(id string) error {
	slog.Info("Pruning git worktrees", "repo", r.forkRepoPath)
	if _, err := RunGitCommand(context.Background(), r.forkRepoPath, "worktree", "prune"); err != nil {
		slog.Error("Failed to prune git worktrees", "repo", r.forkRepoPath, "err", err)
		return err
	}

	slog.Info("Deleting local branch", "repo", r.forkRepoPath, "branch", id)
	if _, err := RunGitCommand(context.Background(), r.forkRepoPath, "branch", "-D", id); err != nil {
		slog.Error("Failed to delete local branch", "repo", r.forkRepoPath, "branch", id, "err", err)
		return err
	}

	if _, err := RunGitCommand(context.Background(), r.userRepoPath, "remote", "prune", containerUseRemote); err != nil {
		slog.Error("Failed to fetch and prune container-use remote", "local-repo", r.userRepoPath, "err", err)
		return err
	}

	return nil
}

// initializeWorktree initializes a new worktree for environment creation.
// It pushes the specified gitRef to create a new branch with the given id, then creates a worktree from that branch.
// Returns the worktree path, any submodule warning, and an error.
func (r *Repository) initializeWorktree(ctx context.Context, id, gitRef string) (string, string, error) {
	if gitRef == "" {
		gitRef = "HEAD"
	}

	worktreePath, err := r.WorktreePath(id)
	if err != nil {
		return "", "", err
	}

	slog.Info("Initializing new worktree", "repository", r.userRepoPath, "environment-id", id, "from-ref", gitRef)

	var submoduleWarning string
	err = r.lockManager.WithLock(ctx, LockTypeForkRepo, func() error {
		resolvedRef, err := RunGitCommand(ctx, r.userRepoPath, "rev-parse", gitRef)
		if err != nil {
			return err
		}
		resolvedRef = strings.TrimSpace(resolvedRef)

		_, err = RunGitCommand(ctx, r.userRepoPath, "push", containerUseRemote, fmt.Sprintf("%s:refs/heads/%s", resolvedRef, id))
		if err != nil {
			// Retry once on failure
			_, err = RunGitCommand(ctx, r.userRepoPath, "push", containerUseRemote, fmt.Sprintf("%s:refs/heads/%s", resolvedRef, id))
			if err != nil {
				return err
			}
		}

		_, err = RunGitCommand(ctx, r.forkRepoPath, "worktree", "add", worktreePath, id)
		if err != nil {
			return err
		}

		_, err = RunGitCommand(ctx, r.userRepoPath, "fetch", containerUseRemote, id)
		if err != nil {
			return err
		}

		// Initialize submodules using host credentials
		submoduleOutput, submoduleErr := RunGitCommand(ctx, worktreePath, "submodule", "update", "--init", "--recursive")
		if submoduleErr != nil {
			// Log warning but don't fail - submodules might require auth
			slog.Warn("Failed to initialize submodules",
				"error", submoduleErr,
				"output", submoduleOutput)
			submoduleWarning = fmt.Sprintf("Failed to initialize submodules: %v", submoduleErr)
		}

		// Absorb git directories for submodules to ensure paths are consistent
		// This is especially important for recursive submodules
		_, absorbErr := RunGitCommand(ctx, worktreePath, "submodule", "absorbgitdirs")
		if absorbErr != nil {
			slog.Warn("Failed to absorb git modules for submodules",
				"error", absorbErr)
		}

		return nil
	})

	return worktreePath, submoduleWarning, err
}

// getWorktree gets or recreates a worktree for an existing environment.
// It assumes the environment branch already exists in the forkRepo and will fail if it doesn't.
func (r *Repository) getWorktree(ctx context.Context, id string) (string, error) {
	worktreePath, err := r.WorktreePath(id)
	if err != nil {
		return "", err
	}

	// Early return if the worktree already exists
	if _, err := os.Stat(worktreePath); err == nil {
		return worktreePath, nil
	}

	slog.Info("Recreating worktree for existing environment", "repository", r.userRepoPath, "environment-id", id)

	return worktreePath, r.lockManager.WithLock(ctx, LockTypeForkRepo, func() error {
		// In case something has changed while waiting for lock. prolly too defensive.
		if _, err := os.Stat(worktreePath); err == nil {
			return nil
		}

		// Verify the environment branch exists in forkRepo before creating worktree
		_, err := RunGitCommand(ctx, r.forkRepoPath, "rev-parse", "--verify", id)
		if err != nil {
			return fmt.Errorf("environment branch %s not found in fork repository: %w", id, err)
		}

		_, err = RunGitCommand(ctx, r.forkRepoPath, "worktree", "add", worktreePath, id)
		if err != nil {
			return err
		}

		_, err = RunGitCommand(ctx, r.userRepoPath, "fetch", containerUseRemote, id)
		if err != nil {
			return err
		}

		return nil
	})
}

// createInitialCommit creates an empty commit with the environment creation message - this prevents multiple environments from overwriting the container-use-state on the parent commit
func (r *Repository) createInitialCommit(ctx context.Context, worktreePath, id, title string) error {
	commitMessage := fmt.Sprintf("Create environment %s: %s", id, title)
	_, err := RunGitCommand(ctx, worktreePath, "commit", "--allow-empty", "-m", commitMessage)
	return err
}

func (r *Repository) propagateToWorktree(ctx context.Context, env *environment.Environment, explanation string) (rerr error) {
	slog.Info("Propagating to worktree...",
		"environment.id", env.ID,
		"workdir", env.State.Config.Workdir,
		"id", env.ID)
	defer func() {
		slog.Info("Propagating to worktree... (DONE)",
			"environment.id", env.ID,
			"workdir", env.State.Config.Workdir,
			"id", env.ID,
			"err", rerr)
	}()

	if err := r.exportEnvironment(ctx, env); err != nil {
		return err
	}

	return r.propagateToGit(ctx, env, explanation)
}

// propagateToGit commits exported changes and syncs them back to the user's git repository
func (r *Repository) propagateToGit(ctx context.Context, env *environment.Environment, explanation string) error {
	worktreePath, err := r.WorktreePath(env.ID)
	if err != nil {
		return fmt.Errorf("failed to get worktree path: %w", err)
	}

	if err := r.commitWorktreeChanges(ctx, worktreePath, explanation, env.State.SubmodulePaths); err != nil {
		return fmt.Errorf("failed to commit worktree changes: %w", err)
	}

	if err := r.saveState(ctx, env); err != nil {
		return fmt.Errorf("failed to add notes: %w", err)
	}

	if err := r.lockManager.WithLock(ctx, LockTypeUserRepo, func() error {
		slog.Info("Fetching container-use remote in source repository")
		_, err := RunGitCommand(ctx, r.userRepoPath, "fetch", containerUseRemote, env.ID)
		return err
	}); err != nil {
		return err
	}

	if err := r.propagateGitNotes(ctx, gitNotesStateRef); err != nil {
		return err
	}

	if note := env.Notes.Pop(); note != "" {
		return r.addGitNote(ctx, env, note)
	}

	return nil
}

// readSubmoduleGitdirPath reads the gitdir path from a submodule's .git file
// reading these files on every export is unfortunate-- ideally we'd compute their values,
// but doing so requires complete knowledge of the tree structure of the submodules.
func readSubmoduleGitdirPath(worktreePath, submodulePath string) (string, error) {
	submoduleGitPath := filepath.Join(worktreePath, submodulePath, ".git")

	gitContent, err := os.ReadFile(submoduleGitPath)
	if err != nil {
		return "", fmt.Errorf("failed to read submodule .git file %s: %w", submoduleGitPath, err)
	}

	gitContentStr := strings.TrimSpace(string(gitContent))
	if !strings.HasPrefix(gitContentStr, "gitdir: ") {
		return "", fmt.Errorf("invalid .git file format in submodule %s: %s", submoduleGitPath, gitContentStr)
	}

	return gitContentStr, nil
}

// addSubmoduleGitdirFiles adds .git files for all submodules to the provided directory
func addSubmoduleGitdirFiles(baseDir *dagger.Directory, worktreePath string, submodulePaths []string) (*dagger.Directory, error) {
	result := baseDir

	for _, submodulePath := range submodulePaths {
		gitdirPath, err := readSubmoduleGitdirPath(worktreePath, submodulePath)
		if err != nil {
			return nil, fmt.Errorf("failed to read gitdir path for submodule %s: %w", submodulePath, err)
		}

		result = result.WithNewFile(filepath.Join(submodulePath, ".git"), gitdirPath)
	}

	return result, nil
}

// propagateFileToWorktree propagates a single file from the environment to the worktree
// This is more efficient than propagateToWorktree for single file operations
func (r *Repository) propagateFileToWorktree(ctx context.Context, env *environment.Environment, filePath, explanation string) (rerr error) {
	slog.Info("Propagating single file to worktree...",
		"environment.id", env.ID,
		"file", filePath,
		"workdir", env.State.Config.Workdir)
	defer func() {
		slog.Info("Propagating single file to worktree... (DONE)",
			"environment.id", env.ID,
			"file", filePath,
			"workdir", env.State.Config.Workdir,
			"err", rerr)
	}()

	if err := r.exportEnvironmentFile(ctx, env, filePath); err != nil {
		return err
	}

	return r.propagateToGit(ctx, env, explanation)
}

func (r *Repository) exportEnvironment(ctx context.Context, env *environment.Environment) error {
	worktreePointer := fmt.Sprintf("gitdir: %s", filepath.Join(r.forkRepoPath, "worktrees", env.ID))

	worktreePath, err := r.WorktreePath(env.ID)
	if err != nil {
		return fmt.Errorf("failed to get worktree path: %w", err)
	}

	// Start with the container's workdir and add the main .git file
	exportDir := env.Workdir().WithNewFile(".git", worktreePointer)

	exportDir, err = addSubmoduleGitdirFiles(exportDir, worktreePath, env.State.SubmodulePaths)
	if err != nil {
		return err
	}

	// Export with wipe to ensure clean state
	_, err = exportDir.Export(ctx, worktreePath, dagger.DirectoryExportOpts{Wipe: true})
	if err != nil {
		return err
	}

	return nil
}

// exportEnvironmentFile exports a single file from the environment to the worktree
func (r *Repository) exportEnvironmentFile(ctx context.Context, env *environment.Environment, filePath string) error {
	worktreePath, err := r.WorktreePath(env.ID)
	if err != nil {
		return fmt.Errorf("failed to get worktree path: %w", err)
	}

	// Get the absolute path for the file in the worktree
	absoluteFilePath := filepath.Join(worktreePath, filePath)

	// Ensure the directory exists
	if err := os.MkdirAll(filepath.Dir(absoluteFilePath), 0755); err != nil {
		return fmt.Errorf("failed to create directory for file %s: %w", filePath, err)
	}

	// Export the single file from the environment
	_, err = env.WorkdirFile(filePath).Export(ctx, absoluteFilePath)
	if err != nil {
		return fmt.Errorf("failed to export file %s: %w", filePath, err)
	}

	return nil
}

func (r *Repository) propagateGitNotes(ctx context.Context, ref string) error {
	fullRef := fmt.Sprintf("refs/notes/%s", ref)

	return r.lockManager.WithLock(ctx, LockTypeUserRepo, func() error {
		fetch := func() error {
			_, err := RunGitCommand(ctx, r.userRepoPath, "fetch", containerUseRemote, fullRef+":"+fullRef)
			return err
		}

		if err := fetch(); err != nil {
			if strings.Contains(err.Error(), "[rejected]") {
				if _, err := RunGitCommand(ctx, r.userRepoPath, "update-ref", "-d", fullRef); err == nil {
					return fetch()
				}
			}
			return err
		}
		return nil
	})
}

func (r *Repository) saveState(ctx context.Context, env *environment.Environment) error {
	state, err := env.State.Marshal()
	if err != nil {
		return err
	}
	worktreePath, err := r.WorktreePath(env.ID)
	if err != nil {
		return fmt.Errorf("failed to get worktree path: %w", err)
	}

	f, err := os.CreateTemp(os.TempDir(), ".container-use-git-notes-*")
	if err != nil {
		return err
	}
	defer f.Close()
	if _, err := f.Write(state); err != nil {
		return err
	}

	return r.lockManager.WithLock(ctx, LockTypeNotes, func() error {
		_, err = RunGitCommand(ctx, worktreePath, "notes", "--ref", gitNotesStateRef, "add", "-f", "-F", f.Name())
		return err
	})
}

func (r *Repository) loadState(ctx context.Context, worktreePath string) ([]byte, error) {
	var result []byte

	err := r.lockManager.WithRLock(ctx, LockTypeNotes, func() error {
		buff, err := RunGitCommand(ctx, worktreePath, "notes", "--ref", gitNotesStateRef, "show")
		if err != nil {
			if strings.Contains(err.Error(), "no note found") {
				result = nil
				return nil
			}
			return err
		}
		result = []byte(buff)
		return nil
	})

	return result, err
}

func (r *Repository) addGitNote(ctx context.Context, env *environment.Environment, note string) error {
	worktreePath, err := r.WorktreePath(env.ID)
	if err != nil {
		return fmt.Errorf("failed to get worktree path: %w", err)
	}
	if err := r.lockManager.WithLock(ctx, LockTypeNotes, func() error {
		_, err = RunGitCommand(ctx, worktreePath, "notes", "--ref", gitNotesLogRef, "append", "-m", note)
		return err
	}); err != nil {
		return err
	}

	return r.propagateGitNotes(ctx, gitNotesLogRef)
}

func (r *Repository) currentUserBranch(ctx context.Context) (string, error) {
	return RunGitCommand(ctx, r.userRepoPath, "branch", "--show-current")
}

func (r *Repository) mergeBase(ctx context.Context, env *environment.EnvironmentInfo) (string, error) {
	currentBranch, err := r.currentUserBranch(ctx)
	if err != nil {
		return "", err
	}
	currentBranch = strings.TrimSpace(currentBranch)
	if currentBranch == "" {
		currentBranch = "HEAD"
	}
	envGitRef := fmt.Sprintf("%s/%s", containerUseRemote, env.ID)
	mergeBase, err := RunGitCommand(ctx, r.userRepoPath, "merge-base", currentBranch, envGitRef)
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(mergeBase), nil
}

func (r *Repository) revisionRange(ctx context.Context, env *environment.EnvironmentInfo) (string, error) {
	mergeBase, err := r.mergeBase(ctx, env)
	if err != nil {
		return "", err
	}
	envGitRef := fmt.Sprintf("%s/%s", containerUseRemote, env.ID)
	return fmt.Sprintf("%s..%s", mergeBase, envGitRef), nil
}

func (r *Repository) commitWorktreeChanges(ctx context.Context, worktreePath, explanation string, submodulePaths []string) error {
	return r.lockManager.WithLock(ctx, LockTypeForkRepo, func() error {
		status, err := RunGitCommand(ctx, worktreePath, "status", "--porcelain")
		if err != nil {
			return err
		}

		if strings.TrimSpace(status) == "" {
			return nil
		}

		if err := r.addNonBinaryFiles(ctx, worktreePath, submodulePaths); err != nil {
			return err
		}

		_, err = RunGitCommand(ctx, worktreePath, "commit", "--allow-empty", "--allow-empty-message", "-m", explanation)
		return err
	})
}

// AI slop below!
// this is just to keep us moving fast because big git repos get hard to work with
// and our demos like to download large dependencies.
// getSubmodulePaths returns a slice of submodule paths relative to the worktree root
func (r *Repository) getSubmodulePaths(ctx context.Context, worktreePath string) []string {
	submodulePaths := []string{}

	// Check if .gitmodules exists
	gitmodulesPath := filepath.Join(worktreePath, ".gitmodules")
	if _, err := os.Stat(gitmodulesPath); os.IsNotExist(err) {
		return submodulePaths
	}

	// Use git submodule status to get submodule paths with correct relative paths from root
	output, err := RunGitCommand(ctx, worktreePath, "submodule", "status", "--recursive")
	if err != nil {
		// If command fails, return empty slice - don't block regular operation
		slog.Debug("Failed to get submodule paths", "error", err)
		return submodulePaths
	}

	for line := range strings.SplitSeq(strings.TrimSpace(output), "\n") {
		line = strings.TrimSpace(line)
		if line != "" {
			// Parse the submodule status line: " <commit> <path> (<description>)"
			// The path is the second field
			fields := strings.Fields(line)
			if len(fields) >= 2 {
				submodulePaths = append(submodulePaths, fields[1])
			}
		}
	}

	return submodulePaths
}

// isWithinSubmodule checks if a file path is within any of the submodule directories
func (r *Repository) isWithinSubmodule(filePath string, submodulePaths []string) bool {
	cleanFilePath := filepath.Clean(filePath)
	for _, submodulePath := range submodulePaths {
		cleanSubmodulePath := filepath.Clean(submodulePath)

		// Check if the file is exactly the submodule path or within it
		if cleanFilePath == cleanSubmodulePath {
			return true
		}

		// Check if the file is within the submodule directory
		if strings.HasPrefix(cleanFilePath, cleanSubmodulePath+string(filepath.Separator)) {
			return true
		}
	}
	return false
}

func (r *Repository) addNonBinaryFiles(ctx context.Context, worktreePath string, submodulePaths []string) error {
	statusOutput, err := RunGitCommand(ctx, worktreePath, "status", "--porcelain")
	if err != nil {
		return err
	}

	// Use cached submodule paths from environment state instead of re-detecting

	for line := range strings.SplitSeq(strings.TrimSpace(statusOutput), "\n") {
		if line == "" {
			continue
		}
		if len(line) < 3 {
			continue
		}

		indexStatus := line[0]
		workTreeStatus := line[1]
		fileName := strings.TrimSpace(line[2:])
		if fileName == "" {
			continue
		}

		if r.shouldSkipFile(fileName) {
			continue
		}

		// Skip files within submodule directories
		if r.isWithinSubmodule(fileName, submodulePaths) {
			slog.Debug("Skipping file within submodule", "file", fileName)
			continue
		}

		switch {
		case indexStatus == '?' && workTreeStatus == '?':
			// ?? = untracked files or directories
			if strings.HasSuffix(fileName, "/") {
				// Untracked directory - traverse and add non-binary files
				dirName := strings.TrimSuffix(fileName, "/")
				if err := r.addFilesFromUntrackedDirectory(ctx, worktreePath, dirName); err != nil {
					return err
				}
			} else if !r.isBinaryFile(worktreePath, fileName) {
				// Untracked file - add if not binary

				_, err = RunGitCommand(ctx, worktreePath, "add", fileName)
				if err != nil {
					return err
				}
			}
		case indexStatus == 'A':
			// A = already staged, skip
			continue
		case indexStatus == 'D' || workTreeStatus == 'D':
			// D = deleted files (always stage deletion)
			_, err = RunGitCommand(ctx, worktreePath, "add", fileName)
			if err != nil {
				return err
			}
		default:
			// M, R, C and other statuses - add if not binary
			if !r.isBinaryFile(worktreePath, fileName) {
				_, err = RunGitCommand(ctx, worktreePath, "add", fileName)
				if err != nil {
					return err
				}
			}
		}
	}

	return nil
}

func (r *Repository) shouldSkipFile(fileName string) bool {
	skipExtensions := []string{
		".tar", ".tar.gz", ".tgz", ".tar.bz2", ".tbz2", ".tar.xz", ".txz",
		".zip", ".rar", ".7z", ".gz", ".bz2", ".xz",
		".exe", ".bin", ".dmg", ".pkg", ".msi",
		".jpg", ".jpeg", ".png", ".gif", ".bmp", ".tiff", ".svg",
		".mp3", ".mp4", ".avi", ".mov", ".wmv", ".flv", ".mkv",
		".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx",
		".so", ".dylib", ".dll", ".a", ".lib",
	}

	lowerName := strings.ToLower(fileName)
	for _, ext := range skipExtensions {
		if strings.HasSuffix(lowerName, ext) {
			return true
		}
	}

	// Use cross-platform path-aware directory patterns
	skipDirNames := []string{
		"node_modules", ".git", "__pycache__", "venv", ".venv", "env", ".env",
		"target", "build", "dist", ".next",
	}

	skipFilePatterns := []string{
		".DS_Store", "*.tmp", "*.temp", "*.cache", "*.log",
	}

	// Check if the path contains any of the skip directory names
	pathParts := strings.Split(filepath.ToSlash(lowerName), "/")
	for _, part := range pathParts {
		for _, skipDir := range skipDirNames {
			if part == strings.ToLower(skipDir) {
				return true
			}
		}
	}

	// Check file patterns
	for _, pattern := range skipFilePatterns {
		if strings.Contains(lowerName, strings.ToLower(pattern)) {
			return true
		}
	}

	return false
}

func (r *Repository) IsDirty(ctx context.Context) (bool, string, error) {
	status, err := RunGitCommand(ctx, r.userRepoPath, "status", "--porcelain")
	if err != nil {
		return false, "", err
	}

	if strings.TrimSpace(status) == "" {
		return false, "", nil
	}

	return true, status, nil
}

func (r *Repository) addFilesFromUntrackedDirectory(ctx context.Context, worktreePath, dirName string) error {
	dirPath := filepath.Join(worktreePath, dirName)

	return filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		relPath, err := filepath.Rel(worktreePath, path)
		if err != nil {
			return err
		}

		if info.IsDir() {
			if r.shouldSkipFile(relPath) {
				return filepath.SkipDir
			}
			return nil
		}

		if r.shouldSkipFile(relPath) {
			return nil
		}

		if !r.isBinaryFile(worktreePath, relPath) {
			_, err = RunGitCommand(ctx, worktreePath, "add", relPath)
			if err != nil {
				return err
			}
		}

		return nil
	})
}

func (r *Repository) isBinaryFile(worktreePath, fileName string) bool {
	fullPath := filepath.Join(worktreePath, fileName)

	stat, err := os.Stat(fullPath)
	if err != nil {
		return true
	}

	if stat.IsDir() {
		return false
	}

	if stat.Size() > maxFileSizeForTextCheck {
		return true
	}

	// Empty files should be treated as text files so `touch .gitkeep` and friends work correctly
	if stat.Size() == 0 {
		return false
	}

	file, err := os.Open(fullPath)
	if err != nil {
		slog.Error("Error opening file", "err", err)
		return true
	}
	defer file.Close()

	buffer := make([]byte, 8000)
	n, err := file.Read(buffer)
	if err != nil && n == 0 {
		return true
	}

	buffer = buffer[:n]
	return slices.Contains(buffer, 0)
}

func (r *Repository) normalizeForkPath(ctx context.Context, repo string) (string, error) {
	// Check if there's an origin remote
	origin, err := RunGitCommand(ctx, repo, "remote", "get-url", "origin")
	if err != nil {
		// If not -- this repository is a local one, we're going to use the filesystem path for the container-use repo
		var exitErr *exec.ExitError
		if errors.As(err, &exitErr) && exitErr.ExitCode() == 2 {
			// Exit code 2 means the remote doesn't exist
			// Create a safe path component from the absolute repo path
			safeRepoPath := createSafePathFromAbsolute(repo)
			return homedir.Expand(filepath.Join(r.getRepoPath(), safeRepoPath))
		}
		return "", err
	}

	// Otherwise, let's use the normalized origin as path
	normalizedOrigin, err := normalizeGitURL(strings.TrimSpace(origin))
	if err != nil {
		return "", err
	}
	return homedir.Expand(filepath.Join(r.getRepoPath(), normalizedOrigin))
}

// createSafePathFromAbsolute converts an absolute path to a safe relative path component
// This handles Windows drive letters and special characters that can't be used in paths
func createSafePathFromAbsolute(absPath string) string {
	// Convert to forward slashes for consistency
	normalized := filepath.ToSlash(absPath)

	// Remove leading slash if present
	normalized = strings.TrimPrefix(normalized, "/")

	// Replace colons (from Windows drive letters) with underscores
	normalized = strings.ReplaceAll(normalized, ":", "_")

	// Replace any remaining problematic characters
	normalized = strings.ReplaceAll(normalized, "<", "_")
	normalized = strings.ReplaceAll(normalized, ">", "_")
	normalized = strings.ReplaceAll(normalized, "|", "_")
	normalized = strings.ReplaceAll(normalized, "?", "_")
	normalized = strings.ReplaceAll(normalized, "*", "_")
	normalized = strings.ReplaceAll(normalized, "\"", "_")

	return normalized
}

func normalizeGitURL(endpoint string) (string, error) {
	if e, ok := normalizeSCPLike(endpoint); ok {
		return e, nil
	}

	return normalizeURL(endpoint)
}

func normalizeURL(endpoint string) (string, error) {
	u, err := url.Parse(endpoint)
	if err != nil {
		return "", err
	}

	if !u.IsAbs() {
		return "", fmt.Errorf(
			"invalid endpoint: %s", endpoint,
		)
	}

	return fmt.Sprintf("%s%s", u.Hostname(), strings.TrimSuffix(u.Path, ".git")), nil
}

func normalizeSCPLike(endpoint string) (string, bool) {
	if matchesURLScheme(endpoint) || !matchesScpLike(endpoint) {
		return "", false
	}

	_, host, _, path := findScpLikeComponents(endpoint)

	return fmt.Sprintf("%s/%s", host, strings.TrimSuffix(path, ".git")), true
}

// matchesURLScheme returns true if the given string matches a URL-like
// format scheme.
func matchesURLScheme(url string) bool {
	return urlSchemeRegExp.MatchString(url)
}

// matchesScpLike returns true if the given string matches an SCP-like
// format scheme.
func matchesScpLike(url string) bool {
	return scpLikeURLRegExp.MatchString(url)
}

// findScpLikeComponents returns the user, host, port and path of the
// given SCP-like URL.
func findScpLikeComponents(url string) (user, host, port, path string) {
	m := scpLikeURLRegExp.FindStringSubmatch(url)
	return m[1], m[2], m[3], m[4]
}



================================================
FILE: repository/git_test.go
================================================
package repository

import (
	"context"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// Git command error handling ensures we gracefully handle git failures
func TestGitCommandErrors(t *testing.T) {
	ctx := context.Background()
	tempDir := t.TempDir()

	// Test invalid command
	_, err := RunGitCommand(ctx, tempDir, "invalid-command")
	assert.Error(t, err, "Should get error for invalid git command")

	// Test command in non-existent directory (use a cross-platform non-existent path)
	nonExistentDir := filepath.Join(tempDir, "nonexistent", "deeply", "nested")
	_, err = RunGitCommand(ctx, nonExistentDir, "status")
	assert.Error(t, err, "Should get error for non-existent directory")
}

// Selective file staging ensures problematic files are automatically excluded from commits
// This tests the actual user-facing behavior: "I want to commit my changes but not break git"
func TestSelectiveFileStaging(t *testing.T) {
	// Test real-world scenarios that users encounter
	scenarios := []struct {
		name        string
		setup       func(t *testing.T, dir string)
		shouldStage []string
		shouldSkip  []string
		reason      string
	}{
		{
			name: "python_project_with_pycache",
			setup: func(t *testing.T, dir string) {
				writeFile(t, dir, "main.py", "print('hello')")
				writeFile(t, dir, "utils.py", "def helper(): pass")
				createDir(t, dir, "__pycache__")
				writeBinaryFile(t, dir, "__pycache__/main.cpython-39.pyc", 150)
				writeBinaryFile(t, dir, "__pycache__/utils.cpython-39.pyc", 200)
			},
			shouldStage: []string{"main.py", "utils.py"},
			shouldSkip:  []string{"__pycache__"},
			reason:      "Python cache files should never be committed",
		},
		{
			name: "mixed_content_directory",
			setup: func(t *testing.T, dir string) {
				createDir(t, dir, "mydir")
				writeFile(t, dir, "mydir/readme.txt", "Documentation")
				writeBinaryFile(t, dir, "mydir/compiled.bin", 100)
				writeFile(t, dir, "mydir/script.sh", "#!/bin/bash\necho hello")
				writeBinaryFile(t, dir, "mydir/image.jpg", 5000)
			},
			shouldStage: []string{"mydir/readme.txt", "mydir/script.sh"},
			shouldSkip:  []string{"mydir/compiled.bin", "mydir/image.jpg"},
			reason:      "Binary files in directories should be automatically excluded",
		},
		{
			name: "node_modules_and_build_artifacts",
			setup: func(t *testing.T, dir string) {
				writeFile(t, dir, "index.js", "console.log('app')")
				createDir(t, dir, "node_modules/lodash")
				writeFile(t, dir, "node_modules/lodash/index.js", "module.exports = {}")
				createDir(t, dir, "build")
				writeBinaryFile(t, dir, "build/app.exe", 1024)
				writeFile(t, dir, "build/config.json", `{"prod": true}`)
			},
			shouldStage: []string{"index.js"},
			shouldSkip:  []string{"node_modules", "build"},
			reason:      "Dependencies and build outputs should be excluded",
		},
	}

	for _, scenario := range scenarios {
		t.Run(scenario.name, func(t *testing.T) {
			// Create a test git repository
			dir := t.TempDir()
			ctx := context.Background()

			// Initialize git repo
			_, err := RunGitCommand(ctx, dir, "init")
			require.NoError(t, err)

			// Set git config to avoid errors
			_, err = RunGitCommand(ctx, dir, "config", "user.email", "test@example.com")
			require.NoError(t, err)
			_, err = RunGitCommand(ctx, dir, "config", "user.name", "Test User")
			require.NoError(t, err)

			// Setup the scenario
			scenario.setup(t, dir)

			// Create a Repository instance for testing
			repo := &Repository{
				lockManager: NewRepositoryLockManager(dir),
			}

			// Run the actual staging logic (testing the integration)
			err = repo.addNonBinaryFiles(ctx, dir, []string{})
			require.NoError(t, err, "Staging should not error")

			status, err := RunGitCommand(ctx, dir, "status", "--porcelain")
			require.NoError(t, err)

			// Verify expected behavior
			for _, file := range scenario.shouldStage {
				// Files should be staged (A  prefix)
				assert.Contains(t, status, "A  "+file, "%s should be staged - %s", file, scenario.reason)
			}

			for _, pattern := range scenario.shouldSkip {
				// Files should remain untracked (?? prefix), not staged (A  prefix)
				assert.NotContains(t, status, "A  "+pattern, "%s should not be staged - %s", pattern, scenario.reason)
				// They should appear as untracked
				if !strings.Contains(pattern, "/") {
					assert.Contains(t, status, "?? "+pattern, "%s should remain untracked - %s", pattern, scenario.reason)
				}
			}
		})
	}
}

// Test the commitWorktreeChanges function
func TestCommitWorktreeChanges(t *testing.T) {
	ctx := context.Background()
	dir := t.TempDir()

	// Initialize git repo
	_, err := RunGitCommand(ctx, dir, "init")
	require.NoError(t, err)

	// Set git config
	_, err = RunGitCommand(ctx, dir, "config", "user.email", "test@example.com")
	require.NoError(t, err)
	_, err = RunGitCommand(ctx, dir, "config", "user.name", "Test User")
	require.NoError(t, err)

	repo := &Repository{
		lockManager: NewRepositoryLockManager(dir),
	}

	t.Run("empty_directory_handling", func(t *testing.T) {
		// Create empty directories (git doesn't track these)
		createDir(t, dir, "empty1")
		createDir(t, dir, "empty2/nested")

		// This verifies that commitWorktreeChanges handles empty directories gracefully
		// It should return nil (success) when there's nothing to commit
		err := repo.commitWorktreeChanges(ctx, dir, "Empty dirs", []string{})
		assert.NoError(t, err, "commitWorktreeChanges should handle empty dirs gracefully")
	})

	t.Run("commits_changes", func(t *testing.T) {
		// Create a file to commit
		writeFile(t, dir, "test.txt", "hello world")

		err := repo.commitWorktreeChanges(ctx, dir, "Testing commit functionality", []string{})
		require.NoError(t, err)

		// Verify commit was created
		log, err := RunGitCommand(ctx, dir, "log", "--oneline")
		require.NoError(t, err)
		assert.Contains(t, log, "Testing commit functionality")
	})
}

// Test helper functions
func writeFile(t *testing.T, dir, name, content string) {
	t.Helper()
	path := filepath.Join(dir, name)
	os.MkdirAll(filepath.Dir(path), 0755)
	err := os.WriteFile(path, []byte(content), 0644)
	require.NoError(t, err)
}

func writeBinaryFile(t *testing.T, dir, name string, size int) {
	t.Helper()
	path := filepath.Join(dir, name)
	os.MkdirAll(filepath.Dir(path), 0755)

	// Create binary content
	data := make([]byte, size)
	for i := range data {
		data[i] = byte(i % 256)
	}

	err := os.WriteFile(path, data, 0644)
	require.NoError(t, err)
}

func createDir(t *testing.T, dir, name string) {
	t.Helper()
	path := filepath.Join(dir, name)
	err := os.MkdirAll(path, 0755)
	require.NoError(t, err)
}



================================================
FILE: repository/repository.go
================================================
package repository

import (
	"context"
	"errors"
	"fmt"
	"io"
	"log/slog"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"sort"
	"strings"
	"sync"

	"dagger.io/dagger"
	"github.com/dagger/container-use/environment"
	petname "github.com/dustinkirkland/golang-petname"
	"github.com/mitchellh/go-homedir"
	"golang.org/x/sync/errgroup"
)

const (
	containerUseRemote = "container-use"
	gitNotesLogRef     = "container-use"
	gitNotesStateRef   = "container-use-state"
)

// getDefaultConfigPath returns the default configuration path for the current OS
func getDefaultConfigPath() string {
	if runtime.GOOS == "windows" {
		// On Windows, use APPDATA or LOCALAPPDATA
		if appData := os.Getenv("APPDATA"); appData != "" {
			return filepath.Join(appData, "container-use")
		}
		if localAppData := os.Getenv("LOCALAPPDATA"); localAppData != "" {
			return filepath.Join(localAppData, "container-use")
		}
		// Fallback to home directory
		if home, err := homedir.Dir(); err == nil {
			return filepath.Join(home, "AppData", "Roaming", "container-use")
		}
		return "container-use" // Last resort fallback
	}
	// On Unix-like systems (Linux, macOS, etc.)
	if home, err := homedir.Dir(); err == nil {
		return filepath.Join(home, ".config", "container-use")
	}
	return "~/.config/container-use" // Fallback for compatibility
}

var (
	cuGlobalConfigPath = getDefaultConfigPath()
)

type Repository struct {
	userRepoPath string
	forkRepoPath string
	basePath     string // defaults to OS-appropriate config path if empty
	lockManager  *RepositoryLockManager
}

// getRepoPath returns the path for storing repository data
func (r *Repository) getRepoPath() string {
	return filepath.Join(r.basePath, "repos")
}

// getWorktreePath returns the path for storing worktrees
func (r *Repository) getWorktreePath() string {
	return filepath.Join(r.basePath, "worktrees")
}

func Open(ctx context.Context, repo string) (*Repository, error) {
	return OpenWithBasePath(ctx, repo, cuGlobalConfigPath)
}

// OpenWithBasePath opens a repository with a custom base path for container-use data.
// This is useful for tests that need isolated environments.
func OpenWithBasePath(ctx context.Context, repo string, basePath string) (*Repository, error) {
	// Expand tilde in basePath for cross-platform compatibility
	expandedBasePath, err := homedir.Expand(basePath)
	if err != nil {
		// If expansion fails, use the original path
		expandedBasePath = basePath
	}

	output, err := RunGitCommand(ctx, repo, "rev-parse", "--show-toplevel")
	if err != nil {
		// Check for exit code 128 which means not a git repository
		var exitErr *exec.ExitError
		if errors.As(err, &exitErr) && exitErr.ExitCode() == 128 {
			return nil, errors.New("you must be in a git repository to use container-use")
		}
		return nil, err
	}
	userRepoPath := strings.TrimSpace(output)

	forkRepoPath, err := getContainerUseRemote(ctx, userRepoPath)
	if err != nil {
		if !errors.Is(err, os.ErrNotExist) {
			return nil, err
		}
		// Create a temporary repository to get the normalized fork path
		tempRepo := &Repository{basePath: expandedBasePath}
		forkRepoPath, err = tempRepo.normalizeForkPath(ctx, userRepoPath)
		if err != nil {
			return nil, err
		}
	}

	r := &Repository{
		userRepoPath: userRepoPath,
		forkRepoPath: forkRepoPath,
		basePath:     expandedBasePath,
		lockManager:  NewRepositoryLockManager(userRepoPath),
	}

	if err := r.ensureFork(ctx); err != nil {
		return nil, fmt.Errorf("unable to fork the repository: %w", err)
	}
	if err := r.ensureUserRemote(ctx); err != nil {
		return nil, fmt.Errorf("unable to set container-use remote: %w", err)
	}

	return r, nil
}

func (r *Repository) ensureFork(ctx context.Context) error {
	return r.lockManager.WithLock(ctx, LockTypeForkRepo, func() error {
		if _, err := os.Stat(r.forkRepoPath); err == nil {
			return nil
		} else if !os.IsNotExist(err) {
			return err
		}

		slog.Info("Initializing local remote", "user-repo", r.userRepoPath, "fork-repo", r.forkRepoPath)
		if err := os.MkdirAll(r.forkRepoPath, 0755); err != nil {
			return err
		}
		_, err := RunGitCommand(ctx, r.forkRepoPath, "init", "--bare", "--template=")
		if err != nil {
			os.RemoveAll(r.forkRepoPath)
			return err
		}
		return nil
	})
}

func (r *Repository) ensureUserRemote(ctx context.Context) error {
	return r.lockManager.WithLock(ctx, LockTypeUserRepo, func() error {
		currentForkPath, err := getContainerUseRemote(ctx, r.userRepoPath)
		if err != nil {
			if !errors.Is(err, os.ErrNotExist) {
				return err
			}
			_, err := RunGitCommand(ctx, r.userRepoPath, "remote", "add", containerUseRemote, r.forkRepoPath)
			return err
		}

		if currentForkPath != r.forkRepoPath {
			_, err := RunGitCommand(ctx, r.userRepoPath, "remote", "set-url", containerUseRemote, r.forkRepoPath)
			return err
		}

		return nil
	})
}

func (r *Repository) SourcePath() string {
	return r.userRepoPath
}

func (r *Repository) exists(ctx context.Context, id string) error {
	if _, err := RunGitCommand(ctx, r.forkRepoPath, "rev-parse", "--verify", id); err != nil {
		if strings.Contains(err.Error(), "Needed a single revision") {
			return fmt.Errorf("environment %q not found", id)
		}
		return err
	}
	return nil
}

// Create creates a new environment with the given description, explanation, and optional git reference.
// The git reference can be HEAD (default), a SHA, a branch name, or a tag.
// Requires a dagger client for container operations during environment initialization.
func (r *Repository) Create(ctx context.Context, dag *dagger.Client, description, explanation, gitRef string) (*environment.Environment, error) {
	if gitRef == "" {
		gitRef = "HEAD"
	}
	id := petname.Generate(2, "-")
	worktree, submoduleWarning, err := r.initializeWorktree(ctx, id, gitRef)
	if err != nil {
		return nil, err
	}

	// Protect createInitialCommit to prevent concurrent writes to .git/worktrees/*/logs/HEAD
	if err := r.lockManager.WithLock(ctx, LockTypeForkRepo, func() error {
		return r.createInitialCommit(ctx, worktree, id, description)
	}); err != nil {
		return nil, fmt.Errorf("failed to create initial commit: %w", err)
	}

	worktreeHead, err := RunGitCommand(ctx, worktree, "rev-parse", "HEAD")
	if err != nil {
		return nil, err
	}
	worktreeHead = strings.TrimSpace(worktreeHead)

	var baseSourceDir *dagger.Directory
	err = r.lockManager.WithRLock(ctx, LockTypeForkRepo, func() error {
		var err error
		baseSourceDir, err = dag.
			Host().
			Directory(r.forkRepoPath, dagger.HostDirectoryOpts{NoCache: true}). // bust cache for each Create call
			AsGit().
			Ref(worktreeHead).
			Tree(dagger.GitRefTreeOpts{DiscardGitDir: true}).
			Sync(ctx) // don't bust cache when loading from state

		return err
	})
	if err != nil {
		return nil, fmt.Errorf("failed loading initial source directory: %w", err)
	}

	config := environment.DefaultConfig()
	if err := config.Load(r.userRepoPath); err != nil {
		return nil, err
	}

	// Detect submodules from the host worktree before creating the environment
	submodulePaths := r.getSubmodulePaths(ctx, worktree)

	env, err := environment.New(ctx, environment.NewEnvArgs{
		Dag:              dag,
		ID:               id,
		Title:            description,
		Config:           config,
		InitialSourceDir: baseSourceDir,
		SubmodulePaths:   submodulePaths,
	})
	if err != nil {
		return nil, err
	}

	// Add submodule warning to environment notes if initialization failed
	if submoduleWarning != "" {
		env.Notes.Add("Warning: %s", submoduleWarning)
	}

	if err := r.propagateToWorktree(ctx, env, explanation); err != nil {
		return nil, err
	}

	return env, nil
}

// Get retrieves a full Environment with dagger client embedded for container operations.
// Use this when you need to perform container operations like running commands, terminals, etc.
// For basic metadata access without container operations, use Info() instead.
func (r *Repository) Get(ctx context.Context, dag *dagger.Client, id string) (*environment.Environment, error) {
	if err := r.exists(ctx, id); err != nil {
		return nil, err
	}

	worktree, err := r.getWorktree(ctx, id)
	if err != nil {
		return nil, err
	}

	state, err := r.loadState(ctx, worktree)
	if err != nil {
		return nil, err
	}

	env, err := environment.Load(ctx, dag, id, state, worktree)
	if err != nil {
		return nil, err
	}

	return env, nil
}

// Info retrieves environment metadata without requiring dagger operations.
// This is more efficient than Get() when you only need access to configuration,
// state, and other metadata without performing container operations.
func (r *Repository) Info(ctx context.Context, id string) (*environment.EnvironmentInfo, error) {
	if err := r.exists(ctx, id); err != nil {
		return nil, err
	}

	worktree, err := r.getWorktree(ctx, id)
	if err != nil {
		return nil, err
	}

	state, err := r.loadState(ctx, worktree)
	if err != nil {
		return nil, err
	}

	envInfo, err := environment.LoadInfo(ctx, id, state, worktree)
	if err != nil {
		return nil, err
	}

	return envInfo, nil
}

// List returns information about all environments in the repository.
// Returns EnvironmentInfo slice avoiding dagger client initialization.
// Use Get() on individual environments when you need full Environment with container operations.
func (r *Repository) List(ctx context.Context) ([]*environment.EnvironmentInfo, error) {
	branches, err := RunGitCommand(ctx, r.forkRepoPath, "branch", "--format", "%(refname:short)")
	if err != nil {
		return nil, err
	}

	branchList := []string{}
	for branch := range strings.SplitSeq(branches, "\n") {
		branch = strings.TrimSpace(branch)
		if branch != "" {
			branchList = append(branchList, branch)
		}
	}

	// Use a worker pool for parallel processing
	maxWorkers := min(8, runtime.NumCPU(), len(branchList))

	if len(branchList) == 0 {
		return []*environment.EnvironmentInfo{}, nil
	}

	// Channel for sending work to workers
	branchChan := make(chan string, len(branchList))

	// Slice to collect results with mutex protection
	var envs []*environment.EnvironmentInfo
	var envsMutex sync.Mutex

	// Error group to manage goroutines and collect errors
	g, ctx := errgroup.WithContext(ctx)

	// Start worker goroutines
	for range maxWorkers {
		g.Go(func() error {
			for branch := range branchChan {
				// Check if context was cancelled
				if ctx.Err() != nil {
					return ctx.Err()
				}

				// note:  we used to do a loadState here to validate that branch contains an environment.
				// r.Info does the exact same process, so instead we rely on its errors to determine if the branch is an env.
				// we always need the full info here, even if it looks like we just use the ID, because we need it to sort the IDs by updated_at.
				envInfo, err := r.Info(ctx, branch)
				if err != nil {
					// Skip branches where we can't load info
					continue
				}

				// Thread-safe append to results
				envsMutex.Lock()
				envs = append(envs, envInfo)
				envsMutex.Unlock()
			}
			return nil
		})
	}

	// Send all branches to workers
	for _, branch := range branchList {
		branchChan <- branch
	}
	close(branchChan)

	// Wait for all workers to complete
	err = g.Wait()
	if err != nil {
		return nil, err
	}

	// Sort by most recently updated environments first
	sort.Slice(envs, func(i, j int) bool {
		return envs[i].State.UpdatedAt.After(envs[j].State.UpdatedAt)
	})

	return envs, nil
}

// ListDescendantEnvironments returns environments that are descendants of the given commit.
// This filters environments to only those where the provided commit is an ancestor
// of the environment's current HEAD. Environments are sorted by most recently updated first.
func (r *Repository) ListDescendantEnvironments(ctx context.Context, ancestorCommit string) ([]*environment.EnvironmentInfo, error) {
	allEnvs, err := r.List(ctx)
	if err != nil {
		return nil, err
	}

	var filteredEnvs []*environment.EnvironmentInfo
	for _, env := range allEnvs {
		if r.isDescendantOfCommit(ctx, ancestorCommit, env.ID) {
			filteredEnvs = append(filteredEnvs, env)
		}
	}

	return filteredEnvs, nil
}

// isDescendantOfCommit checks if the environment is a descendant of the given commit
// using git merge-base --is-ancestor which is the canonical way to check ancestry
func (r *Repository) isDescendantOfCommit(ctx context.Context, ancestorCommit, envID string) bool {
	envRef := fmt.Sprintf("container-use/%s", envID)

	// Use git merge-base --is-ancestor to check if ancestorCommit is an ancestor of envRef
	// This returns exit code 0 if ancestorCommit is an ancestor of envRef
	_, err := RunGitCommand(ctx, r.userRepoPath, "merge-base", "--is-ancestor", ancestorCommit, envRef)

	return err == nil
}

// Update saves the provided environment to the repository.
// Writes configuration and source code changes to the worktree and history + state to git notes.
func (r *Repository) Update(ctx context.Context, env *environment.Environment, explanation string) error {
	return r.propagateToWorktree(ctx, env, explanation)
}

// UpdateFile saves only the specified file from the environment to the repository.
// This is more efficient than Update() for single file operations as it only exports
// and commits the specified file instead of the entire directory.
func (r *Repository) UpdateFile(ctx context.Context, env *environment.Environment, filePath, explanation string) error {
	return r.propagateFileToWorktree(ctx, env, filePath, explanation)
}

// Delete removes an environment from the repository.
func (r *Repository) Delete(ctx context.Context, id string) error {
	if err := r.exists(ctx, id); err != nil {
		return err
	}

	if err := r.deleteWorktree(id); err != nil {
		return err
	}
	if err := r.deleteLocalRemoteBranch(id); err != nil {
		return err
	}
	return nil
}

// Checkout changes the user's current branch to that of the identified environment.
// It attempts to get the most recent commit from the environment without discarding any user changes.
func (r *Repository) Checkout(ctx context.Context, id, branch string) (string, error) {
	if err := r.exists(ctx, id); err != nil {
		return "", err
	}

	if branch == "" {
		branch = "cu-" + id
	}

	// set up remote tracking branch if it's not already there
	_, err := RunGitCommand(ctx, r.userRepoPath, "show-ref", "--verify", "--quiet", fmt.Sprintf("refs/heads/%s", branch))
	localBranchExists := err == nil
	if !localBranchExists {
		_, err = RunGitCommand(ctx, r.userRepoPath, "branch", "--track", branch, fmt.Sprintf("%s/%s", containerUseRemote, id))
		if err != nil {
			return "", err
		}
	}

	_, err = RunGitCommand(ctx, r.userRepoPath, "checkout", branch)
	if err != nil {
		return "", err
	}

	if localBranchExists {
		remoteRef := fmt.Sprintf("%s/%s", containerUseRemote, id)

		counts, err := RunGitCommand(ctx, r.userRepoPath, "rev-list", "--left-right", "--count", fmt.Sprintf("HEAD...%s", remoteRef))
		if err != nil {
			return branch, err
		}

		parts := strings.Split(strings.TrimSpace(counts), "\t")
		if len(parts) != 2 {
			return branch, fmt.Errorf("unexpected git rev-list output: %s", counts)
		}
		aheadCount, behindCount := parts[0], parts[1]

		if behindCount != "0" && aheadCount == "0" {
			_, err = RunGitCommand(ctx, r.userRepoPath, "merge", "--ff-only", remoteRef)
			if err != nil {
				return branch, err
			}
		} else if behindCount != "0" {
			return branch, fmt.Errorf("switched to %s, but %s is %s ahead and container-use/ remote has %s additional commits", branch, branch, aheadCount, behindCount)
		}
	}

	return branch, err
}

func (r *Repository) Log(ctx context.Context, id string, patch bool, w io.Writer) error {
	envInfo, err := r.Info(ctx, id)
	if err != nil {
		return err
	}

	logArgs := []string{
		"log",
		fmt.Sprintf("--notes=%s", gitNotesLogRef),
	}

	if patch {
		logArgs = append(logArgs, "--patch")
	} else {
		logArgs = append(logArgs, "--format=%C(yellow)%h%Creset  %s %Cgreen(%cr)%Creset %+N")
	}

	revisionRange, err := r.revisionRange(ctx, envInfo)
	if err != nil {
		return err
	}

	logArgs = append(logArgs, revisionRange)

	return RunInteractiveGitCommand(ctx, r.userRepoPath, w, logArgs...)
}

func (r *Repository) Diff(ctx context.Context, id string, w io.Writer) error {
	envInfo, err := r.Info(ctx, id)
	if err != nil {
		return err
	}

	diffArgs := []string{
		"diff",
	}

	revisionRange, err := r.revisionRange(ctx, envInfo)
	if err != nil {
		return err
	}

	diffArgs = append(diffArgs, revisionRange)

	return RunInteractiveGitCommand(ctx, r.userRepoPath, w, diffArgs...)
}

func (r *Repository) Merge(ctx context.Context, id string, w io.Writer) error {
	envInfo, err := r.Info(ctx, id)
	if err != nil {
		return err
	}

	return RunInteractiveGitCommand(ctx, r.userRepoPath, w, "merge", "--no-ff", "--autostash", "-m", "Merge environment "+envInfo.ID, "--", "container-use/"+envInfo.ID)
}

func (r *Repository) Apply(ctx context.Context, id string, w io.Writer) error {
	envInfo, err := r.Info(ctx, id)
	if err != nil {
		return err
	}

	return RunInteractiveGitCommand(ctx, r.userRepoPath, w, "merge", "--autostash", "--squash", "--", "container-use/"+envInfo.ID)
}



================================================
FILE: repository/repository_test.go
================================================
package repository

import (
	"context"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestRepositoryOpen tests the Open function which initializes a Repository
func TestRepositoryOpen(t *testing.T) {
	ctx := context.Background()

	t.Run("not_a_git_repository", func(t *testing.T) {
		tempDir := t.TempDir()
		_, err := Open(ctx, tempDir)
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "you must be in a git repository")
	})

	t.Run("valid_git_repository", func(t *testing.T) {
		tempDir := t.TempDir()
		configDir := t.TempDir() // Separate dir for container-use config

		// Initialize a git repo
		_, err := RunGitCommand(ctx, tempDir, "init")
		require.NoError(t, err)

		// Set git config
		_, err = RunGitCommand(ctx, tempDir, "config", "user.email", "test@example.com")
		require.NoError(t, err)
		_, err = RunGitCommand(ctx, tempDir, "config", "user.name", "Test User")
		require.NoError(t, err)

		// Make initial commit
		testFile := filepath.Join(tempDir, "README.md")
		err = os.WriteFile(testFile, []byte("# Test"), 0644)
		require.NoError(t, err)

		_, err = RunGitCommand(ctx, tempDir, "add", ".")
		require.NoError(t, err)
		_, err = RunGitCommand(ctx, tempDir, "commit", "-m", "Initial commit")
		require.NoError(t, err)

		// Open repository with isolated base path
		repo, err := OpenWithBasePath(ctx, tempDir, configDir)
		require.NoError(t, err)
		assert.NotNil(t, repo)
		// Git resolves symlinks, so repo.userRepoPath will be the canonical path
		// This is correct behavior - we should store what git reports
		assert.NotEmpty(t, repo.userRepoPath)
		assert.DirExists(t, repo.userRepoPath)
		assert.NotEmpty(t, repo.forkRepoPath)

		// Verify fork was created
		_, err = os.Stat(repo.forkRepoPath)
		assert.NoError(t, err)

		// Verify remote was added
		remote, err := RunGitCommand(ctx, tempDir, "remote", "get-url", "container-use")
		require.NoError(t, err)
		assert.Equal(t, repo.forkRepoPath, strings.TrimSpace(remote))
	})
}



================================================
FILE: rules/agent.md
================================================
ALWAYS use ONLY Environments for ANY and ALL file, code, or shell operations‚ÄîNO EXCEPTIONS‚Äîeven for simple or generic requests.

DO NOT install or use the git cli with the environment_run_cmd tool. All environment tools will handle git operations for you. Changing ".git" yourself will compromise the integrity of your environment.

You MUST inform the user how to view your work using `container-use log <env_id>` AND `container-use checkout <env_id>`. Failure to do this will make your work inaccessible to others.



================================================
FILE: rules/cursor.mdc
================================================
---
description: "Container-use rules for safe containerized development"
globs:
alwaysApply: true
---

ALWAYS use ONLY Environments for ANY and ALL file, code, or shell operations‚ÄîNO EXCEPTIONS‚Äîeven for simple or generic requests.

DO NOT install or use the git cli with the environment_run_cmd tool. All environment tools will handle git operations for you. Changing ".git" yourself will compromise the integrity of your environment.

You MUST inform the user how to view your work using `container-use log <env_id>` and `container-use checkout <env_id>`. Failure to do this will make your work inaccessible to others.



================================================
FILE: rules/rules.go
================================================
package rules

import _ "embed"

//go:embed agent.md
var AgentRules string

//go:embed cursor.mdc
var CursorRules string



================================================
FILE: rules/windsurf.mdc
================================================
---
trigger: always_on
---

ALWAYS use ONLY Environments for ANY and ALL file, code, or shell operations‚ÄîNO EXCEPTIONS‚Äîeven for simple or generic requests.

DO NOT install or use the git cli with the environment_run_cmd tool. All environment tools will handle git operations for you. Changing ".git" yourself will compromise the integrity of your environment.

You MUST inform the user how to view your work using `container-use log <env_id>` and `container-use checkout <env_id>`. Failure to do this will make your work inaccessible to others.



================================================
FILE: scripts/completions.sh
================================================
#!/bin/sh
set -e
rm -rf completions
mkdir completions

for sh in bash zsh fish; do
	go run ./cmd/container-use completion "$sh" >"completions/container-use.$sh"
	go run ./cmd/container-use completion --command-name=cu "$sh" >"completions/cu.$sh"
done



================================================
FILE: scripts/man.sh
================================================
#!/bin/sh
set -e
rm -rf man
mkdir man
go run ./cmd/container-use man > "man/container-use.1"



================================================
FILE: .container-use/environment.json
================================================
{
  "workdir": "/workdir",
  "base_image": "golang:1.24-bookworm",
  "setup_commands": [
    "apt-get update && apt-get install -y curl git build-essential jq",
    "curl -fsSL https://get.docker.com | sh",
    "cd /tmp && curl -L https://dl.dagger.io/dagger/install.sh | DAGGER_VERSION=v0.18.16 sh && cp ./bin/dagger /usr/local/bin/dagger",
    "git config --global user.name \"Test User\"",
    "git config --global user.email \"test@dagger.com\"",
    "curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b /usr/local/bin v1.64.8",
    "curl -fsSL https://deb.nodesource.com/setup_22.x | bash -",
    "apt-get install -y nodejs",
    "npm i -g mint"
  ]
}



================================================
FILE: .dagger/go.mod
================================================
module dagger/container-use

go 1.24.3

require (
	github.com/99designs/gqlgen v0.17.78
	github.com/Khan/genqlient v0.8.1
	github.com/vektah/gqlparser/v2 v2.5.30
	go.opentelemetry.io/otel v1.37.0
	go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2
	go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2
	go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.37.0
	go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.37.0
	go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.37.0
	go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.37.0
	go.opentelemetry.io/otel/log v0.12.2
	go.opentelemetry.io/otel/metric v1.37.0
	go.opentelemetry.io/otel/sdk v1.37.0
	go.opentelemetry.io/otel/sdk/log v0.12.2
	go.opentelemetry.io/otel/sdk/metric v1.37.0
	go.opentelemetry.io/otel/trace v1.37.0
	go.opentelemetry.io/proto/otlp v1.7.1
	golang.org/x/sync v0.16.0
	google.golang.org/grpc v1.74.2
)

require (
	github.com/cenkalti/backoff/v5 v5.0.2 // indirect
	github.com/go-logr/logr v1.4.3 // indirect
	github.com/go-logr/stdr v1.2.2 // indirect
	github.com/google/uuid v1.6.0 // indirect
	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.1 // indirect
	github.com/sosodev/duration v1.3.1 // indirect
	go.opentelemetry.io/auto/sdk v1.1.0 // indirect
	go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.37.0 // indirect
	golang.org/x/net v0.42.0 // indirect
	golang.org/x/sys v0.34.0 // indirect
	golang.org/x/text v0.27.0 // indirect
	google.golang.org/genproto/googleapis/api v0.0.0-20250728155136-f173205681a0 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20250728155136-f173205681a0 // indirect
	google.golang.org/protobuf v1.36.6 // indirect
)

replace go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc => go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2

replace go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp => go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2

replace go.opentelemetry.io/otel/log => go.opentelemetry.io/otel/log v0.12.2

replace go.opentelemetry.io/otel/sdk/log => go.opentelemetry.io/otel/sdk/log v0.12.2



================================================
FILE: .dagger/go.sum
================================================
github.com/99designs/gqlgen v0.17.78 h1:bhIi7ynrc3js2O8wu1sMQj1YHPENDt3jQGyifoBvoVI=
github.com/99designs/gqlgen v0.17.78/go.mod h1:yI/o31IauG2kX0IsskM4R894OCCG1jXJORhtLQqB7Oc=
github.com/Khan/genqlient v0.8.1 h1:wtOCc8N9rNynRLXN3k3CnfzheCUNKBcvXmVv5zt6WCs=
github.com/Khan/genqlient v0.8.1/go.mod h1:R2G6DzjBvCbhjsEajfRjbWdVglSH/73kSivC9TLWVjU=
github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883 h1:bvNMNQO63//z+xNgfBlViaCIJKLlCJ6/fmUseuG0wVQ=
github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883/go.mod h1:rCTlJbsFo29Kk6CurOXKm700vrz8f0KW0JNfpkRJY/8=
github.com/cenkalti/backoff/v5 v5.0.2 h1:rIfFVxEf1QsI7E1ZHfp/B4DF/6QBAUhmgkxc0H7Zss8=
github.com/cenkalti/backoff/v5 v5.0.2/go.mod h1:rkhZdG3JZukswDf7f0cwqPNk4K0sa+F97BxZthm/crw=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=
github.com/go-logr/logr v1.4.3 h1:CjnDlHq8ikf6E492q6eKboGOC0T8CDaOvkHCIg8idEI=
github.com/go-logr/logr v1.4.3/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=
github.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=
github.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=
github.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=
github.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=
github.com/google/go-cmp v0.7.0 h1:wk8382ETsv4JYUZwIsn6YpYiWiBsYLSJiTsyBybVuN8=
github.com/google/go-cmp v0.7.0/go.mod h1:pXiqmnSA92OHEEa9HXL2W4E7lf9JzCmGVUdgjX3N/iU=
github.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=
github.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.1 h1:X5VWvz21y3gzm9Nw/kaUeku/1+uBhcekkmy4IkffJww=
github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.1/go.mod h1:Zanoh4+gvIgluNqcfMVTJueD4wSS5hT7zTt4Mrutd90=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/sergi/go-diff v1.3.1 h1:xkr+Oxo4BOQKmkn/B9eMK0g5Kg/983T9DqqPHwYqD+8=
github.com/sergi/go-diff v1.3.1/go.mod h1:aMJSSKb2lpPvRNec0+w3fl7LP9IOFzdc9Pa4NFbPK1I=
github.com/sosodev/duration v1.3.1 h1:qtHBDMQ6lvMQsL15g4aopM4HEfOaYuhWBw3NPTtlqq4=
github.com/sosodev/duration v1.3.1/go.mod h1:RQIBBX0+fMLc/D9+Jb/fwvVmo0eZvDDEERAikUR6SDg=
github.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=
github.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=
github.com/vektah/gqlparser/v2 v2.5.30 h1:EqLwGAFLIzt1wpx1IPpY67DwUujF1OfzgEyDsLrN6kE=
github.com/vektah/gqlparser/v2 v2.5.30/go.mod h1:D1/VCZtV3LPnQrcPBeR/q5jkSQIPti0uYCP/RI0gIeo=
go.opentelemetry.io/auto/sdk v1.1.0 h1:cH53jehLUN6UFLY71z+NDOiNJqDdPRaXzTel0sJySYA=
go.opentelemetry.io/auto/sdk v1.1.0/go.mod h1:3wSPjt5PWp2RhlCcmmOial7AvC4DQqZb7a7wCow3W8A=
go.opentelemetry.io/otel v1.37.0 h1:9zhNfelUvx0KBfu/gb+ZgeAfAgtWrfHJZcAqFC228wQ=
go.opentelemetry.io/otel v1.37.0/go.mod h1:ehE/umFRLnuLa/vSccNq9oS1ErUlkkK71gMcN34UG8I=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2 h1:06ZeJRe5BnYXceSM9Vya83XXVaNGe3H1QqsvqRANQq8=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc v0.12.2/go.mod h1:DvPtKE63knkDVP88qpatBj81JxN+w1bqfVbsbCbj1WY=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2 h1:tPLwQlXbJ8NSOfZc4OkgU5h2A38M4c9kfHSVc4PFQGs=
go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp v0.12.2/go.mod h1:QTnxBwT/1rBIgAG1goq6xMydfYOBKU6KTiYF4fp5zL8=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.37.0 h1:zG8GlgXCJQd5BU98C0hZnBbElszTmUgCNCfYneaDL0A=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc v1.37.0/go.mod h1:hOfBCz8kv/wuq73Mx2H2QnWokh/kHZxkh6SNF2bdKtw=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.37.0 h1:9PgnL3QNlj10uGxExowIDIZu66aVBwWhXmbOp1pa6RA=
go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetrichttp v1.37.0/go.mod h1:0ineDcLELf6JmKfuo0wvvhAVMuxWFYvkTin2iV4ydPQ=
go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.37.0 h1:Ahq7pZmv87yiyn3jeFz/LekZmPLLdKejuO3NcK9MssM=
go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.37.0/go.mod h1:MJTqhM0im3mRLw1i8uGHnCvUEeS7VwRyxlLC78PA18M=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.37.0 h1:EtFWSnwW9hGObjkIdmlnWSydO+Qs8OwzfzXLUPg4xOc=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.37.0/go.mod h1:QjUEoiGCPkvFZ/MjK6ZZfNOS6mfVEVKYE99dFhuN2LI=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.37.0 h1:bDMKF3RUSxshZ5OjOTi8rsHGaPKsAt76FaqgvIUySLc=
go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.37.0/go.mod h1:dDT67G/IkA46Mr2l9Uj7HsQVwsjASyV9SjGofsiUZDA=
go.opentelemetry.io/otel/log v0.12.2 h1:yob9JVHn2ZY24byZeaXpTVoPS6l+UrrxmxmPKohXTwc=
go.opentelemetry.io/otel/log v0.12.2/go.mod h1:ShIItIxSYxufUMt+1H5a2wbckGli3/iCfuEbVZi/98E=
go.opentelemetry.io/otel/metric v1.37.0 h1:mvwbQS5m0tbmqML4NqK+e3aDiO02vsf/WgbsdpcPoZE=
go.opentelemetry.io/otel/metric v1.37.0/go.mod h1:04wGrZurHYKOc+RKeye86GwKiTb9FKm1WHtO+4EVr2E=
go.opentelemetry.io/otel/sdk v1.37.0 h1:ItB0QUqnjesGRvNcmAcU0LyvkVyGJ2xftD29bWdDvKI=
go.opentelemetry.io/otel/sdk v1.37.0/go.mod h1:VredYzxUvuo2q3WRcDnKDjbdvmO0sCzOvVAiY+yUkAg=
go.opentelemetry.io/otel/sdk/log v0.12.2 h1:yNoETvTByVKi7wHvYS6HMcZrN5hFLD7I++1xIZ/k6W0=
go.opentelemetry.io/otel/sdk/log v0.12.2/go.mod h1:DcpdmUXHJgSqN/dh+XMWa7Vf89u9ap0/AAk/XGLnEzY=
go.opentelemetry.io/otel/sdk/log/logtest v0.0.0-20250521073539-a85ae98dcedc h1:uqxdywfHqqCl6LmZzI3pUnXT1RGFYyUgxj0AkWPFxi0=
go.opentelemetry.io/otel/sdk/log/logtest v0.0.0-20250521073539-a85ae98dcedc/go.mod h1:TY/N/FT7dmFrP/r5ym3g0yysP1DefqGpAZr4f82P0dE=
go.opentelemetry.io/otel/sdk/metric v1.37.0 h1:90lI228XrB9jCMuSdA0673aubgRobVZFhbjxHHspCPc=
go.opentelemetry.io/otel/sdk/metric v1.37.0/go.mod h1:cNen4ZWfiD37l5NhS+Keb5RXVWZWpRE+9WyVCpbo5ps=
go.opentelemetry.io/otel/trace v1.37.0 h1:HLdcFNbRQBE2imdSEgm/kwqmQj1Or1l/7bW6mxVK7z4=
go.opentelemetry.io/otel/trace v1.37.0/go.mod h1:TlgrlQ+PtQO5XFerSPUYG0JSgGyryXewPGyayAWSBS0=
go.opentelemetry.io/proto/otlp v1.7.1 h1:gTOMpGDb0WTBOP8JaO72iL3auEZhVmAQg4ipjOVAtj4=
go.opentelemetry.io/proto/otlp v1.7.1/go.mod h1:b2rVh6rfI/s2pHWNlB7ILJcRALpcNDzKhACevjI+ZnE=
go.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=
go.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=
golang.org/x/net v0.42.0 h1:jzkYrhi3YQWD6MLBJcsklgQsoAcw89EcZbJw8Z614hs=
golang.org/x/net v0.42.0/go.mod h1:FF1RA5d3u7nAYA4z2TkclSCKh68eSXtiFwcWQpPXdt8=
golang.org/x/sync v0.16.0 h1:ycBJEhp9p4vXvUZNszeOq0kGTPghopOL8q0fq3vstxw=
golang.org/x/sync v0.16.0/go.mod h1:1dzgHSNfp02xaA81J2MS99Qcpr2w7fw1gpm99rleRqA=
golang.org/x/sys v0.34.0 h1:H5Y5sJ2L2JRdyv7ROF1he/lPdvFsd0mJHFw2ThKHxLA=
golang.org/x/sys v0.34.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=
golang.org/x/text v0.27.0 h1:4fGWRpyh641NLlecmyl4LOe6yDdfaYNrGb2zdfo4JV4=
golang.org/x/text v0.27.0/go.mod h1:1D28KMCvyooCX9hBiosv5Tz/+YLxj0j7XhWjpSUF7CU=
google.golang.org/genproto/googleapis/api v0.0.0-20250728155136-f173205681a0 h1:0UOBWO4dC+e51ui0NFKSPbkHHiQ4TmrEfEZMLDyRmY8=
google.golang.org/genproto/googleapis/api v0.0.0-20250728155136-f173205681a0/go.mod h1:8ytArBbtOy2xfht+y2fqKd5DRDJRUQhqbyEnQ4bDChs=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250728155136-f173205681a0 h1:MAKi5q709QWfnkkpNQ0M12hYJ1+e8qYVDyowc4U1XZM=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250728155136-f173205681a0/go.mod h1:qQ0YXyHHx3XkvlzUtpXDkS29lDSafHMZBAZDc03LQ3A=
google.golang.org/grpc v1.74.2 h1:WoosgB65DlWVC9FqI82dGsZhWFNBSLjQ84bjROOpMu4=
google.golang.org/grpc v1.74.2/go.mod h1:CtQ+BGjaAIXHs/5YS3i473GqwBBa1zGQNevxdeBEXrM=
google.golang.org/protobuf v1.36.6 h1:z1NpPI8ku2WgiWnf+t9wTPsn6eP1L7ksHUlkfLvd9xY=
google.golang.org/protobuf v1.36.6/go.mod h1:jduwjTPXsFjZGTmRluh+L6NjiWu7pchiJ2/5YcXBHnY=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=



================================================
FILE: .dagger/main.go
================================================
package main

import (
	"context"
	"dagger/container-use/internal/dagger"
)

type ContainerUse struct {
	Source *dagger.Directory
}

// dagger module for building container-use
func New(
	//+defaultPath="/"
	source *dagger.Directory,
) *ContainerUse {
	return &ContainerUse{
		Source: source,
	}
}

// Build creates a binary for the current platform
func (m *ContainerUse) Build(ctx context.Context,
	//+optional
	platform dagger.Platform,
) *dagger.File {
	return dag.Go(m.Source).Binary("./cmd/container-use", dagger.GoBinaryOpts{
		Platform: platform,
	})
}

// BuildMultiPlatform builds binaries for multiple platforms using GoReleaser
func (m *ContainerUse) BuildMultiPlatform(ctx context.Context,
	// GitHub org name for package publishing, set only if testing release process on a personal fork
	//+optional
	//+default="dagger"
	githubOrgName string,
) *dagger.Directory {
	return dag.Goreleaser(m.Source).
		WithEnvVariable("GH_ORG_NAME", githubOrgName).
		Build().
		WithSnapshot().
		All()
}

// Release creates a release using GoReleaser
func (m *ContainerUse) Release(ctx context.Context,
	// Version tag for the release
	version string,
	// GitHub token for authentication
	githubToken *dagger.Secret,
	// GitHub org name for package publishing, set only if testing release process on a personal fork
	//+default="dagger"
	githubOrgName string,
) (string, error) {
	// Create custom container with nix package for nix-hash binary
	customContainer := dag.Container().
		From("ghcr.io/goreleaser/goreleaser:latest").
		WithExec([]string{"apk", "add", "nix"})

	// Use custom container with Goreleaser
	return dag.Goreleaser(m.Source, dagger.GoreleaserOpts{
		Container: customContainer,
	}).
		WithSecretVariable("GITHUB_TOKEN", githubToken).
		WithEnvVariable("GH_ORG_NAME", githubOrgName).
		Release().
		Run(ctx)
}

// Test runs the test suite
func (m *ContainerUse) Test(ctx context.Context,
	//+optional
	//+default="./..."
	// Package to test
	pkg string,
	//+optional
	// Run tests with verbose output
	verboseOutput bool,
	//+optional
	//+default=true
	// Run tests including integration tests
	integration bool,
) (string, error) {
	// Use a plain Debian-based Go image to avoid Wolfi package constraints (e.g. protoc version pins)
	ctr := dag.Go(m.Source).
		Base().
		WithMountedDirectory("/src", m.Source).
		WithWorkdir("/src").
		// Configure git for tests
		WithExec([]string{"git", "config", "--global", "user.email", "test@example.com"}).
		WithExec([]string{"git", "config", "--global", "user.name", "Test User"})

	args := []string{"go", "test"}
	if verboseOutput {
		args = append(args, "-v")
	}
	if !integration {
		args = append(args, "-short")
	}
	args = append(args, pkg)

	return ctr.
		WithExec(args, dagger.ContainerWithExecOpts{ExperimentalPrivilegedNesting: true}).
		Stdout(ctx)
}

// TestNixHash tests if nix-hash binary is available in our custom container
func (m *ContainerUse) TestNixHash(ctx context.Context) (string, error) {
	// Create the same custom container we use for releases
	customContainer := dag.Container().
		From("ghcr.io/goreleaser/goreleaser:latest").
		WithExec([]string{"apk", "add", "nix"})

	// Test if nix-hash is available
	return customContainer.
		WithExec([]string{"which", "nix-hash"}).
		Stdout(ctx)
}

// Test runs the linter
func (m *ContainerUse) Lint(ctx context.Context) error {
	return dag.
		Golangci().
		Lint(m.Source, dagger.GolangciLintOpts{}).
		Assert(ctx)
}



================================================
FILE: .github/dependabot.yml
================================================
# https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/optimizing-pr-creation-version-updates#setting-up-a-cooldown-period-for-dependency-updates

version: 2
updates:
  - package-ecosystem: github-actions
    directory: /
    schedule:
      interval: weekly
    groups: # 1 PR per week for all images
      actions:
        patterns: ["*"]
  - package-ecosystem: gomod
    directories:
      - /
      - .dagger
    schedule:
      interval: weekly
    # https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#groups--
    groups: # 1 PR per week and group
      major:
        update-types: ["major"]
      minor:
        update-types: ["minor"]
      patch:
        update-types: ["patch"]



================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.yml
================================================
name: Bug Report
description: Report a bug
title: "[Bug]: "
labels: ["bug"]
body:
  - type: textarea
    id: what-happened
    attributes:
      label: What happened?
      description: Brief description of the issue
    validations:
      required: true

  - type: textarea
    id: version
    attributes:
      label: Version
      description: Run `container-use version` and paste the output
      render: shell
    validations:
      required: true

  - type: textarea
    id: logs
    attributes:
      label: Logs
      description: Contents of `/tmp/container-use.debug.stderr.log` (or `$CONTAINER_USE_STDERR_FILE` if set)
      render: text
    validations:
      required: false



================================================
FILE: .github/ISSUE_TEMPLATE/config.yml
================================================
---
blank_issues_enabled: true
contact_links:
  - name: Discord Community
    url: https://discord.gg/YXbtwRQv
    about: Join our Discord for questions and community support
  - name: Documentation
    url: https://container-use.com/quickstart
    about: Check out our setup guide and documentation



================================================
FILE: .github/ISSUE_TEMPLATE/feature_request.yml
================================================
name: Feature Request
description: Suggest a new feature
title: "[Feature]: "
labels: ["enhancement"]
body:
  - type: textarea
    id: feature
    attributes:
      label: What feature would you like?
      description: Brief description of the feature you'd like to see
    validations:
      required: true

  - type: textarea
    id: why
    attributes:
      label: Why would this be useful?
      description: How would this feature help you or others?
    validations:
      required: true



================================================
FILE: .github/workflows/build.yml
================================================
name: Build

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Build with Dagger
        uses: dagger/dagger-for-github@v8.1.0
        with:
          version: "latest"
          verb: call
          args: build -o container-use

      - name: Verify binary
        run: |
          if [ ! -f container-use ]; then
            echo "Binary 'container-use' was not created"
            exit 1
          fi
          echo "Binary created successfully"
          ls -la container-use



================================================
FILE: .github/workflows/lint.yml
================================================
name: Lint

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Run tests
        uses: dagger/dagger-for-github@v8.1.0
        with:
          version: "latest"
          verb: call
          args: lint



================================================
FILE: .github/workflows/publish-docs.yml
================================================
name: Publish Docs

on:
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      source:
        description: "Tag or branch to publish to docs branch"
        required: true

jobs:
  publish-docs:
    name: Publish Docs
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Publish to docs branch
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          if [ "${{ github.event_name }}" = "release" ]; then
            SOURCE="${GITHUB_REF#refs/tags/}"
          else
            SOURCE="${{ github.event.inputs.source }}"
          fi

          SOURCE_SHA=$(git rev-parse $SOURCE)
          git push -f https://github-actions[bot]:${{ secrets.RELEASE_GITHUB_TOKEN }}@github.com/${{ github.repository }}.git "$SOURCE_SHA:refs/heads/docs"
        env:
          RELEASE_GITHUB_TOKEN: ${{ secrets.RELEASE_GITHUB_TOKEN }}



================================================
FILE: .github/workflows/release.yml
================================================
name: Release

on:
  push:
    tags:
      - "v*"

jobs:
  release:
    name: Release
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Release with Dagger
        uses: dagger/dagger-for-github@v8.1.0
        with:
          version: "latest"
          verb: call
          args: release --version "${GITHUB_REF#refs/tags/}" --github-token env:RELEASE_GITHUB_TOKEN --github-org-name=${{ github.repository_owner }}
        env:
          RELEASE_GITHUB_TOKEN: ${{ secrets.RELEASE_GITHUB_TOKEN }}



================================================
FILE: .github/workflows/test.yml
================================================
name: Test

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  test:
    name: Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Run tests
        uses: dagger/dagger-for-github@v8.1.0
        with:
          version: "latest"
          verb: call
          args: test --verbose


================================================
SYMLINK: .goosehints -> AGENT.md
================================================


